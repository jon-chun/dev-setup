{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":"I need you to update `/Users/jonc/code/sentimentarcs/README.md` to include information about the NEW programmatic API and create a comprehensive documentation index.\n\n**Current state:**\n- README mentions CLI usage and \"Python API\" but only shows old SentimentAnalyzer\n- Does not mention the new SentimentPipeline fluent interface\n- Documentation section is minimal (only 3 docs listed)\n- Does not reflect the complete 12-stage pipeline with Stage 10\n- Test information is minimal\n\n**Required updates:**\n\n1. **Update \"Key Features\" section** - Add:\n   - ✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n   - ✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n   - ✅ **Master File Accumulation**: Single CSV with all intermediate results\n   - ✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n2. **Update \"Python API\" section** - Rename to \"Usage\" and add TWO subsections:\n\n   **CLI Usage** (keep existing):\n   ```bash\n   sentimentarcs samples/my_story.txt -c config.yaml\n   ```\n\n   **Programmatic API** (NEW):\n   ```python\n   from sentimentarcs import SentimentPipeline, ArcConfig\n   \n   config = ArcConfig.from_yaml(\"config.yaml\")\n   \n   result = (SentimentPipeline(config)\n       .load_text(\"novel.txt\")\n       .preprocess()\n       .segment()\n       .validate()\n       .analyze_sentiment()\n       .smooth()\n       .normalize()\n       .plot_ensemble()\n       .analyze_incoherence()\n       .detect_crux()\n       .extract_crux()  # NEW Stage 10\n       .plot_crux()\n       .report()\n       .execute())\n   \n   # Access results\n   master_df = result.get_master_dataframe()\n   crux_points = result.get_crux_points()\n   ```\n\n3. **Update \"Pipeline Stages\" section** - Change from 8 stages to 12 stages:\n   1. Preprocess\n   2. Segment  \n   3. Validate\n   4. Sentiment Analysis\n   5. Smoothing\n   6. Normalization\n   7. Ensemble Plot\n   8. Incoherence Analysis\n   9. Crux Detection\n   10. **Crux Context Extraction** (NEW)\n   11. Crux Plot\n   12. Report Generation\n\n4. **Expand \"Documentation\" section** with comprehensive index:\n\n   | Document | Description |\n   |----------|-------------|\n   | **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n   | **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n   | **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n   | **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n   | **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n   | **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n   | **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n   | **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n5. **Update \"Testing\" section** to mention:\n   ```bash\n   # Run all tests (CLI + API)\n   python tests/test_regression_harness.py\n   \n   # Run only API tests\n   python tests/test_regression_harness.py --api-only\n   \n   # Run with pytest\n   pytest tests/\n   ```\n\n6. **Update \"Rich Output Files\" section** - Add NEW standardized structure:\n   ```\n   outputs/{text_name}/\n   ├── datafiles/                     # Shared workspace (NEW)\n   │   ├── {root}_clean.txt\n   │   ├── {root}_segments.csv\n   │   ├── {root}_sentiments.csv\n   │   ├── {root}_crux-points.csv\n   │   ├── {root}_crux-text.csv      # NEW Stage 10\n   │   └── {root}_sentimentarcs.csv  # Master file (NEW)\n   ├── plots/\n   │   ├── {root}_plot-ensemble.png\n   │   └── {root}_plot-crux.png\n   ├── reports/\n   │   └── {root}_report.md\n   └── logs/\n       └── {root}_{timestamp}.log\n   ```\n\n7. **Update Changelog** to version 0.2.0:\n   - ✨ NEW: Complete programmatic API with fluent interface\n   - ✨ NEW: Stage 10 crux context extraction\n   - ✨ NEW: Master file accumulation system\n   - ✨ NEW: 66 API tests (31 unit + 35 integration)\n   - ✨ NEW: Master regression test harness\n   - ✨ NEW: Comprehensive documentation suite (8+ docs)\n\n8. **Keep everything else** from the current README (model selection, configuration, examples, etc.)\n\n**Style:**\n- Maintain current friendly, accessible tone\n- Keep all existing badges and metadata\n- Preserve all existing examples\n- Add \"See [doc link] for details\" cross-references\n- Use ✨ emoji for NEW features in changelog"},"uuid":"841d70b8-41a4-4fb0-b650-8b7db7244bc8","timestamp":"2025-11-11T15:10:49.881Z"}
{"parentUuid":"841d70b8-41a4-4fb0-b650-8b7db7244bc8","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01SEDTQmWHAfQFdE24TqZ5UA","type":"message","role":"assistant","content":[{"type":"text","text":"I'll analyze the current README and update it according to your specifications. Let me first read the current README to understand its structure."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1716,"cache_read_input_tokens":15608,"cache_creation":{"ephemeral_5m_input_tokens":1716,"ephemeral_1h_input_tokens":0},"output_tokens":95,"service_tier":"standard"}},"requestId":"req_011CV2KFvy6o2b2Dy4b6A21t","type":"assistant","uuid":"6c45da97-bb47-4bc9-963e-ecaef6bc8622","timestamp":"2025-11-11T15:10:52.596Z"}
{"parentUuid":"6c45da97-bb47-4bc9-963e-ecaef6bc8622","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01SEDTQmWHAfQFdE24TqZ5UA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019TSAccRRyTmLWxh52qUQNw","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1716,"cache_read_input_tokens":15608,"cache_creation":{"ephemeral_5m_input_tokens":1716,"ephemeral_1h_input_tokens":0},"output_tokens":95,"service_tier":"standard"}},"requestId":"req_011CV2KFvy6o2b2Dy4b6A21t","type":"assistant","uuid":"cf7c967d-349a-42fc-9fc7-ea7432b836e3","timestamp":"2025-11-11T15:10:53.052Z"}
{"parentUuid":"cf7c967d-349a-42fc-9fc7-ea7432b836e3","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019TSAccRRyTmLWxh52qUQNw","type":"tool_result","content":"     1→# SentimentArcs\n     2→\n     3→**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n     4→\n     5→[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n     6→[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n     7→\n     8→By Jon Chun | November 2025\n     9→\n    10→---\n    11→\n    12→## Overview\n    13→\n    14→SentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n    15→\n    16→### Key Features\n    17→\n    18→✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n    19→\n    20→✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n    21→\n    22→✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments (NEW)\n    23→\n    24→✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n    25→\n    26→✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n    27→\n    28→✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n    29→\n    30→✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n    31→\n    32→---\n    33→\n    34→## Quick Start\n    35→\n    36→### Installation\n    37→\n    38→```bash\n    39→pip install sentimentarcs\n    40→\n    41→# Or from source\n    42→git clone https://github.com/yourorg/sentimentarcs.git\n    43→cd sentimentarcs\n    44→pip install -e .\n    45→```\n    46→\n    47→### Basic Usage\n    48→\n    49→**1. Create configuration file** (`config.yaml`):\n    50→\n    51→```yaml\n    52→project:\n    53→  name: \"my_analysis\"\n    54→\n    55→models:\n    56→  enabled_models:\n    57→    - \"vader\"      # Fast lexical model\n    58→    - \"textblob\"   # Fast lexical model\n    59→\n    60→incoherence:\n    61→  enabled: true    # Measure model disagreement\n    62→  algorithm: \"sd\"  # Standard deviation\n    63→\n    64→crux_detection:\n    65→  base_model_choice: [\"vader\", \"textblob\"]\n    66→  method: \"derivative_extrema\"\n    67→```\n    68→\n    69→**2. Run analysis**:\n    70→\n    71→```bash\n    72→sentimentarcs samples/my_story.txt -c config.yaml\n    73→```\n    74→\n    75→**3. View results**:\n    76→\n    77→```bash\n    78→# Navigate to outputs\n    79→cd outputs/my_story/\n    80→\n    81→# View main report\n    82→cat reports/my_analysis_report_vader-textblob.md\n    83→\n    84→# View plot\n    85→open plots/my_analysis_arc_vader-textblob.png\n    86→\n    87→# View incoherence analysis\n    88→cat incoherence/my_analysis_incoherence_report.txt\n    89→```\n    90→\n    91→### Python API\n    92→\n    93→```python\n    94→from sentimentarcs.config import ArcConfig\n    95→from sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer\n    96→\n    97→# Load configuration\n    98→config = ArcConfig.from_yaml(\"config.yaml\")\n    99→\n   100→# Run analysis\n   101→analyzer = SentimentAnalyzer(config)\n   102→result = analyzer.run(\"samples/my_story.txt\")\n   103→\n   104→# Access results\n   105→print(f\"Found {len(result.crux.peaks)} emotional peaks\")\n   106→print(result.sentiment_table.head())\n   107→```\n   108→\n   109→---\n   110→\n   111→## Documentation\n   112→\n   113→| Document | Description |\n   114→|----------|-------------|\n   115→| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n   116→| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n   117→| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |\n   118→\n   119→---\n   120→\n   121→## Features in Detail\n   122→\n   123→### 1. Multiple Sentiment Models\n   124→\n   125→**Local Models** (no API key required):\n   126→- **VADER**: Fast, rule-based lexical model (social media, informal text)\n   127→- **TextBlob**: Pattern-based lexical model (general purpose)\n   128→- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n   129→- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n   130→\n   131→**API Models** (cloud):\n   132→- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n   133→- **Anthropic**: Claude Sonnet (highly nuanced)\n   134→- **Google**: Gemini (multimodal capabilities)\n   135→\n   136→**Local API Models** (private, free):\n   137→- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n   138→- **LM Studio**: Local model hosting\n   139→\n   140→### 2. Ensemble Analysis\n   141→\n   142→Combine multiple models for robust predictions:\n   143→\n   144→```yaml\n   145→models:\n   146→  enabled_models:\n   147→    - \"vader\"\n   148→    - \"textblob\"\n   149→    - \"distilbert\"\n   150→\n   151→crux_detection:\n   152→  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n   153→  avg_method: \"median\"  # Options: mean, median, mode\n   154→```\n   155→\n   156→### 3. Incoherence Analysis (NEW)\n   157→\n   158→Measure model disagreement to identify ambiguous segments:\n   159→\n   160→```yaml\n   161→incoherence:\n   162→  enabled: true\n   163→  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n   164→  min_models: 2\n   165→```\n   166→\n   167→**Outputs**:\n   168→- `incoherence_{algorithm}` column in main sentiment CSV\n   169→- Separate incoherence CSV with focused analysis\n   170→- Markdown report with statistics and top disagreement segments\n   171→\n   172→**Interpretation**:\n   173→- **Low** (0.0-0.2): Strong model agreement\n   174→- **Medium** (0.2-0.5): Moderate disagreement\n   175→- **High** (0.5+): Strong disagreement (review recommended)\n   176→\n   177→### 4. Multi-Model Ollama Support\n   178→\n   179→Run multiple local models in ensemble:\n   180→\n   181→```yaml\n   182→models:\n   183→  enabled_models:\n   184→    - \"api_ollama_llama3.2\"\n   185→    - \"api_ollama_phi4\"\n   186→    - \"api_ollama_gemma3\"\n   187→\n   188→api_models:\n   189→  ollama:\n   190→    enabled: true\n   191→    base_url: \"http://localhost:11434\"\n   192→    model_switch_delay_sec: 3\n   193→    ollama_models:\n   194→      llama3.2: \"llama3.2:3b\"\n   195→      phi4: \"phi4-mini:3.8b\"\n   196→      gemma3: \"gemma3:4b\"\n   197→```\n   198→\n   199→### 5. Crux Detection\n   200→\n   201→Automatically identify emotional peaks and valleys:\n   202→\n   203→- **Peaks**: Moments of highest emotional intensity\n   204→- **Valleys**: Moments of lowest emotional intensity\n   205→- **Context Windows**: Extract surrounding text for analysis\n   206→\n   207→### 6. Rich Output Files\n   208→\n   209→Each analysis generates:\n   210→\n   211→```\n   212→outputs/{text_name}/\n   213→├── segments/               # Segmented text\n   214→│   ├── {project}_segments_{models}.csv\n   215→│   └── {project}_cleaned_{models}.txt\n   216→├── sentiment/              # Sentiment analysis results\n   217→│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n   218→├── incoherence/            # Model disagreement analysis (NEW)\n   219→│   ├── {project}_incoherence.csv\n   220→│   └── {project}_incoherence_report.txt\n   221→├── plots/                  # Visualizations\n   222→│   ├── {project}_arc_{models}.png           # Main sentiment arc\n   223→│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n   224→├── reports/                # Analysis reports\n   225→│   └── {project}_report_{models}.md\n   226→└── logs/                   # Detailed logs\n   227→    └── sentimentarcs_{models}_{timestamp}.log\n   228→```\n   229→\n   230→---\n   231→\n   232→## Pipeline Stages\n   233→\n   234→SentimentArcs follows an 8-stage pipeline:\n   235→\n   236→1. **Preprocess**: Load and clean text\n   237→2. **Segment**: Split into sentences/paragraphs\n   238→3. **Validate**: Remove invalid segments\n   239→4. **Sentiment Analysis**: Run enabled models sequentially\n   240→5. **Smoothing**: Apply moving average smoothing\n   241→6. **Normalization**: Normalize to [-1, 1] range\n   242→6.5. **Ensemble Plot**: Generate multi-model overlay\n   243→**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n   244→7. **Crux Detection**: Identify emotional peaks/valleys\n   245→8. **Report Generation**: Create plots and markdown reports\n   246→\n   247→---\n   248→\n   249→## Model Selection Guide\n   250→\n   251→| Use Case | Recommended Models | Config |\n   252→|----------|-------------------|--------|\n   253→| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n   254→| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n   255→| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n   256→| **Private/Free** | Ollama (multiple models) | Local inference |\n   257→| **Ensemble Robust** | 3+ models + median | Best practice |\n   258→\n   259→---\n   260→\n   261→## Configuration\n   262→\n   263→### Minimal Configuration\n   264→\n   265→```yaml\n   266→project:\n   267→  name: \"my_analysis\"\n   268→\n   269→models:\n   270→  enabled_models:\n   271→    - \"vader\"\n   272→    - \"textblob\"\n   273→```\n   274→\n   275→### Advanced Configuration\n   276→\n   277→```yaml\n   278→project:\n   279→  name: \"comprehensive_analysis\"\n   280→\n   281→models:\n   282→  enabled_models:\n   283→    - \"vader\"\n   284→    - \"textblob\"\n   285→    - \"distilbert\"\n   286→    - \"api_ollama_llama3.2\"\n   287→    - \"api_ollama_phi4\"\n   288→\n   289→incoherence:\n   290→  enabled: true\n   291→  algorithm: \"sd\"\n   292→\n   293→crux_detection:\n   294→  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n   295→  avg_method: \"median\"\n   296→  min_prominence: 0.1\n   297→  context_window_segments: 10\n   298→\n   299→smoothing:\n   300→  enabled: true\n   301→  window_size: 5\n   302→```\n   303→\n   304→See [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n   305→\n   306→---\n   307→\n   308→## Requirements\n   309→\n   310→### Core Dependencies\n   311→\n   312→- Python 3.9+\n   313→- pandas >= 1.5\n   314→- numpy >= 1.24\n   315→- matplotlib >= 3.7\n   316→- scipy >= 1.10\n   317→- pyyaml >= 6.0\n   318→- pydantic >= 2.0\n   319→\n   320→### Optional Dependencies\n   321→\n   322→**For local sentiment models**:\n   323→- textblob >= 0.18\n   324→- vaderSentiment >= 3.3.2\n   325→\n   326→**For neural models**:\n   327→- transformers >= 4.0\n   328→- torch >= 2.0\n   329→\n   330→**For API models**:\n   331→- openai >= 1.0.0\n   332→- anthropic >= 0.20.0\n   333→- requests >= 2.31\n   334→\n   335→---\n   336→\n   337→## API Models Setup\n   338→\n   339→### Environment Variables\n   340→\n   341→Create `.env` file:\n   342→\n   343→```bash\n   344→OPENAI_API_KEY=\"sk-proj-...\"\n   345→ANTHROPIC_API_KEY=\"sk-ant-...\"\n   346→GEMINI_API_KEY=\"...\"\n   347→```\n   348→\n   349→### OpenAI (GPT-5, GPT-4o, GPT-4)\n   350→\n   351→```yaml\n   352→api_models:\n   353→  openai:\n   354→    enabled: true\n   355→    model_name: \"gpt-5-mini\"\n   356→    api_key_env: \"OPENAI_API_KEY\"\n   357→    batch_size: 20\n   358→```\n   359→\n   360→### Ollama (Local Inference)\n   361→\n   362→```bash\n   363→# Start Ollama server\n   364→ollama serve\n   365→\n   366→# Pull models\n   367→ollama pull llama3.2:3b\n   368→ollama pull phi4-mini:3.8b\n   369→\n   370→# Configure in config.yaml\n   371→models:\n   372→  enabled_models:\n   373→    - \"api_ollama_llama3.2\"\n   374→    - \"api_ollama_phi4\"\n   375→```\n   376→\n   377→---\n   378→\n   379→## Testing\n   380→\n   381→```bash\n   382→# Run all tests\n   383→pytest tests/\n   384→\n   385→# Run unit tests only\n   386→pytest tests/unit/\n   387→\n   388→# Run integration tests only\n   389→pytest tests/integration/\n   390→\n   391→# Exclude API tests (no credentials needed)\n   392→pytest tests/ -k \"not api\"\n   393→\n   394→# With coverage\n   395→pytest --cov=sentimentarcs --cov-report=html tests/\n   396→```\n   397→\n   398→See [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n   399→\n   400→---\n   401→\n   402→## Examples\n   403→\n   404→### Example 1: Quick Novel Analysis\n   405→\n   406→```bash\n   407→# Use fast lexical models\n   408→sentimentarcs samples/novel.txt -c config.yaml\n   409→```\n   410→\n   411→### Example 2: Academic Research\n   412→\n   413→```yaml\n   414→# config_research.yaml\n   415→models:\n   416→  enabled_models:\n   417→    - \"vader\"\n   418→    - \"textblob\"\n   419→    - \"distilbert\"\n   420→    - \"nlptown\"\n   421→\n   422→incoherence:\n   423→  enabled: true  # Track model agreement\n   424→\n   425→reproducibility:\n   426→  random_seed: 42\n   427→  deterministic: true\n   428→```\n   429→\n   430→### Example 3: Budget Analysis with Ollama\n   431→\n   432→```yaml\n   433→# config_ollama.yaml\n   434→models:\n   435→  enabled_models:\n   436→    - \"api_ollama_llama3.2\"\n   437→    - \"api_ollama_phi4\"\n   438→    - \"api_ollama_granite\"\n   439→\n   440→crux_detection:\n   441→  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n   442→  avg_method: \"median\"\n   443→```\n   444→\n   445→### Example 4: SOTA with OpenAI\n   446→\n   447→```yaml\n   448→# config_openai.yaml\n   449→models:\n   450→  enabled_models:\n   451→    - \"api_openai\"\n   452→\n   453→api_models:\n   454→  openai:\n   455→    enabled: true\n   456→    model_name: \"gpt-5-mini\"\n   457→    batch_size: 20\n   458→```\n   459→\n   460→---\n   461→\n   462→## Output Interpretation\n   463→\n   464→### Sentiment Scores\n   465→\n   466→- **-1.0**: Very negative (sadness, anger, fear)\n   467→- **-0.5**: Moderately negative (disappointment, worry)\n   468→- **0.0**: Neutral (factual, balanced)\n   469→- **+0.5**: Moderately positive (contentment, satisfaction)\n   470→- **+1.0**: Very positive (joy, excitement, triumph)\n   471→\n   472→### Incoherence Scores\n   473→\n   474→- **0.0-0.2**: Strong agreement (low ambiguity)\n   475→- **0.2-0.5**: Moderate disagreement (some ambiguity)\n   476→- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n   477→\n   478→### Crux Points\n   479→\n   480→- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n   481→- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n   482→- **Context**: Surrounding text provides narrative context\n   483→\n   484→---\n   485→\n   486→## Development\n   487→\n   488→### Project Structure\n   489→\n   490→```\n   491→sentimentarcs/\n   492→├── sentimentarcs/          # Main package\n   493→│   ├── core/              # Pipeline stages\n   494→│   ├── models/            # Sentiment models\n   495→│   ├── analysis/          # Analysis modules\n   496→│   ├── plotting/          # Visualization\n   497→│   ├── config.py          # Configuration\n   498→│   └── cli.py             # Command-line interface\n   499→├── tests/                  # Test suite\n   500→│   ├── unit/              # Unit tests\n   501→│   └── integration/       # Integration tests\n   502→├── docs/                   # Documentation\n   503→│   ├── doc_user-guide.md\n   504→│   ├── doc_tech-spec.md\n   505→│   └── TESTING.md\n   506→├── samples/                # Sample texts\n   507→├── config.yaml             # Default configuration\n   508→└── README.md               # This file\n   509→```\n   510→\n   511→### Contributing\n   512→\n   513→1. Fork the repository\n   514→2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n   515→3. Make your changes\n   516→4. Run tests (`pytest tests/`)\n   517→5. Commit your changes (`git commit -m 'Add amazing feature'`)\n   518→6. Push to branch (`git push origin feature/amazing-feature`)\n   519→7. Open a Pull Request\n   520→\n   521→---\n   522→\n   523→## Citation\n   524→\n   525→If you use SentimentArcs in your research, please cite:\n   526→\n   527→```bibtex\n   528→@software{sentimentarcs2025,\n   529→  author = {Chun, Jon},\n   530→  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n   531→  year = {2025},\n   532→  url = {https://github.com/yourorg/sentimentarcs}\n   533→}\n   534→```\n   535→\n   536→---\n   537→\n   538→## License\n   539→\n   540→MIT License - see [LICENSE](LICENSE) file for details.\n   541→\n   542→---\n   543→\n   544→## Changelog\n   545→\n   546→### Version 0.1.0 (November 2025)\n   547→\n   548→**New Features**:\n   549→- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n   550→- ✨ Multi-model Ollama support with model switching\n   551→- ✨ OpenAI GPT-5-mini support with native API\n   552→- ✨ Ensemble averaging for crux detection\n   553→- ✨ Comprehensive test suite (29 tests)\n   554→\n   555→**Models Added**:\n   556→- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n   557→- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n   558→- Anthropic, Google, LM Studio API support\n   559→\n   560→**Improvements**:\n   561→- Better column ordering in output CSVs\n   562→- Progress tracking with time estimates\n   563→- Exponential backoff retry for API models\n   564→- Pydantic response validation\n   565→- Model warmup for Ollama\n   566→\n   567→**Documentation**:\n   568→- Comprehensive user guide\n   569→- Technical specification for developers\n   570→- Testing guide\n   571→\n   572→---\n   573→\n   574→## Support\n   575→\n   576→- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n   577→- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n   578→- **Email**: jon.chun@example.com\n   579→\n   580→---\n   581→\n   582→## Acknowledgments\n   583→\n   584→- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n   585→- TextBlob: [textblob](https://textblob.readthedocs.io/)\n   586→- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n   587→- Ollama: [ollama](https://ollama.ai/)\n   588→\n   589→---\n   590→\n   591→**Built with ❤️ for computational literary analysis**\n   592→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d8b6a879-d339-4842-b533-ce5c931b3213","timestamp":"2025-11-11T15:10:53.081Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","content":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments (NEW)\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n### Python API\n\n```python\nfrom sentimentarcs.config import ArcConfig\nfrom sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer\n\n# Load configuration\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\n# Run analysis\nanalyzer = SentimentAnalyzer(config)\nresult = analyzer.run(\"samples/my_story.txt\")\n\n# Access results\nprint(f\"Found {len(result.crux.peaks)} emotional peaks\")\nprint(result.sentiment_table.head())\n```\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","numLines":592,"startLine":1,"totalLines":592}}}
{"parentUuid":"d8b6a879-d339-4842-b533-ce5c931b3213","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll update the README.md according to all your specifications. Let me make these changes:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"1bd85382-4c38-4dc5-97bc-f4890ec9db5c","timestamp":"2025-11-11T15:10:56.623Z"}
{"parentUuid":"1bd85382-4c38-4dc5-97bc-f4890ec9db5c","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GwuMQkcambnRFo4mZPrBHV","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"### Key Features\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments (NEW)\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)","new_string":"### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"9c2b8a8c-256b-47e5-9177-2e728ad869f0","timestamp":"2025-11-11T15:11:06.776Z"}
{"parentUuid":"9c2b8a8c-256b-47e5-9177-2e728ad869f0","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015yabqXtQwt42wrzSMwXza7","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"### Python API\n\n```python\nfrom sentimentarcs.config import ArcConfig\nfrom sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer\n\n# Load configuration\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\n# Run analysis\nanalyzer = SentimentAnalyzer(config)\nresult = analyzer.run(\"samples/my_story.txt\")\n\n# Access results\nprint(f\"Found {len(result.crux.peaks)} emotional peaks\")\nprint(result.sentiment_table.head())\n```","new_string":"## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"ebee8b8e-da75-47be-81d4-affdd3f91429","timestamp":"2025-11-11T15:11:12.850Z"}
{"parentUuid":"ebee8b8e-da75-47be-81d4-affdd3f91429","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Bfqjg5MKtBxHqziTDUt7Wy","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |","new_string":"## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"09cdf82c-a9d4-4b8d-a7cf-89a6d46b1df6","timestamp":"2025-11-11T15:11:18.284Z"}
{"parentUuid":"09cdf82c-a9d4-4b8d-a7cf-89a6d46b1df6","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017LEkHr34oM6ZALN7qGcVWK","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports","new_string":"## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"0daa3baf-0edd-4c0f-9255-f142bcaee605","timestamp":"2025-11-11T15:11:22.705Z"}
{"parentUuid":"0daa3baf-0edd-4c0f-9255-f142bcaee605","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01V2Y65aePHV8rcgvk7S4z54","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```","new_string":"### 6. Rich Output Files\n\nEach analysis generates standardized output structure:\n\n```\noutputs/{text_name}/\n├── datafiles/                     # Shared workspace (NEW)\n│   ├── {root}_clean.txt\n│   ├── {root}_segments.csv\n│   ├── {root}_sentiments.csv\n│   ├── {root}_crux-points.csv\n│   ├── {root}_crux-text.csv      # NEW Stage 10\n│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n├── plots/\n│   ├── {root}_plot-ensemble.png\n│   └── {root}_plot-crux.png\n├── reports/\n│   └── {root}_report.md\n└── logs/\n    └── {root}_{timestamp}.log\n```\n\nSee [User Guide](docs/doc_user-guide.md#output-files) for details."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"c34ac540-f4a6-43c1-85bd-95fe3e178de9","timestamp":"2025-11-11T15:11:28.962Z"}
{"parentUuid":"c34ac540-f4a6-43c1-85bd-95fe3e178de9","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Tw6f5eWLhSg94ycPFmhnhN","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.","new_string":"## Testing\n\n```bash\n# Run all tests (CLI + API)\npython tests/test_regression_harness.py\n\n# Run only API tests\npython tests/test_regression_harness.py --api-only\n\n# Run with pytest\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"0a3e68fa-7b1f-4cf8-95c8-d1e2d25b05f8","timestamp":"2025-11-11T15:11:32.646Z"}
{"parentUuid":"0a3e68fa-7b1f-4cf8-95c8-d1e2d25b05f8","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01RaQfnz4cHrUHRbTeRGy1eC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JEKWRYPtrDjs1rygRg8A5G","name":"Edit","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","old_string":"## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide","new_string":"## Changelog\n\n### Version 0.2.0 (November 2025)\n\n**New Features**:\n- ✨ NEW: Complete programmatic API with fluent interface\n- ✨ NEW: Stage 10 crux context extraction\n- ✨ NEW: Master file accumulation system\n- ✨ NEW: 66 API tests (31 unit + 35 integration)\n- ✨ NEW: Master regression test harness\n- ✨ NEW: Comprehensive documentation suite (8+ docs)\n- ✨ NEW: Standardized output directory structure\n\n**Documentation**:\n- API Quick Start guide\n- API Design specification\n- API Usage guide with patterns\n- API Implementation summary\n- Enhanced Testing guide (91 tests)\n- Roadmap for future development\n\n**Improvements**:\n- Dual interface support (CLI + programmatic API)\n- Unified master dataframe accumulation\n- 100% test pass rate across all tests\n- Enhanced crux context extraction\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6492,"cache_read_input_tokens":17324,"cache_creation":{"ephemeral_5m_input_tokens":6492,"ephemeral_1h_input_tokens":0},"output_tokens":3674,"service_tier":"standard"}},"requestId":"req_011CV2KGApY8crEXaber1wap","type":"assistant","uuid":"dd210528-4836-4521-9bdf-f9bbb4820cfc","timestamp":"2025-11-11T15:11:40.938Z"}
{"parentUuid":"dd210528-4836-4521-9bdf-f9bbb4820cfc","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GwuMQkcambnRFo4mZPrBHV","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n    12→## Overview\n    13→\n    14→SentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n    15→\n    16→### Key Features\n    17→\n    18→✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n    19→\n    20→✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n    21→\n    22→✅ **Master File Accumulation**: Single CSV with all intermediate results\n    23→\n    24→✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n    25→\n    26→✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n    27→\n    28→✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n    29→\n    30→✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n    31→\n    32→✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n    33→\n    34→✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n    35→\n    36→✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n    37→\n    38→✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n    39→\n    40→---\n    41→\n    42→## Quick Start"}]},"uuid":"291d5c53-904c-4595-91d9-337f74241ce3","timestamp":"2025-11-11T15:11:41.983Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"### Key Features\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments (NEW)\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)","newString":"### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments (NEW)\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n### Python API\n\n```python\nfrom sentimentarcs.config import ArcConfig\nfrom sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer\n\n# Load configuration\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\n# Run analysis\nanalyzer = SentimentAnalyzer(config)\nresult = analyzer.run(\"samples/my_story.txt\")\n\n# Access results\nprint(f\"Found {len(result.crux.peaks)} emotional peaks\")\nprint(result.sentiment_table.head())\n```\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":15,"oldLines":11,"newStart":15,"newLines":19,"lines":[" "," ### Key Features"," ","+✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)","+","+✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)","+","+✅ **Master File Accumulation**: Single CSV with all intermediate results","+","+✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate","+"," ✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)"," "," ✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging"," ","-✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments (NEW)","+✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments"," "," ✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms"," "]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"291d5c53-904c-4595-91d9-337f74241ce3","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015yabqXtQwt42wrzSMwXza7","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n    95→# View incoherence analysis\n    96→cat incoherence/my_analysis_incoherence_report.txt\n    97→```\n    98→\n    99→## Usage\n   100→\n   101→### CLI Usage\n   102→\n   103→```bash\n   104→sentimentarcs samples/my_story.txt -c config.yaml\n   105→```\n   106→\n   107→### Programmatic API\n   108→\n   109→```python\n   110→from sentimentarcs import SentimentPipeline, ArcConfig\n   111→\n   112→config = ArcConfig.from_yaml(\"config.yaml\")\n   113→\n   114→result = (SentimentPipeline(config)\n   115→    .load_text(\"novel.txt\")\n   116→    .preprocess()\n   117→    .segment()\n   118→    .validate()\n   119→    .analyze_sentiment()\n   120→    .smooth()\n   121→    .normalize()\n   122→    .plot_ensemble()\n   123→    .analyze_incoherence()\n   124→    .detect_crux()\n   125→    .extract_crux()  # NEW Stage 10\n   126→    .plot_crux()\n   127→    .report()\n   128→    .execute())\n   129→\n   130→# Access results\n   131→master_df = result.get_master_dataframe()\n   132→crux_points = result.get_crux_points()\n   133→```\n   134→\n   135→See [API Quick Start](docs/doc_api-quick-start.md) for details.\n   136→\n   137→---\n   138→\n   139→## Documentation"}]},"uuid":"8292aa08-a7d1-496d-bddc-6ba2b3b9eabb","timestamp":"2025-11-11T15:11:42.999Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"### Python API\n\n```python\nfrom sentimentarcs.config import ArcConfig\nfrom sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer\n\n# Load configuration\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\n# Run analysis\nanalyzer = SentimentAnalyzer(config)\nresult = analyzer.run(\"samples/my_story.txt\")\n\n# Access results\nprint(f\"Found {len(result.crux.peaks)} emotional peaks\")\nprint(result.sentiment_table.head())\n```","newString":"## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n### Python API\n\n```python\nfrom sentimentarcs.config import ArcConfig\nfrom sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer\n\n# Load configuration\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\n# Run analysis\nanalyzer = SentimentAnalyzer(config)\nresult = analyzer.run(\"samples/my_story.txt\")\n\n# Access results\nprint(f\"Found {len(result.crux.peaks)} emotional peaks\")\nprint(result.sentiment_table.head())\n```\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":96,"oldLines":24,"newStart":96,"newLines":44,"lines":[" cat incoherence/my_analysis_incoherence_report.txt"," ```"," ","-### Python API","+## Usage"," ","+### CLI Usage","+","+```bash","+sentimentarcs samples/my_story.txt -c config.yaml","+```","+","+### Programmatic API","+"," ```python","-from sentimentarcs.config import ArcConfig","-from sentimentarcs.core.sentiment_analyzer import SentimentAnalyzer","+from sentimentarcs import SentimentPipeline, ArcConfig"," ","-# Load configuration"," config = ArcConfig.from_yaml(\"config.yaml\")"," ","-# Run analysis","-analyzer = SentimentAnalyzer(config)","-result = analyzer.run(\"samples/my_story.txt\")","+result = (SentimentPipeline(config)","+    .load_text(\"novel.txt\")","+    .preprocess()","+    .segment()","+    .validate()","+    .analyze_sentiment()","+    .smooth()","+    .normalize()","+    .plot_ensemble()","+    .analyze_incoherence()","+    .detect_crux()","+    .extract_crux()  # NEW Stage 10","+    .plot_crux()","+    .report()","+    .execute())"," "," # Access results","-print(f\"Found {len(result.crux.peaks)} emotional peaks\")","-print(result.sentiment_table.head())","+master_df = result.get_master_dataframe()","+crux_points = result.get_crux_points()"," ```"," ","+See [API Quick Start](docs/doc_api-quick-start.md) for details.","+"," ---"," "," ## Documentation"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"8292aa08-a7d1-496d-bddc-6ba2b3b9eabb","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Bfqjg5MKtBxHqziTDUt7Wy","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   135→See [API Quick Start](docs/doc_api-quick-start.md) for details.\n   136→\n   137→---\n   138→\n   139→## Documentation\n   140→\n   141→| Document | Description |\n   142→|----------|-------------|\n   143→| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n   144→| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n   145→| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n   146→| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n   147→| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n   148→| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n   149→| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n   150→| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n   151→\n   152→---\n   153→\n   154→## Features in Detail"}]},"uuid":"c47d3077-1d73-45a2-bff4-e3bd4699098e","timestamp":"2025-11-11T15:11:44.013Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |","newString":"## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |\n| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":140,"oldLines":9,"newStart":140,"newLines":14,"lines":[" "," | Document | Description |"," |----------|-------------|","-| **[User Guide](docs/doc_user-guide.md)** | Comprehensive guide for installation, configuration, and analysis |","-| **[Technical Specification](docs/doc_tech-spec.md)** | Detailed architecture and API reference for developers |","-| **[Testing Guide](docs/TESTING.md)** | Test structure, running tests, and adding new tests |","+| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |","+| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |","+| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |","+| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |","+| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |","+| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |","+| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |","+| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |"," "," ---"," "]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"c47d3077-1d73-45a2-bff4-e3bd4699098e","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017LEkHr34oM6ZALN7qGcVWK","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   261→```\n   262→\n   263→---\n   264→\n   265→## Pipeline Stages\n   266→\n   267→SentimentArcs follows a 12-stage pipeline:\n   268→\n   269→1. **Preprocess**: Load and clean text\n   270→2. **Segment**: Split into sentences/paragraphs\n   271→3. **Validate**: Remove invalid segments\n   272→4. **Sentiment Analysis**: Run enabled models sequentially\n   273→5. **Smoothing**: Apply moving average smoothing\n   274→6. **Normalization**: Normalize to [-1, 1] range\n   275→7. **Ensemble Plot**: Generate multi-model overlay\n   276→8. **Incoherence Analysis**: Compute model disagreement metrics\n   277→9. **Crux Detection**: Identify emotional peaks/valleys\n   278→10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n   279→11. **Crux Plot**: Generate crux visualization\n   280→12. **Report Generation**: Create analysis reports\n   281→\n   282→See [Technical Specification](docs/doc_tech-spec.md) for details.\n   283→\n   284→---\n   285→\n   286→## Model Selection Guide"}]},"uuid":"33055131-3eb8-4abc-9b21-2eb66a6dd529","timestamp":"2025-11-11T15:11:45.033Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports","newString":"## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details.","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows an 8-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n6.5. **Ensemble Plot**: Generate multi-model overlay\n**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)\n7. **Crux Detection**: Identify emotional peaks/valleys\n8. **Report Generation**: Create plots and markdown reports\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":264,"oldLines":7,"newStart":264,"newLines":7,"lines":[" "," ## Pipeline Stages"," ","-SentimentArcs follows an 8-stage pipeline:","+SentimentArcs follows a 12-stage pipeline:"," "," 1. **Preprocess**: Load and clean text"," 2. **Segment**: Split into sentences/paragraphs"]},{"oldStart":272,"oldLines":11,"newStart":272,"newLines":15,"lines":[" 4. **Sentiment Analysis**: Run enabled models sequentially"," 5. **Smoothing**: Apply moving average smoothing"," 6. **Normalization**: Normalize to [-1, 1] range","-6.5. **Ensemble Plot**: Generate multi-model overlay","-**6.75. Incoherence Analysis**: Compute model disagreement metrics (NEW)","-7. **Crux Detection**: Identify emotional peaks/valleys","-8. **Report Generation**: Create plots and markdown reports","+7. **Ensemble Plot**: Generate multi-model overlay","+8. **Incoherence Analysis**: Compute model disagreement metrics","+9. **Crux Detection**: Identify emotional peaks/valleys","+10. **Crux Context Extraction**: Extract text context around crux points (NEW)","+11. **Crux Plot**: Generate crux visualization","+12. **Report Generation**: Create analysis reports"," ","+See [Technical Specification](docs/doc_tech-spec.md) for details.","+"," ---"," "," ## Model Selection Guide"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"33055131-3eb8-4abc-9b21-2eb66a6dd529","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01V2Y65aePHV8rcgvk7S4z54","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   236→- **Peaks**: Moments of highest emotional intensity\n   237→- **Valleys**: Moments of lowest emotional intensity\n   238→- **Context Windows**: Extract surrounding text for analysis\n   239→\n   240→### 6. Rich Output Files\n   241→\n   242→Each analysis generates standardized output structure:\n   243→\n   244→```\n   245→outputs/{text_name}/\n   246→├── datafiles/                     # Shared workspace (NEW)\n   247→│   ├── {root}_clean.txt\n   248→│   ├── {root}_segments.csv\n   249→│   ├── {root}_sentiments.csv\n   250→│   ├── {root}_crux-points.csv\n   251→│   ├── {root}_crux-text.csv      # NEW Stage 10\n   252→│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n   253→├── plots/\n   254→│   ├── {root}_plot-ensemble.png\n   255→│   └── {root}_plot-crux.png\n   256→├── reports/\n   257→│   └── {root}_report.md\n   258→└── logs/\n   259→    └── {root}_{timestamp}.log\n   260→```\n   261→\n   262→See [User Guide](docs/doc_user-guide.md#output-files) for details.\n   263→\n   264→---\n   265→\n   266→## Pipeline Stages"}]},"uuid":"eee00001-e74e-4527-b7dc-6bfc975710e7","timestamp":"2025-11-11T15:11:46.051Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```","newString":"### 6. Rich Output Files\n\nEach analysis generates standardized output structure:\n\n```\noutputs/{text_name}/\n├── datafiles/                     # Shared workspace (NEW)\n│   ├── {root}_clean.txt\n│   ├── {root}_segments.csv\n│   ├── {root}_sentiments.csv\n│   ├── {root}_crux-points.csv\n│   ├── {root}_crux-text.csv      # NEW Stage 10\n│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n├── plots/\n│   ├── {root}_plot-ensemble.png\n│   └── {root}_plot-crux.png\n├── reports/\n│   └── {root}_report.md\n└── logs/\n    └── {root}_{timestamp}.log\n```\n\nSee [User Guide](docs/doc_user-guide.md#output-files) for details.","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates:\n\n```\noutputs/{text_name}/\n├── segments/               # Segmented text\n│   ├── {project}_segments_{models}.csv\n│   └── {project}_cleaned_{models}.txt\n├── sentiment/              # Sentiment analysis results\n│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence\n├── incoherence/            # Model disagreement analysis (NEW)\n│   ├── {project}_incoherence.csv\n│   └── {project}_incoherence_report.txt\n├── plots/                  # Visualizations\n│   ├── {project}_arc_{models}.png           # Main sentiment arc\n│   └── {project}_ensemble_{models}.png      # Multi-model overlay\n├── reports/                # Analysis reports\n│   └── {project}_report_{models}.md\n└── logs/                   # Detailed logs\n    └── sentimentarcs_{models}_{timestamp}.log\n```\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details.\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":239,"oldLines":27,"newStart":239,"newLines":28,"lines":[" "," ### 6. Rich Output Files"," ","-Each analysis generates:","+Each analysis generates standardized output structure:"," "," ```"," outputs/{text_name}/","-├── segments/               # Segmented text","-│   ├── {project}_segments_{models}.csv","-│   └── {project}_cleaned_{models}.txt","-├── sentiment/              # Sentiment analysis results","-│   └── {project}_sentiment_{models}.csv  ← Main results with incoherence","-├── incoherence/            # Model disagreement analysis (NEW)","-│   ├── {project}_incoherence.csv","-│   └── {project}_incoherence_report.txt","-├── plots/                  # Visualizations","-│   ├── {project}_arc_{models}.png           # Main sentiment arc","-│   └── {project}_ensemble_{models}.png      # Multi-model overlay","-├── reports/                # Analysis reports","-│   └── {project}_report_{models}.md","-└── logs/                   # Detailed logs","-    └── sentimentarcs_{models}_{timestamp}.log","+├── datafiles/                     # Shared workspace (NEW)","+│   ├── {root}_clean.txt","+│   ├── {root}_segments.csv","+│   ├── {root}_sentiments.csv","+│   ├── {root}_crux-points.csv","+│   ├── {root}_crux-text.csv      # NEW Stage 10","+│   └── {root}_sentimentarcs.csv  # Master file (NEW)","+├── plots/","+│   ├── {root}_plot-ensemble.png","+│   └── {root}_plot-crux.png","+├── reports/","+│   └── {root}_report.md","+└── logs/","+    └── {root}_{timestamp}.log"," ```"," ","+See [User Guide](docs/doc_user-guide.md#output-files) for details.","+"," ---"," "," ## Pipeline Stages"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"eee00001-e74e-4527-b7dc-6bfc975710e7","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Tw6f5eWLhSg94ycPFmhnhN","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   413→```\n   414→\n   415→---\n   416→\n   417→## Testing\n   418→\n   419→```bash\n   420→# Run all tests (CLI + API)\n   421→python tests/test_regression_harness.py\n   422→\n   423→# Run only API tests\n   424→python tests/test_regression_harness.py --api-only\n   425→\n   426→# Run with pytest\n   427→pytest tests/\n   428→\n   429→# Run unit tests only\n   430→pytest tests/unit/\n   431→\n   432→# Run integration tests only\n   433→pytest tests/integration/\n   434→\n   435→# Exclude API tests (no credentials needed)\n   436→pytest tests/ -k \"not api\"\n   437→\n   438→# With coverage\n   439→pytest --cov=sentimentarcs --cov-report=html tests/\n   440→```\n   441→\n   442→See [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation.\n   443→\n   444→---\n   445→\n   446→## Examples"}]},"uuid":"4615d732-a577-47f1-8c14-669eb59c26fb","timestamp":"2025-11-11T15:11:47.066Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.","newString":"## Testing\n\n```bash\n# Run all tests (CLI + API)\npython tests/test_regression_harness.py\n\n# Run only API tests\npython tests/test_regression_harness.py --api-only\n\n# Run with pytest\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation.","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates standardized output structure:\n\n```\noutputs/{text_name}/\n├── datafiles/                     # Shared workspace (NEW)\n│   ├── {root}_clean.txt\n│   ├── {root}_segments.csv\n│   ├── {root}_sentiments.csv\n│   ├── {root}_crux-points.csv\n│   ├── {root}_crux-text.csv      # NEW Stage 10\n│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n├── plots/\n│   ├── {root}_plot-ensemble.png\n│   └── {root}_plot-crux.png\n├── reports/\n│   └── {root}_report.md\n└── logs/\n    └── {root}_{timestamp}.log\n```\n\nSee [User Guide](docs/doc_user-guide.md#output-files) for details.\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details.\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":417,"oldLines":7,"newStart":417,"newLines":13,"lines":[" ## Testing"," "," ```bash","-# Run all tests","+# Run all tests (CLI + API)","+python tests/test_regression_harness.py","+","+# Run only API tests","+python tests/test_regression_harness.py --api-only","+","+# Run with pytest"," pytest tests/"," "," # Run unit tests only"]},{"oldStart":433,"oldLines":7,"newStart":439,"newLines":7,"lines":[" pytest --cov=sentimentarcs --cov-report=html tests/"," ```"," ","-See [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.","+See [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation."," "," ---"," "]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"4615d732-a577-47f1-8c14-669eb59c26fb","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JEKWRYPtrDjs1rygRg8A5G","type":"tool_result","content":"The file /Users/jonc/code/sentimentarcs/README.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   584→MIT License - see [LICENSE](LICENSE) file for details.\n   585→\n   586→---\n   587→\n   588→## Changelog\n   589→\n   590→### Version 0.2.0 (November 2025)\n   591→\n   592→**New Features**:\n   593→- ✨ NEW: Complete programmatic API with fluent interface\n   594→- ✨ NEW: Stage 10 crux context extraction\n   595→- ✨ NEW: Master file accumulation system\n   596→- ✨ NEW: 66 API tests (31 unit + 35 integration)\n   597→- ✨ NEW: Master regression test harness\n   598→- ✨ NEW: Comprehensive documentation suite (8+ docs)\n   599→- ✨ NEW: Standardized output directory structure\n   600→\n   601→**Documentation**:\n   602→- API Quick Start guide\n   603→- API Design specification\n   604→- API Usage guide with patterns\n   605→- API Implementation summary\n   606→- Enhanced Testing guide (91 tests)\n   607→- Roadmap for future development\n   608→\n   609→**Improvements**:\n   610→- Dual interface support (CLI + programmatic API)\n   611→- Unified master dataframe accumulation\n   612→- 100% test pass rate across all tests\n   613→- Enhanced crux context extraction\n   614→\n   615→### Version 0.1.0 (November 2025)\n   616→\n   617→**New Features**:\n   618→- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n   619→- ✨ Multi-model Ollama support with model switching\n   620→- ✨ OpenAI GPT-5-mini support with native API\n   621→- ✨ Ensemble averaging for crux detection\n   622→- ✨ Comprehensive test suite (29 tests)\n   623→\n   624→**Models Added**:\n   625→- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n   626→- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n   627→- Anthropic, Google, LM Studio API support\n   628→\n   629→**Improvements**:\n   630→- Better column ordering in output CSVs\n   631→- Progress tracking with time estimates\n   632→- Exponential backoff retry for API models\n   633→- Pydantic response validation\n   634→- Model warmup for Ollama\n   635→\n   636→**Documentation**:\n   637→- Comprehensive user guide\n   638→- Technical specification for developers\n   639→- Testing guide\n   640→\n   641→---\n   642→\n   643→## Support"}]},"uuid":"07dba554-9160-4ba0-bbd6-1d333f5289ea","timestamp":"2025-11-11T15:11:48.080Z","toolUseResult":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","oldString":"## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide","newString":"## Changelog\n\n### Version 0.2.0 (November 2025)\n\n**New Features**:\n- ✨ NEW: Complete programmatic API with fluent interface\n- ✨ NEW: Stage 10 crux context extraction\n- ✨ NEW: Master file accumulation system\n- ✨ NEW: 66 API tests (31 unit + 35 integration)\n- ✨ NEW: Master regression test harness\n- ✨ NEW: Comprehensive documentation suite (8+ docs)\n- ✨ NEW: Standardized output directory structure\n\n**Documentation**:\n- API Quick Start guide\n- API Design specification\n- API Usage guide with patterns\n- API Implementation summary\n- Enhanced Testing guide (91 tests)\n- Roadmap for future development\n\n**Improvements**:\n- Dual interface support (CLI + programmatic API)\n- Unified master dataframe accumulation\n- 100% test pass rate across all tests\n- Enhanced crux context extraction\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide","originalFile":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates standardized output structure:\n\n```\noutputs/{text_name}/\n├── datafiles/                     # Shared workspace (NEW)\n│   ├── {root}_clean.txt\n│   ├── {root}_segments.csv\n│   ├── {root}_sentiments.csv\n│   ├── {root}_crux-points.csv\n│   ├── {root}_crux-text.csv      # NEW Stage 10\n│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n├── plots/\n│   ├── {root}_plot-ensemble.png\n│   └── {root}_plot-crux.png\n├── reports/\n│   └── {root}_report.md\n└── logs/\n    └── {root}_{timestamp}.log\n```\n\nSee [User Guide](docs/doc_user-guide.md#output-files) for details.\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details.\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests (CLI + API)\npython tests/test_regression_harness.py\n\n# Run only API tests\npython tests/test_regression_harness.py --api-only\n\n# Run with pytest\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","structuredPatch":[{"oldStart":587,"oldLines":6,"newStart":587,"newLines":31,"lines":[" "," ## Changelog"," ","+### Version 0.2.0 (November 2025)","+","+**New Features**:","+- ✨ NEW: Complete programmatic API with fluent interface","+- ✨ NEW: Stage 10 crux context extraction","+- ✨ NEW: Master file accumulation system","+- ✨ NEW: 66 API tests (31 unit + 35 integration)","+- ✨ NEW: Master regression test harness","+- ✨ NEW: Comprehensive documentation suite (8+ docs)","+- ✨ NEW: Standardized output directory structure","+","+**Documentation**:","+- API Quick Start guide","+- API Design specification","+- API Usage guide with patterns","+- API Implementation summary","+- Enhanced Testing guide (91 tests)","+- Roadmap for future development","+","+**Improvements**:","+- Dual interface support (CLI + programmatic API)","+- Unified master dataframe accumulation","+- 100% test pass rate across all tests","+- Enhanced crux context extraction","+"," ### Version 0.1.0 (November 2025)"," "," **New Features**:"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"07dba554-9160-4ba0-bbd6-1d333f5289ea","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01D4wfdXntjyUyEUS2z1seYZ","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! I've successfully updated the README.md with all the requested changes. Let me verify the changes by reading a few key sections to ensure everything is correct:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7095,"cache_read_input_tokens":23816,"cache_creation":{"ephemeral_5m_input_tokens":7095,"ephemeral_1h_input_tokens":0},"output_tokens":391,"service_tier":"standard"}},"requestId":"req_011CV2KLDqiZhFT5CcM88UaP","type":"assistant","uuid":"55fab8c7-fee6-49b5-9709-815a1485c0c2","timestamp":"2025-11-11T15:11:51.786Z"}
{"parentUuid":"55fab8c7-fee6-49b5-9709-815a1485c0c2","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01D4wfdXntjyUyEUS2z1seYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VePiGe1aa4Tm1dFjQfHKHX","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","offset":16,"limit":25}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7095,"cache_read_input_tokens":23816,"cache_creation":{"ephemeral_5m_input_tokens":7095,"ephemeral_1h_input_tokens":0},"output_tokens":391,"service_tier":"standard"}},"requestId":"req_011CV2KLDqiZhFT5CcM88UaP","type":"assistant","uuid":"392d659d-8fc8-4820-99e0-b8682aaec301","timestamp":"2025-11-11T15:11:52.684Z"}
{"parentUuid":"392d659d-8fc8-4820-99e0-b8682aaec301","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01D4wfdXntjyUyEUS2z1seYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CPWwo9vgeDu7mRFj4A4bjK","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","offset":99,"limit":40}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7095,"cache_read_input_tokens":23816,"cache_creation":{"ephemeral_5m_input_tokens":7095,"ephemeral_1h_input_tokens":0},"output_tokens":391,"service_tier":"standard"}},"requestId":"req_011CV2KLDqiZhFT5CcM88UaP","type":"assistant","uuid":"b1a16e92-63c0-47c2-b96d-49f11e4a7abd","timestamp":"2025-11-11T15:11:53.438Z"}
{"parentUuid":"b1a16e92-63c0-47c2-b96d-49f11e4a7abd","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01D4wfdXntjyUyEUS2z1seYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011Bpuy24KHaV8h2AJgwGVho","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","offset":139,"limit":15}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7095,"cache_read_input_tokens":23816,"cache_creation":{"ephemeral_5m_input_tokens":7095,"ephemeral_1h_input_tokens":0},"output_tokens":391,"service_tier":"standard"}},"requestId":"req_011CV2KLDqiZhFT5CcM88UaP","type":"assistant","uuid":"693c7a3f-68f0-42e7-9509-8177ca30b6b0","timestamp":"2025-11-11T15:11:54.132Z"}
{"parentUuid":"693c7a3f-68f0-42e7-9509-8177ca30b6b0","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01D4wfdXntjyUyEUS2z1seYZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014VQ98W6v8NwXWEYEf4paBL","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md","offset":265,"limit":20}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":7095,"cache_read_input_tokens":23816,"cache_creation":{"ephemeral_5m_input_tokens":7095,"ephemeral_1h_input_tokens":0},"output_tokens":391,"service_tier":"standard"}},"requestId":"req_011CV2KLDqiZhFT5CcM88UaP","type":"assistant","uuid":"26ad5122-65c3-4178-926e-abfcf4a16c32","timestamp":"2025-11-11T15:11:54.702Z"}
{"parentUuid":"26ad5122-65c3-4178-926e-abfcf4a16c32","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VePiGe1aa4Tm1dFjQfHKHX","type":"tool_result","content":"    16→### Key Features\n    17→\n    18→✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n    19→\n    20→✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n    21→\n    22→✅ **Master File Accumulation**: Single CSV with all intermediate results\n    23→\n    24→✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n    25→\n    26→✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n    27→\n    28→✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n    29→\n    30→✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n    31→\n    32→✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n    33→\n    34→✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n    35→\n    36→✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n    37→\n    38→✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n    39→\n    40→---\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f85ba9e1-e4a4-4ea3-beaa-2807aca30061","timestamp":"2025-11-11T15:11:54.720Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","content":"### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---","numLines":25,"startLine":16,"totalLines":661}}}
{"parentUuid":"f85ba9e1-e4a4-4ea3-beaa-2807aca30061","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CPWwo9vgeDu7mRFj4A4bjK","type":"tool_result","content":"    99→## Usage\n   100→\n   101→### CLI Usage\n   102→\n   103→```bash\n   104→sentimentarcs samples/my_story.txt -c config.yaml\n   105→```\n   106→\n   107→### Programmatic API\n   108→\n   109→```python\n   110→from sentimentarcs import SentimentPipeline, ArcConfig\n   111→\n   112→config = ArcConfig.from_yaml(\"config.yaml\")\n   113→\n   114→result = (SentimentPipeline(config)\n   115→    .load_text(\"novel.txt\")\n   116→    .preprocess()\n   117→    .segment()\n   118→    .validate()\n   119→    .analyze_sentiment()\n   120→    .smooth()\n   121→    .normalize()\n   122→    .plot_ensemble()\n   123→    .analyze_incoherence()\n   124→    .detect_crux()\n   125→    .extract_crux()  # NEW Stage 10\n   126→    .plot_crux()\n   127→    .report()\n   128→    .execute())\n   129→\n   130→# Access results\n   131→master_df = result.get_master_dataframe()\n   132→crux_points = result.get_crux_points()\n   133→```\n   134→\n   135→See [API Quick Start](docs/doc_api-quick-start.md) for details.\n   136→\n   137→---\n   138→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"36468a21-b243-4121-a97c-0b7e4c65d774","timestamp":"2025-11-11T15:11:54.721Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","content":"## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n","numLines":40,"startLine":99,"totalLines":661}}}
{"parentUuid":"36468a21-b243-4121-a97c-0b7e4c65d774","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011Bpuy24KHaV8h2AJgwGVho","type":"tool_result","content":"   139→## Documentation\n   140→\n   141→| Document | Description |\n   142→|----------|-------------|\n   143→| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n   144→| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n   145→| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n   146→| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n   147→| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n   148→| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n   149→| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n   150→| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n   151→\n   152→---\n   153→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"98edfb06-a318-4226-86c5-053dcc3dd4c4","timestamp":"2025-11-11T15:11:54.721Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","content":"## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n---\n","numLines":15,"startLine":139,"totalLines":661}}}
{"parentUuid":"98edfb06-a318-4226-86c5-053dcc3dd4c4","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014VQ98W6v8NwXWEYEf4paBL","type":"tool_result","content":"   265→\n   266→## Pipeline Stages\n   267→\n   268→SentimentArcs follows a 12-stage pipeline:\n   269→\n   270→1. **Preprocess**: Load and clean text\n   271→2. **Segment**: Split into sentences/paragraphs\n   272→3. **Validate**: Remove invalid segments\n   273→4. **Sentiment Analysis**: Run enabled models sequentially\n   274→5. **Smoothing**: Apply moving average smoothing\n   275→6. **Normalization**: Normalize to [-1, 1] range\n   276→7. **Ensemble Plot**: Generate multi-model overlay\n   277→8. **Incoherence Analysis**: Compute model disagreement metrics\n   278→9. **Crux Detection**: Identify emotional peaks/valleys\n   279→10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n   280→11. **Crux Plot**: Generate crux visualization\n   281→12. **Report Generation**: Create analysis reports\n   282→\n   283→See [Technical Specification](docs/doc_tech-spec.md) for details.\n   284→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"734aacd6-7a99-44d3-9bc8-692376ce69f9","timestamp":"2025-11-11T15:11:54.721Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","content":"\n## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details.\n","numLines":20,"startLine":265,"totalLines":661}}}
{"parentUuid":"734aacd6-7a99-44d3-9bc8-692376ce69f9","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"ba4842dd","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_01KNvJEPHuxCFRq5mYy4hvSS","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! All changes have been successfully applied. Let me create a summary of what was updated:\n\n## Summary of Changes to /Users/jonc/code/sentimentarcs/README.md\n\nI've successfully updated the README with all requested changes:\n\n### 1. **Key Features Section** (Lines 16-38)\nAdded NEW features at the top:\n- Dual Interfaces (CLI + programmatic API)\n- 12-Stage Pipeline with Stage 10\n- Master File Accumulation\n- Comprehensive Testing (91 tests, 100% pass rate)\n\n### 2. **Usage Section** (Lines 99-135)\nCompletely restructured with:\n- **CLI Usage**: Simple one-liner example\n- **Programmatic API**: Full fluent interface example showing all 12 stages including `.extract_crux()` (NEW Stage 10)\n- Cross-reference to API Quick Start guide\n\n### 3. **Documentation Section** (Lines 139-150)\nExpanded to 8 comprehensive docs:\n- Quick Start API\n- User Guide\n- Technical Specification\n- API Design\n- API Usage Guide\n- API Implementation\n- Testing Guide (91 tests)\n- Roadmap\n\n### 4. **Pipeline Stages Section** (Lines 266-282)\nUpdated from 8 stages to 12 stages:\n- Numbered 1-12 clearly\n- Added Stage 10: Crux Context Extraction (NEW)\n- Reorganized stages 7-12 logically\n- Added cross-reference to Technical Specification\n\n### 5. **Rich Output Files Section** (Lines 240-262)\nNEW standardized structure:\n- `datafiles/` shared workspace\n- `{root}_crux-text.csv` (Stage 10 output)\n- `{root}_sentimentarcs.csv` (Master file)\n- Simplified, consistent naming\n- Cross-reference to User Guide\n\n### 6. **Testing Section** (Lines 417-442)\nAdded NEW commands:\n- `python tests/test_regression_harness.py` (all tests)\n- `--api-only` flag option\n- Kept existing pytest commands\n- Cross-reference to Testing Guide\n\n### 7. **Changelog Section** (Lines 588-639)\nAdded Version 0.2.0 with:\n- 6 NEW features with ✨ emoji\n- Documentation list (8+ docs)\n- Improvements section\n- Kept Version 0.1.0 intact below\n\n### Style Maintained\n- All existing badges, metadata, and sections preserved\n- Friendly, accessible tone maintained\n- All existing examples kept (Quick Novel Analysis, Academic Research, etc.)\n- Cross-references added throughout\n- ✨ emoji used consistently for NEW features\n\nThe README now accurately reflects the complete dual-interface system with CLI and programmatic API, the full 12-stage pipeline, comprehensive testing coverage, and the complete documentation suite."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2235,"cache_read_input_tokens":30911,"cache_creation":{"ephemeral_5m_input_tokens":2235,"ephemeral_1h_input_tokens":0},"output_tokens":669,"service_tier":"standard"}},"requestId":"req_011CV2KLj9b9uPNFFs3M3WKw","type":"assistant","uuid":"afece9bf-1735-4868-b429-c79dba8495bd","timestamp":"2025-11-11T15:12:10.215Z"}
