{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":"I need you to create a comprehensive `/Users/jonc/code/sentimentarcs/docs/doc_roadmap.md` document for the SentimentArcs project.\n\n**Context:**\nSentimentArcs is a mature sentiment analysis library with:\n- Dual interfaces (CLI + programmatic API)\n- 12-stage pipeline with 9 sentiment models\n- Incoherence analysis for model disagreement\n- 91 tests with 100% pass rate\n- Comprehensive documentation (8+ docs)\n\n**Requirements:**\n\nThe roadmap should have THREE main sections:\n\n## Section A: Priority Scoring Framework\n\nCreate a weighted scoring system with these **8 independent factors**:\n\n1. **Impact** (weight: 25) - How many users benefit? How much value added?\n2. **Effort** (weight: 20) - Development time/complexity (inverse: lower effort = higher score)\n3. **Dependencies** (weight: 10) - External dependencies, prerequisite features (inverse)\n4. **Strategic Fit** (weight: 15) - Alignment with core mission (sentiment analysis research)\n5. **User Demand** (weight: 10) - Community requests, common pain points\n6. **Technical Debt** (weight: 5) - Reduces existing debt or prevents future debt\n7. **Innovation** (weight: 10) - Novel capabilities, competitive advantage\n8. **Maintainability** (weight: 5) - Long-term sustainability, code quality impact\n\n**For each factor:**\n- Explain the factor and why it matters\n- Describe the scoring scale (1-10)\n- Provide scoring guidelines with examples\n- Justify the weight assignment\n\n**Total score:** Sum of (factor_score × weight) / 100 = Priority Score (0-10 scale)\n\n## Section B: Enhancement Brainstorming\n\nBrainstorm **20-25 enhancements** across these categories:\n\n**Performance & Scalability:**\n- Parallel execution for independent stages\n- Caching layer for expensive operations\n- Streaming processing for large texts\n- Distributed computing support\n- GPU acceleration for neural models\n\n**User Experience:**\n- Progress callbacks and live updates\n- Interactive CLI with prompts\n- Web UI for pipeline building\n- Visual pipeline designer\n- Real-time preview mode\n\n**Analysis Capabilities:**\n- Emotion classification (Plutchik's wheel)\n- Character-level sentiment tracking\n- Topic modeling integration\n- Temporal sentiment dynamics\n- Comparative analysis (multiple texts)\n\n**Integration & Export:**\n- REST/GraphQL API server\n- Database integration (PostgreSQL, MongoDB)\n- Dashboard/visualization platform\n- Export to academic formats (LaTeX, BibTeX)\n- Integration with popular frameworks (spaCy, Hugging Face)\n\n**Testing & Quality:**\n- Performance benchmarking suite\n- Regression testing automation\n- Property-based testing\n- Fuzzing for robustness\n- Security scanning (SAST/DAST)\n\n**Documentation & Community:**\n- Interactive tutorials (Jupyter notebooks)\n- Video walkthrough series\n- Academic paper templates\n- Community plugin system\n- Translation to other languages\n\n**Infrastructure:**\n- Docker containerization\n- CI/CD pipeline improvements\n- Cloud deployment templates (AWS, GCP, Azure)\n- Kubernetes orchestration\n- Monitoring and alerting\n\n**Research & Innovation:**\n- Transformer fine-tuning for domain-specific sentiment\n- Explainable AI for sentiment decisions\n- Active learning for model improvement\n- Multi-modal sentiment (text + images)\n- Cross-lingual sentiment analysis\n\n## Section C: Ranked Priority List\n\nFor the **top 15 enhancements** (by priority score), provide:\n\n1. **Title and Category**\n2. **Priority Score** (calculated using framework from Section A)\n3. **Concise Description** (2-3 sentences)\n4. **Detailed Technical Specification** (implementation approach, architecture, key components)\n5. **Score Breakdown** (show how each of 8 factors contributed to total score)\n6. **Justification** (why this score? why prioritize this?)\n7. **Estimated Effort** (time range: 1-3 days, 1-2 weeks, 1-3 months)\n8. **Dependencies** (what must be completed first)\n9. **Risk Factors** (technical risks, blockers)\n10. **Success Metrics** (how to measure success)\n\n**Format example:**\n```markdown\n### 1. Parallel Stage Execution (Priority: 8.7/10)\n\n**Category:** Performance & Scalability\n\n**Description:** Enable parallel execution of independent pipeline stages to significantly reduce analysis time for large texts...\n\n**Technical Specification:**\n- Use Python multiprocessing/asyncio for concurrent execution\n- Identify stage dependency graph (DAG)\n- Implement task scheduler with dependency resolution\n- ...\n\n**Score Breakdown:**\n- Impact: 9/10 (weight 25) = 2.25\n- Effort: 6/10 (weight 20) = 1.20\n- ...\n- **Total: 8.70/10**\n\n**Justification:**\nThis enhancement scores highly because...\n\n**Estimated Effort:** 2-3 weeks\n\n**Dependencies:** None (can be implemented independently)\n\n**Risk Factors:**\n- Race conditions in shared state\n- Complexity in error handling across processes\n\n**Success Metrics:**\n- 40-60% reduction in execution time for multi-model analysis\n- No regression in result accuracy\n```\n\n**Important:**\n- Use realistic, thoughtful scoring (not all items should be 8-10)\n- Consider trade-offs (high impact often means high effort)\n- Be specific in technical specs (not just \"implement X\")\n- Justify scores with concrete reasoning\n- Include both quick wins (1-3 days) and major features (1-3 months)\n- Consider current state (what's already implemented)\n\n**Please create the complete roadmap document with all three sections.**"},"uuid":"bb09173d-2a44-4baf-bd15-ca98e8e1c5fa","timestamp":"2025-11-11T15:12:54.288Z"}
{"parentUuid":"bb09173d-2a44-4baf-bd15-ca98e8e1c5fa","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012cSo1XRuh6NfPxSFpLoBHU","type":"message","role":"assistant","content":[{"type":"text","text":"I'll create a comprehensive roadmap document for the SentimentArcs project. Let me first explore the codebase to understand the current state and architecture."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2414,"cache_read_input_tokens":14476,"cache_creation":{"ephemeral_5m_input_tokens":2414,"ephemeral_1h_input_tokens":0},"output_tokens":247,"service_tier":"standard"}},"requestId":"req_011CV2KR6sAS1Sfh9UCAWKWT","type":"assistant","uuid":"634ae6c2-0712-4dc0-9585-4a173ec2d63b","timestamp":"2025-11-11T15:12:57.457Z"}
{"parentUuid":"634ae6c2-0712-4dc0-9585-4a173ec2d63b","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012cSo1XRuh6NfPxSFpLoBHU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UhkwEs9LWZDfUUkb8s5M7H","name":"Bash","input":{"command":"find /Users/jonc/code/sentimentarcs -type f -name \"*.md\" | head -20","description":"Find existing documentation files"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2414,"cache_read_input_tokens":14476,"cache_creation":{"ephemeral_5m_input_tokens":2414,"ephemeral_1h_input_tokens":0},"output_tokens":247,"service_tier":"standard"}},"requestId":"req_011CV2KR6sAS1Sfh9UCAWKWT","type":"assistant","uuid":"ee1c0003-81b9-4334-a3a0-48deb1f28e5c","timestamp":"2025-11-11T15:12:58.401Z"}
{"parentUuid":"ee1c0003-81b9-4334-a3a0-48deb1f28e5c","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012cSo1XRuh6NfPxSFpLoBHU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NbmYRoxz4NEnh5SLyYYyGi","name":"Glob","input":{"pattern":"**/*.py","path":"/Users/jonc/code/sentimentarcs"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2414,"cache_read_input_tokens":14476,"cache_creation":{"ephemeral_5m_input_tokens":2414,"ephemeral_1h_input_tokens":0},"output_tokens":247,"service_tier":"standard"}},"requestId":"req_011CV2KR6sAS1Sfh9UCAWKWT","type":"assistant","uuid":"10e68df9-4918-4193-828e-a8679bcca819","timestamp":"2025-11-11T15:12:59.069Z"}
{"parentUuid":"10e68df9-4918-4193-828e-a8679bcca819","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_012cSo1XRuh6NfPxSFpLoBHU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01K9J3Xwh6z69nLj6UYQxJKo","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2414,"cache_read_input_tokens":14476,"cache_creation":{"ephemeral_5m_input_tokens":2414,"ephemeral_1h_input_tokens":0},"output_tokens":247,"service_tier":"standard"}},"requestId":"req_011CV2KR6sAS1Sfh9UCAWKWT","type":"assistant","uuid":"f1e9fd33-485d-4f6c-9593-352aca12abca","timestamp":"2025-11-11T15:12:59.381Z"}
{"parentUuid":"f1e9fd33-485d-4f6c-9593-352aca12abca","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01K9J3Xwh6z69nLj6UYQxJKo","type":"tool_result","content":"     1→# SentimentArcs\n     2→\n     3→**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n     4→\n     5→[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n     6→[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n     7→\n     8→By Jon Chun | November 2025\n     9→\n    10→---\n    11→\n    12→## Overview\n    13→\n    14→SentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n    15→\n    16→### Key Features\n    17→\n    18→✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n    19→\n    20→✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n    21→\n    22→✅ **Master File Accumulation**: Single CSV with all intermediate results\n    23→\n    24→✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n    25→\n    26→✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n    27→\n    28→✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n    29→\n    30→✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n    31→\n    32→✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n    33→\n    34→✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n    35→\n    36→✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n    37→\n    38→✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n    39→\n    40→---\n    41→\n    42→## Quick Start\n    43→\n    44→### Installation\n    45→\n    46→```bash\n    47→pip install sentimentarcs\n    48→\n    49→# Or from source\n    50→git clone https://github.com/yourorg/sentimentarcs.git\n    51→cd sentimentarcs\n    52→pip install -e .\n    53→```\n    54→\n    55→### Basic Usage\n    56→\n    57→**1. Create configuration file** (`config.yaml`):\n    58→\n    59→```yaml\n    60→project:\n    61→  name: \"my_analysis\"\n    62→\n    63→models:\n    64→  enabled_models:\n    65→    - \"vader\"      # Fast lexical model\n    66→    - \"textblob\"   # Fast lexical model\n    67→\n    68→incoherence:\n    69→  enabled: true    # Measure model disagreement\n    70→  algorithm: \"sd\"  # Standard deviation\n    71→\n    72→crux_detection:\n    73→  base_model_choice: [\"vader\", \"textblob\"]\n    74→  method: \"derivative_extrema\"\n    75→```\n    76→\n    77→**2. Run analysis**:\n    78→\n    79→```bash\n    80→sentimentarcs samples/my_story.txt -c config.yaml\n    81→```\n    82→\n    83→**3. View results**:\n    84→\n    85→```bash\n    86→# Navigate to outputs\n    87→cd outputs/my_story/\n    88→\n    89→# View main report\n    90→cat reports/my_analysis_report_vader-textblob.md\n    91→\n    92→# View plot\n    93→open plots/my_analysis_arc_vader-textblob.png\n    94→\n    95→# View incoherence analysis\n    96→cat incoherence/my_analysis_incoherence_report.txt\n    97→```\n    98→\n    99→## Usage\n   100→\n   101→### CLI Usage\n   102→\n   103→```bash\n   104→sentimentarcs samples/my_story.txt -c config.yaml\n   105→```\n   106→\n   107→### Programmatic API\n   108→\n   109→```python\n   110→from sentimentarcs import SentimentPipeline, ArcConfig\n   111→\n   112→config = ArcConfig.from_yaml(\"config.yaml\")\n   113→\n   114→result = (SentimentPipeline(config)\n   115→    .load_text(\"novel.txt\")\n   116→    .preprocess()\n   117→    .segment()\n   118→    .validate()\n   119→    .analyze_sentiment()\n   120→    .smooth()\n   121→    .normalize()\n   122→    .plot_ensemble()\n   123→    .analyze_incoherence()\n   124→    .detect_crux()\n   125→    .extract_crux()  # NEW Stage 10\n   126→    .plot_crux()\n   127→    .report()\n   128→    .execute())\n   129→\n   130→# Access results\n   131→master_df = result.get_master_dataframe()\n   132→crux_points = result.get_crux_points()\n   133→```\n   134→\n   135→See [API Quick Start](docs/doc_api-quick-start.md) for details.\n   136→\n   137→---\n   138→\n   139→## Documentation\n   140→\n   141→| Document | Description |\n   142→|----------|-------------|\n   143→| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n   144→| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n   145→| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n   146→| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n   147→| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n   148→| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n   149→| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n   150→| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n   151→\n   152→---\n   153→\n   154→## Features in Detail\n   155→\n   156→### 1. Multiple Sentiment Models\n   157→\n   158→**Local Models** (no API key required):\n   159→- **VADER**: Fast, rule-based lexical model (social media, informal text)\n   160→- **TextBlob**: Pattern-based lexical model (general purpose)\n   161→- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n   162→- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n   163→\n   164→**API Models** (cloud):\n   165→- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n   166→- **Anthropic**: Claude Sonnet (highly nuanced)\n   167→- **Google**: Gemini (multimodal capabilities)\n   168→\n   169→**Local API Models** (private, free):\n   170→- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n   171→- **LM Studio**: Local model hosting\n   172→\n   173→### 2. Ensemble Analysis\n   174→\n   175→Combine multiple models for robust predictions:\n   176→\n   177→```yaml\n   178→models:\n   179→  enabled_models:\n   180→    - \"vader\"\n   181→    - \"textblob\"\n   182→    - \"distilbert\"\n   183→\n   184→crux_detection:\n   185→  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n   186→  avg_method: \"median\"  # Options: mean, median, mode\n   187→```\n   188→\n   189→### 3. Incoherence Analysis (NEW)\n   190→\n   191→Measure model disagreement to identify ambiguous segments:\n   192→\n   193→```yaml\n   194→incoherence:\n   195→  enabled: true\n   196→  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n   197→  min_models: 2\n   198→```\n   199→\n   200→**Outputs**:\n   201→- `incoherence_{algorithm}` column in main sentiment CSV\n   202→- Separate incoherence CSV with focused analysis\n   203→- Markdown report with statistics and top disagreement segments\n   204→\n   205→**Interpretation**:\n   206→- **Low** (0.0-0.2): Strong model agreement\n   207→- **Medium** (0.2-0.5): Moderate disagreement\n   208→- **High** (0.5+): Strong disagreement (review recommended)\n   209→\n   210→### 4. Multi-Model Ollama Support\n   211→\n   212→Run multiple local models in ensemble:\n   213→\n   214→```yaml\n   215→models:\n   216→  enabled_models:\n   217→    - \"api_ollama_llama3.2\"\n   218→    - \"api_ollama_phi4\"\n   219→    - \"api_ollama_gemma3\"\n   220→\n   221→api_models:\n   222→  ollama:\n   223→    enabled: true\n   224→    base_url: \"http://localhost:11434\"\n   225→    model_switch_delay_sec: 3\n   226→    ollama_models:\n   227→      llama3.2: \"llama3.2:3b\"\n   228→      phi4: \"phi4-mini:3.8b\"\n   229→      gemma3: \"gemma3:4b\"\n   230→```\n   231→\n   232→### 5. Crux Detection\n   233→\n   234→Automatically identify emotional peaks and valleys:\n   235→\n   236→- **Peaks**: Moments of highest emotional intensity\n   237→- **Valleys**: Moments of lowest emotional intensity\n   238→- **Context Windows**: Extract surrounding text for analysis\n   239→\n   240→### 6. Rich Output Files\n   241→\n   242→Each analysis generates standardized output structure:\n   243→\n   244→```\n   245→outputs/{text_name}/\n   246→├── datafiles/                     # Shared workspace (NEW)\n   247→│   ├── {root}_clean.txt\n   248→│   ├── {root}_segments.csv\n   249→│   ├── {root}_sentiments.csv\n   250→│   ├── {root}_crux-points.csv\n   251→│   ├── {root}_crux-text.csv      # NEW Stage 10\n   252→│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n   253→├── plots/\n   254→│   ├── {root}_plot-ensemble.png\n   255→│   └── {root}_plot-crux.png\n   256→├── reports/\n   257→│   └── {root}_report.md\n   258→└── logs/\n   259→    └── {root}_{timestamp}.log\n   260→```\n   261→\n   262→See [User Guide](docs/doc_user-guide.md#output-files) for details.\n   263→\n   264→---\n   265→\n   266→## Pipeline Stages\n   267→\n   268→SentimentArcs follows a 12-stage pipeline:\n   269→\n   270→1. **Preprocess**: Load and clean text\n   271→2. **Segment**: Split into sentences/paragraphs\n   272→3. **Validate**: Remove invalid segments\n   273→4. **Sentiment Analysis**: Run enabled models sequentially\n   274→5. **Smoothing**: Apply moving average smoothing\n   275→6. **Normalization**: Normalize to [-1, 1] range\n   276→7. **Ensemble Plot**: Generate multi-model overlay\n   277→8. **Incoherence Analysis**: Compute model disagreement metrics\n   278→9. **Crux Detection**: Identify emotional peaks/valleys\n   279→10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n   280→11. **Crux Plot**: Generate crux visualization\n   281→12. **Report Generation**: Create analysis reports\n   282→\n   283→See [Technical Specification](docs/doc_tech-spec.md) for details.\n   284→\n   285→---\n   286→\n   287→## Model Selection Guide\n   288→\n   289→| Use Case | Recommended Models | Config |\n   290→|----------|-------------------|--------|\n   291→| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n   292→| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n   293→| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n   294→| **Private/Free** | Ollama (multiple models) | Local inference |\n   295→| **Ensemble Robust** | 3+ models + median | Best practice |\n   296→\n   297→---\n   298→\n   299→## Configuration\n   300→\n   301→### Minimal Configuration\n   302→\n   303→```yaml\n   304→project:\n   305→  name: \"my_analysis\"\n   306→\n   307→models:\n   308→  enabled_models:\n   309→    - \"vader\"\n   310→    - \"textblob\"\n   311→```\n   312→\n   313→### Advanced Configuration\n   314→\n   315→```yaml\n   316→project:\n   317→  name: \"comprehensive_analysis\"\n   318→\n   319→models:\n   320→  enabled_models:\n   321→    - \"vader\"\n   322→    - \"textblob\"\n   323→    - \"distilbert\"\n   324→    - \"api_ollama_llama3.2\"\n   325→    - \"api_ollama_phi4\"\n   326→\n   327→incoherence:\n   328→  enabled: true\n   329→  algorithm: \"sd\"\n   330→\n   331→crux_detection:\n   332→  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n   333→  avg_method: \"median\"\n   334→  min_prominence: 0.1\n   335→  context_window_segments: 10\n   336→\n   337→smoothing:\n   338→  enabled: true\n   339→  window_size: 5\n   340→```\n   341→\n   342→See [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n   343→\n   344→---\n   345→\n   346→## Requirements\n   347→\n   348→### Core Dependencies\n   349→\n   350→- Python 3.9+\n   351→- pandas >= 1.5\n   352→- numpy >= 1.24\n   353→- matplotlib >= 3.7\n   354→- scipy >= 1.10\n   355→- pyyaml >= 6.0\n   356→- pydantic >= 2.0\n   357→\n   358→### Optional Dependencies\n   359→\n   360→**For local sentiment models**:\n   361→- textblob >= 0.18\n   362→- vaderSentiment >= 3.3.2\n   363→\n   364→**For neural models**:\n   365→- transformers >= 4.0\n   366→- torch >= 2.0\n   367→\n   368→**For API models**:\n   369→- openai >= 1.0.0\n   370→- anthropic >= 0.20.0\n   371→- requests >= 2.31\n   372→\n   373→---\n   374→\n   375→## API Models Setup\n   376→\n   377→### Environment Variables\n   378→\n   379→Create `.env` file:\n   380→\n   381→```bash\n   382→OPENAI_API_KEY=\"sk-proj-...\"\n   383→ANTHROPIC_API_KEY=\"sk-ant-...\"\n   384→GEMINI_API_KEY=\"...\"\n   385→```\n   386→\n   387→### OpenAI (GPT-5, GPT-4o, GPT-4)\n   388→\n   389→```yaml\n   390→api_models:\n   391→  openai:\n   392→    enabled: true\n   393→    model_name: \"gpt-5-mini\"\n   394→    api_key_env: \"OPENAI_API_KEY\"\n   395→    batch_size: 20\n   396→```\n   397→\n   398→### Ollama (Local Inference)\n   399→\n   400→```bash\n   401→# Start Ollama server\n   402→ollama serve\n   403→\n   404→# Pull models\n   405→ollama pull llama3.2:3b\n   406→ollama pull phi4-mini:3.8b\n   407→\n   408→# Configure in config.yaml\n   409→models:\n   410→  enabled_models:\n   411→    - \"api_ollama_llama3.2\"\n   412→    - \"api_ollama_phi4\"\n   413→```\n   414→\n   415→---\n   416→\n   417→## Testing\n   418→\n   419→```bash\n   420→# Run all tests (CLI + API)\n   421→python tests/test_regression_harness.py\n   422→\n   423→# Run only API tests\n   424→python tests/test_regression_harness.py --api-only\n   425→\n   426→# Run with pytest\n   427→pytest tests/\n   428→\n   429→# Run unit tests only\n   430→pytest tests/unit/\n   431→\n   432→# Run integration tests only\n   433→pytest tests/integration/\n   434→\n   435→# Exclude API tests (no credentials needed)\n   436→pytest tests/ -k \"not api\"\n   437→\n   438→# With coverage\n   439→pytest --cov=sentimentarcs --cov-report=html tests/\n   440→```\n   441→\n   442→See [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation.\n   443→\n   444→---\n   445→\n   446→## Examples\n   447→\n   448→### Example 1: Quick Novel Analysis\n   449→\n   450→```bash\n   451→# Use fast lexical models\n   452→sentimentarcs samples/novel.txt -c config.yaml\n   453→```\n   454→\n   455→### Example 2: Academic Research\n   456→\n   457→```yaml\n   458→# config_research.yaml\n   459→models:\n   460→  enabled_models:\n   461→    - \"vader\"\n   462→    - \"textblob\"\n   463→    - \"distilbert\"\n   464→    - \"nlptown\"\n   465→\n   466→incoherence:\n   467→  enabled: true  # Track model agreement\n   468→\n   469→reproducibility:\n   470→  random_seed: 42\n   471→  deterministic: true\n   472→```\n   473→\n   474→### Example 3: Budget Analysis with Ollama\n   475→\n   476→```yaml\n   477→# config_ollama.yaml\n   478→models:\n   479→  enabled_models:\n   480→    - \"api_ollama_llama3.2\"\n   481→    - \"api_ollama_phi4\"\n   482→    - \"api_ollama_granite\"\n   483→\n   484→crux_detection:\n   485→  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n   486→  avg_method: \"median\"\n   487→```\n   488→\n   489→### Example 4: SOTA with OpenAI\n   490→\n   491→```yaml\n   492→# config_openai.yaml\n   493→models:\n   494→  enabled_models:\n   495→    - \"api_openai\"\n   496→\n   497→api_models:\n   498→  openai:\n   499→    enabled: true\n   500→    model_name: \"gpt-5-mini\"\n   501→    batch_size: 20\n   502→```\n   503→\n   504→---\n   505→\n   506→## Output Interpretation\n   507→\n   508→### Sentiment Scores\n   509→\n   510→- **-1.0**: Very negative (sadness, anger, fear)\n   511→- **-0.5**: Moderately negative (disappointment, worry)\n   512→- **0.0**: Neutral (factual, balanced)\n   513→- **+0.5**: Moderately positive (contentment, satisfaction)\n   514→- **+1.0**: Very positive (joy, excitement, triumph)\n   515→\n   516→### Incoherence Scores\n   517→\n   518→- **0.0-0.2**: Strong agreement (low ambiguity)\n   519→- **0.2-0.5**: Moderate disagreement (some ambiguity)\n   520→- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n   521→\n   522→### Crux Points\n   523→\n   524→- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n   525→- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n   526→- **Context**: Surrounding text provides narrative context\n   527→\n   528→---\n   529→\n   530→## Development\n   531→\n   532→### Project Structure\n   533→\n   534→```\n   535→sentimentarcs/\n   536→├── sentimentarcs/          # Main package\n   537→│   ├── core/              # Pipeline stages\n   538→│   ├── models/            # Sentiment models\n   539→│   ├── analysis/          # Analysis modules\n   540→│   ├── plotting/          # Visualization\n   541→│   ├── config.py          # Configuration\n   542→│   └── cli.py             # Command-line interface\n   543→├── tests/                  # Test suite\n   544→│   ├── unit/              # Unit tests\n   545→│   └── integration/       # Integration tests\n   546→├── docs/                   # Documentation\n   547→│   ├── doc_user-guide.md\n   548→│   ├── doc_tech-spec.md\n   549→│   └── TESTING.md\n   550→├── samples/                # Sample texts\n   551→├── config.yaml             # Default configuration\n   552→└── README.md               # This file\n   553→```\n   554→\n   555→### Contributing\n   556→\n   557→1. Fork the repository\n   558→2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n   559→3. Make your changes\n   560→4. Run tests (`pytest tests/`)\n   561→5. Commit your changes (`git commit -m 'Add amazing feature'`)\n   562→6. Push to branch (`git push origin feature/amazing-feature`)\n   563→7. Open a Pull Request\n   564→\n   565→---\n   566→\n   567→## Citation\n   568→\n   569→If you use SentimentArcs in your research, please cite:\n   570→\n   571→```bibtex\n   572→@software{sentimentarcs2025,\n   573→  author = {Chun, Jon},\n   574→  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n   575→  year = {2025},\n   576→  url = {https://github.com/yourorg/sentimentarcs}\n   577→}\n   578→```\n   579→\n   580→---\n   581→\n   582→## License\n   583→\n   584→MIT License - see [LICENSE](LICENSE) file for details.\n   585→\n   586→---\n   587→\n   588→## Changelog\n   589→\n   590→### Version 0.2.0 (November 2025)\n   591→\n   592→**New Features**:\n   593→- ✨ NEW: Complete programmatic API with fluent interface\n   594→- ✨ NEW: Stage 10 crux context extraction\n   595→- ✨ NEW: Master file accumulation system\n   596→- ✨ NEW: 66 API tests (31 unit + 35 integration)\n   597→- ✨ NEW: Master regression test harness\n   598→- ✨ NEW: Comprehensive documentation suite (8+ docs)\n   599→- ✨ NEW: Standardized output directory structure\n   600→\n   601→**Documentation**:\n   602→- API Quick Start guide\n   603→- API Design specification\n   604→- API Usage guide with patterns\n   605→- API Implementation summary\n   606→- Enhanced Testing guide (91 tests)\n   607→- Roadmap for future development\n   608→\n   609→**Improvements**:\n   610→- Dual interface support (CLI + programmatic API)\n   611→- Unified master dataframe accumulation\n   612→- 100% test pass rate across all tests\n   613→- Enhanced crux context extraction\n   614→\n   615→### Version 0.1.0 (November 2025)\n   616→\n   617→**New Features**:\n   618→- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n   619→- ✨ Multi-model Ollama support with model switching\n   620→- ✨ OpenAI GPT-5-mini support with native API\n   621→- ✨ Ensemble averaging for crux detection\n   622→- ✨ Comprehensive test suite (29 tests)\n   623→\n   624→**Models Added**:\n   625→- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n   626→- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n   627→- Anthropic, Google, LM Studio API support\n   628→\n   629→**Improvements**:\n   630→- Better column ordering in output CSVs\n   631→- Progress tracking with time estimates\n   632→- Exponential backoff retry for API models\n   633→- Pydantic response validation\n   634→- Model warmup for Ollama\n   635→\n   636→**Documentation**:\n   637→- Comprehensive user guide\n   638→- Technical specification for developers\n   639→- Testing guide\n   640→\n   641→---\n   642→\n   643→## Support\n   644→\n   645→- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n   646→- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n   647→- **Email**: jon.chun@example.com\n   648→\n   649→---\n   650→\n   651→## Acknowledgments\n   652→\n   653→- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n   654→- TextBlob: [textblob](https://textblob.readthedocs.io/)\n   655→- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n   656→- Ollama: [ollama](https://ollama.ai/)\n   657→\n   658→---\n   659→\n   660→**Built with ❤️ for computational literary analysis**\n   661→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5e29dba8-3297-4848-b8da-23d804ee07e4","timestamp":"2025-11-11T15:12:59.443Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/README.md","content":"# SentimentArcs\n\n**A comprehensive Python library for diachronic sentiment analysis of long-form text**\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nBy Jon Chun | November 2025\n\n---\n\n## Overview\n\nSentimentArcs analyzes **emotional trajectories** in long-form text (novels, articles, transcripts) by segmenting, analyzing, and visualizing sentiment arcs with multiple models and ensemble techniques.\n\n### Key Features\n\n✅ **Dual Interfaces**: Both CLI (SentimentAnalyzer) and programmatic API (SentimentPipeline)\n\n✅ **12-Stage Pipeline**: Complete workflow with NEW Stage 10 (crux context extraction)\n\n✅ **Master File Accumulation**: Single CSV with all intermediate results\n\n✅ **Comprehensive Testing**: 91 tests (47 unit + 44 integration) with 100% pass rate\n\n✅ **9 Sentiment Models**: Lexical (VADER, TextBlob), Neural (DistilBERT, NLPTown), and API-based (OpenAI, Anthropic, Google, Ollama, LM Studio)\n\n✅ **Ensemble Analysis**: Combine multiple models for robust predictions with ensemble averaging\n\n✅ **Incoherence Metrics**: Measure model disagreement to identify ambiguous segments\n\n✅ **Crux Detection**: Automatically identify emotional peaks and valleys with configurable algorithms\n\n✅ **Rich Outputs**: Publication-quality plots, comprehensive reports, detailed CSVs, and structured logs\n\n✅ **Configurable Pipeline**: YAML-based configuration for reproducible analysis\n\n✅ **Local & Cloud**: Support for both local inference (Ollama) and cloud APIs (OpenAI, Anthropic, Google)\n\n---\n\n## Quick Start\n\n### Installation\n\n```bash\npip install sentimentarcs\n\n# Or from source\ngit clone https://github.com/yourorg/sentimentarcs.git\ncd sentimentarcs\npip install -e .\n```\n\n### Basic Usage\n\n**1. Create configuration file** (`config.yaml`):\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"      # Fast lexical model\n    - \"textblob\"   # Fast lexical model\n\nincoherence:\n  enabled: true    # Measure model disagreement\n  algorithm: \"sd\"  # Standard deviation\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]\n  method: \"derivative_extrema\"\n```\n\n**2. Run analysis**:\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n**3. View results**:\n\n```bash\n# Navigate to outputs\ncd outputs/my_story/\n\n# View main report\ncat reports/my_analysis_report_vader-textblob.md\n\n# View plot\nopen plots/my_analysis_arc_vader-textblob.png\n\n# View incoherence analysis\ncat incoherence/my_analysis_incoherence_report.txt\n```\n\n## Usage\n\n### CLI Usage\n\n```bash\nsentimentarcs samples/my_story.txt -c config.yaml\n```\n\n### Programmatic API\n\n```python\nfrom sentimentarcs import SentimentPipeline, ArcConfig\n\nconfig = ArcConfig.from_yaml(\"config.yaml\")\n\nresult = (SentimentPipeline(config)\n    .load_text(\"novel.txt\")\n    .preprocess()\n    .segment()\n    .validate()\n    .analyze_sentiment()\n    .smooth()\n    .normalize()\n    .plot_ensemble()\n    .analyze_incoherence()\n    .detect_crux()\n    .extract_crux()  # NEW Stage 10\n    .plot_crux()\n    .report()\n    .execute())\n\n# Access results\nmaster_df = result.get_master_dataframe()\ncrux_points = result.get_crux_points()\n```\n\nSee [API Quick Start](docs/doc_api-quick-start.md) for details.\n\n---\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| **[Quick Start API](docs/doc_api-quick-start.md)** | 5-minute guide to programmatic API |\n| **[User Guide](docs/doc_user-guide.md)** | Comprehensive CLI usage guide |\n| **[Technical Specification](docs/doc_tech-spec.md)** | Architecture and implementation details |\n| **[API Design](docs/doc_api-design_v2.md)** | Complete programmatic API specification |\n| **[API Usage Guide](docs/doc_api-usage.md)** | Comprehensive API examples and patterns |\n| **[API Implementation](docs/doc_api-implementation-summary.md)** | Architecture and implementation summary |\n| **[Testing Guide](docs/doc_testing.md)** | Comprehensive testing documentation (91 tests) |\n| **[Roadmap](docs/doc_roadmap.md)** | Future enhancements and priorities |\n\n---\n\n## Features in Detail\n\n### 1. Multiple Sentiment Models\n\n**Local Models** (no API key required):\n- **VADER**: Fast, rule-based lexical model (social media, informal text)\n- **TextBlob**: Pattern-based lexical model (general purpose)\n- **DistilBERT**: Neural transformer model (formal text, nuanced sentiment)\n- **NLPTown**: Multilingual BERT model (100+ languages, 5-star ratings)\n\n**API Models** (cloud):\n- **OpenAI**: GPT-5-mini, GPT-4o, GPT-4 (state-of-the-art)\n- **Anthropic**: Claude Sonnet (highly nuanced)\n- **Google**: Gemini (multimodal capabilities)\n\n**Local API Models** (private, free):\n- **Ollama**: Local inference server (llama3.2, gemma3, granite, phi4, etc.)\n- **LM Studio**: Local model hosting\n\n### 2. Ensemble Analysis\n\nCombine multiple models for robust predictions:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"  # Options: mean, median, mode\n```\n\n### 3. Incoherence Analysis (NEW)\n\nMeasure model disagreement to identify ambiguous segments:\n\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"  # Options: sd (std dev), var (variance), mad (mean abs dev)\n  min_models: 2\n```\n\n**Outputs**:\n- `incoherence_{algorithm}` column in main sentiment CSV\n- Separate incoherence CSV with focused analysis\n- Markdown report with statistics and top disagreement segments\n\n**Interpretation**:\n- **Low** (0.0-0.2): Strong model agreement\n- **Medium** (0.2-0.5): Moderate disagreement\n- **High** (0.5+): Strong disagreement (review recommended)\n\n### 4. Multi-Model Ollama Support\n\nRun multiple local models in ensemble:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_gemma3\"\n\napi_models:\n  ollama:\n    enabled: true\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      llama3.2: \"llama3.2:3b\"\n      phi4: \"phi4-mini:3.8b\"\n      gemma3: \"gemma3:4b\"\n```\n\n### 5. Crux Detection\n\nAutomatically identify emotional peaks and valleys:\n\n- **Peaks**: Moments of highest emotional intensity\n- **Valleys**: Moments of lowest emotional intensity\n- **Context Windows**: Extract surrounding text for analysis\n\n### 6. Rich Output Files\n\nEach analysis generates standardized output structure:\n\n```\noutputs/{text_name}/\n├── datafiles/                     # Shared workspace (NEW)\n│   ├── {root}_clean.txt\n│   ├── {root}_segments.csv\n│   ├── {root}_sentiments.csv\n│   ├── {root}_crux-points.csv\n│   ├── {root}_crux-text.csv      # NEW Stage 10\n│   └── {root}_sentimentarcs.csv  # Master file (NEW)\n├── plots/\n│   ├── {root}_plot-ensemble.png\n│   └── {root}_plot-crux.png\n├── reports/\n│   └── {root}_report.md\n└── logs/\n    └── {root}_{timestamp}.log\n```\n\nSee [User Guide](docs/doc_user-guide.md#output-files) for details.\n\n---\n\n## Pipeline Stages\n\nSentimentArcs follows a 12-stage pipeline:\n\n1. **Preprocess**: Load and clean text\n2. **Segment**: Split into sentences/paragraphs\n3. **Validate**: Remove invalid segments\n4. **Sentiment Analysis**: Run enabled models sequentially\n5. **Smoothing**: Apply moving average smoothing\n6. **Normalization**: Normalize to [-1, 1] range\n7. **Ensemble Plot**: Generate multi-model overlay\n8. **Incoherence Analysis**: Compute model disagreement metrics\n9. **Crux Detection**: Identify emotional peaks/valleys\n10. **Crux Context Extraction**: Extract text context around crux points (NEW)\n11. **Crux Plot**: Generate crux visualization\n12. **Report Generation**: Create analysis reports\n\nSee [Technical Specification](docs/doc_tech-spec.md) for details.\n\n---\n\n## Model Selection Guide\n\n| Use Case | Recommended Models | Config |\n|----------|-------------------|--------|\n| **Quick Analysis** | VADER, TextBlob | Fast, no GPU |\n| **Accurate Analysis** | DistilBERT, NLPTown | Requires GPU |\n| **SOTA Results** | OpenAI GPT-5, Claude | Requires API key |\n| **Private/Free** | Ollama (multiple models) | Local inference |\n| **Ensemble Robust** | 3+ models + median | Best practice |\n\n---\n\n## Configuration\n\n### Minimal Configuration\n\n```yaml\nproject:\n  name: \"my_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n```\n\n### Advanced Configuration\n\n```yaml\nproject:\n  name: \"comprehensive_analysis\"\n\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\", \"distilbert\"]\n  avg_method: \"median\"\n  min_prominence: 0.1\n  context_window_segments: 10\n\nsmoothing:\n  enabled: true\n  window_size: 5\n```\n\nSee [docs/doc_user-guide.md](docs/doc_user-guide.md#configuration-guide) for complete configuration reference.\n\n---\n\n## Requirements\n\n### Core Dependencies\n\n- Python 3.9+\n- pandas >= 1.5\n- numpy >= 1.24\n- matplotlib >= 3.7\n- scipy >= 1.10\n- pyyaml >= 6.0\n- pydantic >= 2.0\n\n### Optional Dependencies\n\n**For local sentiment models**:\n- textblob >= 0.18\n- vaderSentiment >= 3.3.2\n\n**For neural models**:\n- transformers >= 4.0\n- torch >= 2.0\n\n**For API models**:\n- openai >= 1.0.0\n- anthropic >= 0.20.0\n- requests >= 2.31\n\n---\n\n## API Models Setup\n\n### Environment Variables\n\nCreate `.env` file:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\n### OpenAI (GPT-5, GPT-4o, GPT-4)\n\n```yaml\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    api_key_env: \"OPENAI_API_KEY\"\n    batch_size: 20\n```\n\n### Ollama (Local Inference)\n\n```bash\n# Start Ollama server\nollama serve\n\n# Pull models\nollama pull llama3.2:3b\nollama pull phi4-mini:3.8b\n\n# Configure in config.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n```\n\n---\n\n## Testing\n\n```bash\n# Run all tests (CLI + API)\npython tests/test_regression_harness.py\n\n# Run only API tests\npython tests/test_regression_harness.py --api-only\n\n# Run with pytest\npytest tests/\n\n# Run unit tests only\npytest tests/unit/\n\n# Run integration tests only\npytest tests/integration/\n\n# Exclude API tests (no credentials needed)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\nSee [Testing Guide](docs/doc_testing.md) for comprehensive testing documentation.\n\n---\n\n## Examples\n\n### Example 1: Quick Novel Analysis\n\n```bash\n# Use fast lexical models\nsentimentarcs samples/novel.txt -c config.yaml\n```\n\n### Example 2: Academic Research\n\n```yaml\n# config_research.yaml\nmodels:\n  enabled_models:\n    - \"vader\"\n    - \"textblob\"\n    - \"distilbert\"\n    - \"nlptown\"\n\nincoherence:\n  enabled: true  # Track model agreement\n\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\n### Example 3: Budget Analysis with Ollama\n\n```yaml\n# config_ollama.yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_llama3.2\"\n    - \"api_ollama_phi4\"\n    - \"api_ollama_granite\"\n\ncrux_detection:\n  base_model_choice: [\"api_ollama_llama3.2\", \"api_ollama_phi4\"]\n  avg_method: \"median\"\n```\n\n### Example 4: SOTA with OpenAI\n\n```yaml\n# config_openai.yaml\nmodels:\n  enabled_models:\n    - \"api_openai\"\n\napi_models:\n  openai:\n    enabled: true\n    model_name: \"gpt-5-mini\"\n    batch_size: 20\n```\n\n---\n\n## Output Interpretation\n\n### Sentiment Scores\n\n- **-1.0**: Very negative (sadness, anger, fear)\n- **-0.5**: Moderately negative (disappointment, worry)\n- **0.0**: Neutral (factual, balanced)\n- **+0.5**: Moderately positive (contentment, satisfaction)\n- **+1.0**: Very positive (joy, excitement, triumph)\n\n### Incoherence Scores\n\n- **0.0-0.2**: Strong agreement (low ambiguity)\n- **0.2-0.5**: Moderate disagreement (some ambiguity)\n- **0.5+**: Strong disagreement (high ambiguity, review recommended)\n\n### Crux Points\n\n- **Peaks**: Segments with highest normalized sentiment (emotional highs)\n- **Valleys**: Segments with lowest normalized sentiment (emotional lows)\n- **Context**: Surrounding text provides narrative context\n\n---\n\n## Development\n\n### Project Structure\n\n```\nsentimentarcs/\n├── sentimentarcs/          # Main package\n│   ├── core/              # Pipeline stages\n│   ├── models/            # Sentiment models\n│   ├── analysis/          # Analysis modules\n│   ├── plotting/          # Visualization\n│   ├── config.py          # Configuration\n│   └── cli.py             # Command-line interface\n├── tests/                  # Test suite\n│   ├── unit/              # Unit tests\n│   └── integration/       # Integration tests\n├── docs/                   # Documentation\n│   ├── doc_user-guide.md\n│   ├── doc_tech-spec.md\n│   └── TESTING.md\n├── samples/                # Sample texts\n├── config.yaml             # Default configuration\n└── README.md               # This file\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Make your changes\n4. Run tests (`pytest tests/`)\n5. Commit your changes (`git commit -m 'Add amazing feature'`)\n6. Push to branch (`git push origin feature/amazing-feature`)\n7. Open a Pull Request\n\n---\n\n## Citation\n\nIf you use SentimentArcs in your research, please cite:\n\n```bibtex\n@software{sentimentarcs2025,\n  author = {Chun, Jon},\n  title = {SentimentArcs: Diachronic Sentiment Analysis with Ensemble Models},\n  year = {2025},\n  url = {https://github.com/yourorg/sentimentarcs}\n}\n```\n\n---\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n---\n\n## Changelog\n\n### Version 0.2.0 (November 2025)\n\n**New Features**:\n- ✨ NEW: Complete programmatic API with fluent interface\n- ✨ NEW: Stage 10 crux context extraction\n- ✨ NEW: Master file accumulation system\n- ✨ NEW: 66 API tests (31 unit + 35 integration)\n- ✨ NEW: Master regression test harness\n- ✨ NEW: Comprehensive documentation suite (8+ docs)\n- ✨ NEW: Standardized output directory structure\n\n**Documentation**:\n- API Quick Start guide\n- API Design specification\n- API Usage guide with patterns\n- API Implementation summary\n- Enhanced Testing guide (91 tests)\n- Roadmap for future development\n\n**Improvements**:\n- Dual interface support (CLI + programmatic API)\n- Unified master dataframe accumulation\n- 100% test pass rate across all tests\n- Enhanced crux context extraction\n\n### Version 0.1.0 (November 2025)\n\n**New Features**:\n- ✨ Stage 6.75: Incoherence analysis for model disagreement metrics\n- ✨ Multi-model Ollama support with model switching\n- ✨ OpenAI GPT-5-mini support with native API\n- ✨ Ensemble averaging for crux detection\n- ✨ Comprehensive test suite (29 tests)\n\n**Models Added**:\n- OpenAI API (GPT-5-mini, GPT-4o, GPT-4, GPT-3.5)\n- Ollama API (llama3.2, phi4, gemma3, granite, and more)\n- Anthropic, Google, LM Studio API support\n\n**Improvements**:\n- Better column ordering in output CSVs\n- Progress tracking with time estimates\n- Exponential backoff retry for API models\n- Pydantic response validation\n- Model warmup for Ollama\n\n**Documentation**:\n- Comprehensive user guide\n- Technical specification for developers\n- Testing guide\n\n---\n\n## Support\n\n- **Issues**: [GitHub Issues](https://github.com/yourorg/sentimentarcs/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/yourorg/sentimentarcs/discussions)\n- **Email**: jon.chun@example.com\n\n---\n\n## Acknowledgments\n\n- VADER Sentiment: [hutto2014vader](https://github.com/cjhutto/vaderSentiment)\n- TextBlob: [textblob](https://textblob.readthedocs.io/)\n- HuggingFace Transformers: [transformers](https://huggingface.co/transformers/)\n- Ollama: [ollama](https://ollama.ai/)\n\n---\n\n**Built with ❤️ for computational literary analysis**\n","numLines":661,"startLine":1,"totalLines":661}}}
{"parentUuid":"5e29dba8-3297-4848-b8da-23d804ee07e4","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NbmYRoxz4NEnh5SLyYYyGi","type":"tool_result","content":"/Users/jonc/code/sentimentarcs/sentimentarcs/utils/reproducibility.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/utils/file_io.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/aggregator.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/smoothing.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/core/normalizer.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/core/text_processor.py\n/Users/jonc/code/sentimentarcs/setup.py\n/Users/jonc/code/sentimentarcs/version.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/utils/logging_utils.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/lmstudio_api_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/anthropic_api_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/google_api_model.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_text_processor.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_normalizer.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_smoothing.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_crux_detector.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_models_local.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_models_api.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/base.py\n/Users/jonc/code/sentimentarcs/tests/conftest.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/api_chat_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/__init__.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/utils/__init__.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/__init__.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/themes.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/dashboard.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/exceptions.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/textblob_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/nlptown_model.py\n/Users/jonc/code/sentimentarcs/tests/integration/test_cli.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/utils/output_manager.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/vader_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/distilbert_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/cli.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/crux_detector.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/report_generator.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/utils/logging_config.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/plotter.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/crux_detector_old.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/api_validation.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/openai_api_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/__init__.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/config.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/incoherence_detector.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/models/ollama_api_model.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/core/sentiment_analyzer.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_incoherence_detector.py\n/Users/jonc/code/sentimentarcs/tests/integration/test_incoherence_analysis.py\n/Users/jonc/code/sentimentarcs/tests/integration/test_sentiment_analyzer.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/api/__init__.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/api/pipeline.py\n/Users/jonc/code/sentimentarcs/sentimentarcs/__init__.py\n/Users/jonc/code/sentimentarcs/examples/example_programmatic_api.py\n/Users/jonc/code/sentimentarcs/tests/unit/test_api_pipeline_unit.py\n/Users/jonc/code/sentimentarcs/tests/integration/test_api_pipeline_integration.py\n/Users/jonc/code/sentimentarcs/tests/test_regression_harness.py"}]},"uuid":"7b46e404-6e28-4922-9fa0-c7c65b7d152d","timestamp":"2025-11-11T15:12:59.460Z","toolUseResult":{"filenames":["/Users/jonc/code/sentimentarcs/sentimentarcs/utils/reproducibility.py","/Users/jonc/code/sentimentarcs/sentimentarcs/utils/file_io.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/aggregator.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/smoothing.py","/Users/jonc/code/sentimentarcs/sentimentarcs/core/normalizer.py","/Users/jonc/code/sentimentarcs/sentimentarcs/core/text_processor.py","/Users/jonc/code/sentimentarcs/setup.py","/Users/jonc/code/sentimentarcs/version.py","/Users/jonc/code/sentimentarcs/sentimentarcs/utils/logging_utils.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/lmstudio_api_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/anthropic_api_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/google_api_model.py","/Users/jonc/code/sentimentarcs/tests/unit/test_text_processor.py","/Users/jonc/code/sentimentarcs/tests/unit/test_normalizer.py","/Users/jonc/code/sentimentarcs/tests/unit/test_smoothing.py","/Users/jonc/code/sentimentarcs/tests/unit/test_crux_detector.py","/Users/jonc/code/sentimentarcs/tests/unit/test_models_local.py","/Users/jonc/code/sentimentarcs/tests/unit/test_models_api.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/base.py","/Users/jonc/code/sentimentarcs/tests/conftest.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/api_chat_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/__init__.py","/Users/jonc/code/sentimentarcs/sentimentarcs/utils/__init__.py","/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/__init__.py","/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/themes.py","/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/dashboard.py","/Users/jonc/code/sentimentarcs/sentimentarcs/exceptions.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/textblob_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/nlptown_model.py","/Users/jonc/code/sentimentarcs/tests/integration/test_cli.py","/Users/jonc/code/sentimentarcs/sentimentarcs/utils/output_manager.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/vader_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/distilbert_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/cli.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/crux_detector.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/report_generator.py","/Users/jonc/code/sentimentarcs/sentimentarcs/utils/logging_config.py","/Users/jonc/code/sentimentarcs/sentimentarcs/visualization/plotter.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/crux_detector_old.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/api_validation.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/openai_api_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/__init__.py","/Users/jonc/code/sentimentarcs/sentimentarcs/config.py","/Users/jonc/code/sentimentarcs/sentimentarcs/analysis/incoherence_detector.py","/Users/jonc/code/sentimentarcs/sentimentarcs/models/ollama_api_model.py","/Users/jonc/code/sentimentarcs/sentimentarcs/core/sentiment_analyzer.py","/Users/jonc/code/sentimentarcs/tests/unit/test_incoherence_detector.py","/Users/jonc/code/sentimentarcs/tests/integration/test_incoherence_analysis.py","/Users/jonc/code/sentimentarcs/tests/integration/test_sentiment_analyzer.py","/Users/jonc/code/sentimentarcs/sentimentarcs/api/__init__.py","/Users/jonc/code/sentimentarcs/sentimentarcs/api/pipeline.py","/Users/jonc/code/sentimentarcs/sentimentarcs/__init__.py","/Users/jonc/code/sentimentarcs/examples/example_programmatic_api.py","/Users/jonc/code/sentimentarcs/tests/unit/test_api_pipeline_unit.py","/Users/jonc/code/sentimentarcs/tests/integration/test_api_pipeline_integration.py","/Users/jonc/code/sentimentarcs/tests/test_regression_harness.py"],"durationMs":21,"numFiles":56,"truncated":false}}
{"parentUuid":"7b46e404-6e28-4922-9fa0-c7c65b7d152d","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UhkwEs9LWZDfUUkb8s5M7H","type":"tool_result","content":"/Users/jonc/code/sentimentarcs/.pytest_cache/README.md\n/Users/jonc/code/sentimentarcs/sentimentarcs/api/README.md\n/Users/jonc/code/sentimentarcs/docs/doc_tech-spec.md\n/Users/jonc/code/sentimentarcs/docs/API_DESIGN.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-implementation-summary.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-design-review.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-quick-start.md\n/Users/jonc/code/sentimentarcs/docs/doc_user-guide.md\n/Users/jonc/code/sentimentarcs/docs/doc_testing.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-design_v2.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-usage.md\n/Users/jonc/code/sentimentarcs/README.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_tdd_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/prompt_research_incoherence-algos.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_api_grok4_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/prompt_initial-project-spec_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_TECH_SPECmd_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/prompt_api-design_grok4_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_AGENTmd_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_tech-spec_api_grok4_20251110.md","is_error":false}]},"uuid":"0984c3a8-10f9-4467-9848-29c94034eac6","timestamp":"2025-11-11T15:12:59.865Z","toolUseResult":{"stdout":"/Users/jonc/code/sentimentarcs/.pytest_cache/README.md\n/Users/jonc/code/sentimentarcs/sentimentarcs/api/README.md\n/Users/jonc/code/sentimentarcs/docs/doc_tech-spec.md\n/Users/jonc/code/sentimentarcs/docs/API_DESIGN.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-implementation-summary.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-design-review.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-quick-start.md\n/Users/jonc/code/sentimentarcs/docs/doc_user-guide.md\n/Users/jonc/code/sentimentarcs/docs/doc_testing.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-design_v2.md\n/Users/jonc/code/sentimentarcs/docs/doc_api-usage.md\n/Users/jonc/code/sentimentarcs/README.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_tdd_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/prompt_research_incoherence-algos.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_api_grok4_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/prompt_initial-project-spec_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_TECH_SPECmd_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/prompt_api-design_grok4_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_AGENTmd_gpt5_20251110.md\n/Users/jonc/code/sentimentarcs/docs-dev/doc_tech-spec_api_grok4_20251110.md","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"0984c3a8-10f9-4467-9848-29c94034eac6","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_014nDKQ415bZhBwXcUWqTF3i","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me explore key architecture files to understand the implementation details:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8720,"cache_creation_input_tokens":820,"cache_read_input_tokens":16890,"cache_creation":{"ephemeral_5m_input_tokens":820,"ephemeral_1h_input_tokens":0},"output_tokens":240,"service_tier":"standard"}},"requestId":"req_011CV2KRWetgjco5SYhzmkZZ","type":"assistant","uuid":"ca67aaa6-bb50-4da9-b9d1-b82376b40353","timestamp":"2025-11-11T15:13:03.101Z"}
{"parentUuid":"ca67aaa6-bb50-4da9-b9d1-b82376b40353","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_014nDKQ415bZhBwXcUWqTF3i","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Dx5qQycnfShvaFcevZNoLj","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/docs/doc_tech-spec.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8720,"cache_creation_input_tokens":820,"cache_read_input_tokens":16890,"cache_creation":{"ephemeral_5m_input_tokens":820,"ephemeral_1h_input_tokens":0},"output_tokens":240,"service_tier":"standard"}},"requestId":"req_011CV2KRWetgjco5SYhzmkZZ","type":"assistant","uuid":"287021c4-e0ee-4e52-aa1c-87e89cb66486","timestamp":"2025-11-11T15:13:03.920Z"}
{"parentUuid":"287021c4-e0ee-4e52-aa1c-87e89cb66486","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_014nDKQ415bZhBwXcUWqTF3i","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013VyGRnyJVCxZsbLR4eqguH","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/sentimentarcs/core/sentiment_analyzer.py","limit":100}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8720,"cache_creation_input_tokens":820,"cache_read_input_tokens":16890,"cache_creation":{"ephemeral_5m_input_tokens":820,"ephemeral_1h_input_tokens":0},"output_tokens":240,"service_tier":"standard"}},"requestId":"req_011CV2KRWetgjco5SYhzmkZZ","type":"assistant","uuid":"665fa196-a0b1-40ce-821f-b78486217d20","timestamp":"2025-11-11T15:13:04.650Z"}
{"parentUuid":"665fa196-a0b1-40ce-821f-b78486217d20","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_014nDKQ415bZhBwXcUWqTF3i","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DxbXu2LmjMxfkzPSEQ9Ywe","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/sentimentarcs/api/pipeline.py","limit":100}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":8720,"cache_creation_input_tokens":820,"cache_read_input_tokens":16890,"cache_creation":{"ephemeral_5m_input_tokens":820,"ephemeral_1h_input_tokens":0},"output_tokens":240,"service_tier":"standard"}},"requestId":"req_011CV2KRWetgjco5SYhzmkZZ","type":"assistant","uuid":"266b32dc-348d-402a-bf39-3370a28bfa5c","timestamp":"2025-11-11T15:13:05.161Z"}
{"parentUuid":"266b32dc-348d-402a-bf39-3370a28bfa5c","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013VyGRnyJVCxZsbLR4eqguH","type":"tool_result","content":"     1→# sentimentarcs/core/sentiment_analyzer.py\n     2→\n     3→\"\"\"\n     4→High-level sentiment analysis pipeline orchestration.\n     5→\n     6→Stages\n     7→------\n     8→1. preprocess (clean)\n     9→2. segment\n    10→3. validate segmentation\n    11→4. get_sentiment\n    12→5. smooth\n    13→6. norm\n    14→6.5. ensemble plot (all models)\n    15→7. peak/valley crux segment_no detection\n    16→8. crux text window extraction + report/plots\n    17→\"\"\"\n    18→\n    19→from __future__ import annotations\n    20→\n    21→from dataclasses import dataclass\n    22→from pathlib import Path\n    23→from typing import Dict, Optional\n    24→\n    25→import pandas as pd\n    26→\n    27→from ..config import ArcConfig\n    28→from ..utils.file_io import load_text, save_text, save_dataframe\n    29→from ..utils.output_manager import OutputPaths, compute_output_paths\n    30→from ..utils.reproducibility import set_global_seed\n    31→from ..utils.logging_config import configure_logging\n    32→from .text_processor import SegmentationResult, run_text_pipeline\n    33→from .normalizer import normalize_dataframe\n    34→from ..models import create_model\n    35→from ..analysis.aggregator import aggregate_mean\n    36→from ..analysis.smoothing import smooth_series\n    37→from ..analysis.crux_detector import (\n    38→    CruxDetectionResult,\n    39→    detect_crux_points,\n    40→    write_crux_windows_text,\n    41→    write_crux_windows_csv,\n    42→)\n    43→from ..analysis.report_generator import ReportGenerator\n    44→from ..visualization.plotter import plot_single_model, plot_ensemble_models\n    45→\n    46→\n    47→\n    48→@dataclass\n    49→class SentimentAnalyzerResult:\n    50→    \"\"\"\n    51→    Container for the outputs of a full SentimentAnalyzer run.\n    52→\n    53→    Attributes\n    54→    ----------\n    55→    segments:\n    56→        SegmentationResult with cleaned text and valid/invalid segments.\n    57→    sentiment_table:\n    58→        DataFrame with per-segment sentiment columns.\n    59→    crux:\n    60→        CruxDetectionResult or None if crux detection was skipped.\n    61→    ensemble_plot_path:\n    62→        Path to the ensemble plot PNG showing all models, or None on failure.\n    63→    plot_path:\n    64→        Path to the main sentiment arc plot PNG, or None on failure.\n    65→    report_path:\n    66→        Path to the generated Markdown report, or None on failure.\n    67→    \"\"\"\n    68→\n    69→    segments: SegmentationResult\n    70→    sentiment_table: pd.DataFrame\n    71→    crux: Optional[CruxDetectionResult]\n    72→    ensemble_plot_path: Optional[Path]\n    73→    plot_path: Optional[Path]\n    74→    report_path: Optional[Path]\n    75→\n    76→\n    77→class SentimentAnalyzer:\n    78→    \"\"\"\n    79→    High-level orchestrator for the SentimentArcs pipeline.\n    80→\n    81→    Typical usage\n    82→    -------------\n    83→    >>> cfg = ArcConfig.from_yaml(\"config.yaml\")\n    84→    >>> analyzer = SentimentAnalyzer(cfg)\n    85→    >>> result = analyzer.run(\"samples/tiny_story_en.txt\")\n    86→    \"\"\"\n    87→\n    88→    def __init__(self, cfg: ArcConfig) -> None:\n    89→        self.cfg = cfg\n    90→\n    91→        # Reproducibility: seed Python + NumPy\n    92→        set_global_seed(cfg.reproducibility.random_seed)\n    93→\n    94→        # Output directories\n    95→        self.output_paths: OutputPaths = compute_output_paths(cfg)\n    96→\n    97→        # Compute base_label from crux_detection.base_model_choice early\n    98→        base_models = cfg.crux_detection.base_model_choice\n    99→        if isinstance(base_models, str):\n   100→            self._base_label = base_models\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"adc88958-cb4d-47e8-bcaf-5deffc8114b9","timestamp":"2025-11-11T15:13:05.179Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/sentimentarcs/core/sentiment_analyzer.py","content":"# sentimentarcs/core/sentiment_analyzer.py\n\n\"\"\"\nHigh-level sentiment analysis pipeline orchestration.\n\nStages\n------\n1. preprocess (clean)\n2. segment\n3. validate segmentation\n4. get_sentiment\n5. smooth\n6. norm\n6.5. ensemble plot (all models)\n7. peak/valley crux segment_no detection\n8. crux text window extraction + report/plots\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, Optional\n\nimport pandas as pd\n\nfrom ..config import ArcConfig\nfrom ..utils.file_io import load_text, save_text, save_dataframe\nfrom ..utils.output_manager import OutputPaths, compute_output_paths\nfrom ..utils.reproducibility import set_global_seed\nfrom ..utils.logging_config import configure_logging\nfrom .text_processor import SegmentationResult, run_text_pipeline\nfrom .normalizer import normalize_dataframe\nfrom ..models import create_model\nfrom ..analysis.aggregator import aggregate_mean\nfrom ..analysis.smoothing import smooth_series\nfrom ..analysis.crux_detector import (\n    CruxDetectionResult,\n    detect_crux_points,\n    write_crux_windows_text,\n    write_crux_windows_csv,\n)\nfrom ..analysis.report_generator import ReportGenerator\nfrom ..visualization.plotter import plot_single_model, plot_ensemble_models\n\n\n\n@dataclass\nclass SentimentAnalyzerResult:\n    \"\"\"\n    Container for the outputs of a full SentimentAnalyzer run.\n\n    Attributes\n    ----------\n    segments:\n        SegmentationResult with cleaned text and valid/invalid segments.\n    sentiment_table:\n        DataFrame with per-segment sentiment columns.\n    crux:\n        CruxDetectionResult or None if crux detection was skipped.\n    ensemble_plot_path:\n        Path to the ensemble plot PNG showing all models, or None on failure.\n    plot_path:\n        Path to the main sentiment arc plot PNG, or None on failure.\n    report_path:\n        Path to the generated Markdown report, or None on failure.\n    \"\"\"\n\n    segments: SegmentationResult\n    sentiment_table: pd.DataFrame\n    crux: Optional[CruxDetectionResult]\n    ensemble_plot_path: Optional[Path]\n    plot_path: Optional[Path]\n    report_path: Optional[Path]\n\n\nclass SentimentAnalyzer:\n    \"\"\"\n    High-level orchestrator for the SentimentArcs pipeline.\n\n    Typical usage\n    -------------\n    >>> cfg = ArcConfig.from_yaml(\"config.yaml\")\n    >>> analyzer = SentimentAnalyzer(cfg)\n    >>> result = analyzer.run(\"samples/tiny_story_en.txt\")\n    \"\"\"\n\n    def __init__(self, cfg: ArcConfig) -> None:\n        self.cfg = cfg\n\n        # Reproducibility: seed Python + NumPy\n        set_global_seed(cfg.reproducibility.random_seed)\n\n        # Output directories\n        self.output_paths: OutputPaths = compute_output_paths(cfg)\n\n        # Compute base_label from crux_detection.base_model_choice early\n        base_models = cfg.crux_detection.base_model_choice\n        if isinstance(base_models, str):\n            self._base_label = base_models","numLines":100,"startLine":1,"totalLines":800}}}
{"parentUuid":"adc88958-cb4d-47e8-bcaf-5deffc8114b9","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DxbXu2LmjMxfkzPSEQ9Ywe","type":"tool_result","content":"     1→\"\"\"\n     2→SentimentArcs Programmatic API - Pipeline Implementation.\n     3→\n     4→This module implements a fluent interface for the 12-stage sentiment analysis pipeline\n     5→with master file accumulation and flexible file I/O management.\n     6→\"\"\"\n     7→\n     8→from __future__ import annotations\n     9→\n    10→import logging\n    11→import time\n    12→from dataclasses import dataclass, field\n    13→from pathlib import Path\n    14→from typing import Dict, List, Optional\n    15→\n    16→import pandas as pd\n    17→\n    18→from ..config import ArcConfig\n    19→from ..core.text_processor import run_text_pipeline, preprocess_text, segment_text, build_segment_dataframe, validate_segments\n    20→from ..core.normalizer import normalize_dataframe\n    21→from ..analysis.smoothing import smooth_series\n    22→from ..analysis.crux_detector import CruxDetectionResult, detect_crux_points\n    23→from ..analysis.incoherence_detector import compute_incoherence, generate_incoherence_report\n    24→from ..analysis.report_generator import ReportGenerator\n    25→from ..visualization.plotter import plot_single_model, plot_ensemble_models\n    26→from ..models import create_model\n    27→from ..utils.file_io import load_text, save_text, save_dataframe\n    28→from ..utils.reproducibility import set_global_seed\n    29→\n    30→\n    31→@dataclass\n    32→class PipelineState:\n    33→    \"\"\"\n    34→    Container for pipeline state between stages.\n    35→\n    36→    Attributes\n    37→    ----------\n    38→    config : ArcConfig\n    39→        Pipeline configuration\n    40→    filename_root : str\n    41→        Root name for all output files\n    42→    workspace_dir : Path\n    43→        Main workspace directory (outputs/{root}/datafiles/)\n    44→    plots_dir : Path\n    45→        Plots directory (outputs/{root}/plots/)\n    46→    reports_dir : Path\n    47→        Reports directory (outputs/{root}/reports/)\n    48→    logs_dir : Path\n    49→        Logs directory (outputs/{root}/logs/)\n    50→    master_file_path : Path\n    51→        Path to master accumulation file ({root}_sentimentarcs.csv)\n    52→    master_df : Optional[pd.DataFrame]\n    53→        Master DataFrame with all accumulated columns\n    54→\n    55→    Stage output paths\n    56→    ------------------\n    57→    clean_txt_path : Optional[Path]\n    58→        Stage 1 output\n    59→    segments_csv_path : Optional[Path]\n    60→        Stage 2 output\n    61→    segments_clean_csv_path : Optional[Path]\n    62→        Stage 3 output\n    63→    sentiments_csv_path : Optional[Path]\n    64→        Stage 4 output\n    65→    sentiments_smooth_csv_path : Optional[Path]\n    66→        Stage 5 output\n    67→    sentiments_norm_csv_path : Optional[Path]\n    68→        Stage 6 output\n    69→    plot_ensemble_path : Optional[Path]\n    70→        Stage 7 output\n    71→    incoherence_csv_path : Optional[Path]\n    72→        Stage 8 output\n    73→    crux_points_csv_path : Optional[Path]\n    74→        Stage 9 output\n    75→    crux_text_csv_path : Optional[Path]\n    76→        Stage 10 output\n    77→    plot_crux_path : Optional[Path]\n    78→        Stage 11 output\n    79→    report_path : Optional[Path]\n    80→        Stage 12 output\n    81→\n    82→    Stage data\n    83→    ----------\n    84→    raw_text : Optional[str]\n    85→        Original raw text\n    86→    cleaned_text : Optional[str]\n    87→        Preprocessed text\n    88→    crux_result : Optional[CruxDetectionResult]\n    89→        Crux detection results\n    90→\n    91→    Metadata\n    92→    --------\n    93→    stage_history : List[str]\n    94→        List of completed stages\n    95→    execution_time : Dict[str, float]\n    96→        Execution time per stage\n    97→    models : Dict[str, object]\n    98→        Loaded sentiment models\n    99→    \"\"\"\n   100→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"0388a94f-3a9d-4267-8db1-940e391ee5d8","timestamp":"2025-11-11T15:13:05.180Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/sentimentarcs/api/pipeline.py","content":"\"\"\"\nSentimentArcs Programmatic API - Pipeline Implementation.\n\nThis module implements a fluent interface for the 12-stage sentiment analysis pipeline\nwith master file accumulation and flexible file I/O management.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport time\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\n\nimport pandas as pd\n\nfrom ..config import ArcConfig\nfrom ..core.text_processor import run_text_pipeline, preprocess_text, segment_text, build_segment_dataframe, validate_segments\nfrom ..core.normalizer import normalize_dataframe\nfrom ..analysis.smoothing import smooth_series\nfrom ..analysis.crux_detector import CruxDetectionResult, detect_crux_points\nfrom ..analysis.incoherence_detector import compute_incoherence, generate_incoherence_report\nfrom ..analysis.report_generator import ReportGenerator\nfrom ..visualization.plotter import plot_single_model, plot_ensemble_models\nfrom ..models import create_model\nfrom ..utils.file_io import load_text, save_text, save_dataframe\nfrom ..utils.reproducibility import set_global_seed\n\n\n@dataclass\nclass PipelineState:\n    \"\"\"\n    Container for pipeline state between stages.\n\n    Attributes\n    ----------\n    config : ArcConfig\n        Pipeline configuration\n    filename_root : str\n        Root name for all output files\n    workspace_dir : Path\n        Main workspace directory (outputs/{root}/datafiles/)\n    plots_dir : Path\n        Plots directory (outputs/{root}/plots/)\n    reports_dir : Path\n        Reports directory (outputs/{root}/reports/)\n    logs_dir : Path\n        Logs directory (outputs/{root}/logs/)\n    master_file_path : Path\n        Path to master accumulation file ({root}_sentimentarcs.csv)\n    master_df : Optional[pd.DataFrame]\n        Master DataFrame with all accumulated columns\n\n    Stage output paths\n    ------------------\n    clean_txt_path : Optional[Path]\n        Stage 1 output\n    segments_csv_path : Optional[Path]\n        Stage 2 output\n    segments_clean_csv_path : Optional[Path]\n        Stage 3 output\n    sentiments_csv_path : Optional[Path]\n        Stage 4 output\n    sentiments_smooth_csv_path : Optional[Path]\n        Stage 5 output\n    sentiments_norm_csv_path : Optional[Path]\n        Stage 6 output\n    plot_ensemble_path : Optional[Path]\n        Stage 7 output\n    incoherence_csv_path : Optional[Path]\n        Stage 8 output\n    crux_points_csv_path : Optional[Path]\n        Stage 9 output\n    crux_text_csv_path : Optional[Path]\n        Stage 10 output\n    plot_crux_path : Optional[Path]\n        Stage 11 output\n    report_path : Optional[Path]\n        Stage 12 output\n\n    Stage data\n    ----------\n    raw_text : Optional[str]\n        Original raw text\n    cleaned_text : Optional[str]\n        Preprocessed text\n    crux_result : Optional[CruxDetectionResult]\n        Crux detection results\n\n    Metadata\n    --------\n    stage_history : List[str]\n        List of completed stages\n    execution_time : Dict[str, float]\n        Execution time per stage\n    models : Dict[str, object]\n        Loaded sentiment models\n    \"\"\"\n","numLines":100,"startLine":1,"totalLines":1563}}}
{"parentUuid":"0388a94f-3a9d-4267-8db1-940e391ee5d8","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Dx5qQycnfShvaFcevZNoLj","type":"tool_result","content":"     1→# SentimentArcs Technical Specification\n     2→\n     3→**Version:** 0.1.0\n     4→**Last Updated:** November 2025\n     5→**Author:** Jon Chun\n     6→\n     7→This document provides a comprehensive technical specification for experienced engineers to quickly understand the SentimentArcs architecture, implementation, and extension points.\n     8→\n     9→---\n    10→\n    11→## Table of Contents\n    12→\n    13→1. [Architecture Overview](#architecture-overview)\n    14→2. [Pipeline Stages](#pipeline-stages)\n    15→3. [Models Architecture](#models-architecture)\n    16→4. [Configuration System](#configuration-system)\n    17→5. [Data Flow](#data-flow)\n    18→6. [Extension Points](#extension-points)\n    19→7. [API Reference](#api-reference)\n    20→8. [Testing Strategy](#testing-strategy)\n    21→9. [Performance Considerations](#performance-considerations)\n    22→\n    23→---\n    24→\n    25→## Architecture Overview\n    26→\n    27→### Design Philosophy\n    28→\n    29→SentimentArcs follows a **stage-based pipeline architecture** with clear separation of concerns:\n    30→\n    31→- **Immutable Data Flow**: Each stage reads from and writes to DataFrames\n    32→- **Configuration-Driven**: YAML configuration controls all pipeline behavior\n    33→- **Model Abstraction**: Unified interface for local and API-based models\n    34→- **Output Isolation**: Each run creates isolated output directory tree\n    35→\n    36→### Core Components\n    37→\n    38→```\n    39→sentimentarcs/\n    40→├── core/\n    41→│   ├── sentiment_analyzer.py    # Main pipeline orchestrator\n    42→│   ├── text_processor.py        # Segmentation and cleaning\n    43→│   └── normalizer.py            # Data normalization\n    44→├── models/\n    45→│   ├── base.py                  # BaseSentimentModel interface\n    46→│   ├── vader_model.py           # Local: VADER\n    47→│   ├── textblob_model.py        # Local: TextBlob\n    48→│   ├── distilbert_model.py      # Local: DistilBERT (HuggingFace)\n    49→│   ├── nlptown_model.py         # Local: NLPTown (HuggingFace)\n    50→│   ├── openai_api_model.py      # API: OpenAI (GPT-5-mini, GPT-4o)\n    51→│   ├── anthropic_api_model.py   # API: Anthropic (Claude)\n    52→│   ├── google_api_model.py      # API: Google (Gemini)\n    53→│   ├── ollama_api_model.py      # API: Local Ollama server\n    54→│   ├── lmstudio_api_model.py    # API: Local LM Studio server\n    55→│   ├── api_validation.py        # Pydantic response validation\n    56→│   └── __init__.py              # Model factory\n    57→├── analysis/\n    58→│   ├── aggregator.py            # Ensemble aggregation (mean/median/mode)\n    59→│   ├── smoothing.py             # Moving average smoothing\n    60→│   ├── crux_detector.py         # Peak/valley detection\n    61→│   └── incoherence_detector.py  # Stage 6.75: Model disagreement metrics\n    62→├── plotting/\n    63→│   ├── arc_plot.py              # Single-model sentiment arcs\n    64→│   └── ensemble_plot.py         # Multi-model overlays\n    65→├── config.py                     # Configuration dataclasses\n    66→├── cli.py                        # Command-line interface\n    67→└── utils/\n    68→    ├── file_io.py               # CSV/text file operations\n    69→    ├── logging_config.py        # Structured logging\n    70→    └── reproducibility.py       # Random seed management\n    71→```\n    72→\n    73→---\n    74→\n    75→## Pipeline Stages\n    76→\n    77→### Stage 1-3: Text Processing\n    78→\n    79→**Input**: Raw text file\n    80→**Output**: Segmented and validated DataFrame\n    81→\n    82→```python\n    83→# Stage 1: Load and clean text\n    84→raw_text = load_text(input_path, encoding=\"utf-8\")\n    85→cleaned_text = preprocess_text(raw_text)\n    86→\n    87→# Stage 2: Segment into sentences/paragraphs\n    88→segments = segment_text(cleaned_text, max_chars=2000)\n    89→\n    90→# Stage 3: Validate segments\n    91→valid_segments = validate_segments(segments, min_chars=5)\n    92→```\n    93→\n    94→**Output Columns**: `segment_no`, `segment_text`\n    95→\n    96→**Configuration**:\n    97→```yaml\n    98→text:\n    99→  encoding: \"utf-8\"\n   100→  language: \"en\"\n   101→\n   102→segmentation:\n   103→  max_segment_chars: 2000\n   104→  min_segment_chars: 5\n   105→  allow_empty_segments: false\n   106→```\n   107→\n   108→### Stage 4: Sentiment Analysis\n   109→\n   110→**Input**: Segmented DataFrame\n   111→**Output**: DataFrame with raw sentiment columns\n   112→\n   113→```python\n   114→for model_name in enabled_models:\n   115→    model = create_model(model_name, **config)\n   116→    model.load()\n   117→    scores = model.predict(texts)\n   118→    df[f\"{model_name}_sentiment\"] = scores\n   119→    model.unload()\n   120→```\n   121→\n   122→**Output Columns**: `{model}_sentiment` for each enabled model\n   123→\n   124→**Model Loading Strategy**:\n   125→- **Sequential**: Load → Predict → Unload → Next model\n   126→- **Memory Management**: Explicit unload() for transformers\n   127→- **Model Switching Delay**: 3-second delay for Ollama model switches\n   128→\n   129→### Stage 5: Smoothing\n   130→\n   131→**Input**: Raw sentiment columns\n   132→**Output**: Smoothed sentiment columns\n   133→\n   134→```python\n   135→from sentimentarcs.analysis.smoothing import smooth_series\n   136→\n   137→smoothed = smooth_series(\n   138→    raw_series,\n   139→    window_size=5,\n   140→    method=\"moving_average\"\n   141→)\n   142→df[f\"{model}_sentiment_smoothed\"] = smoothed\n   143→```\n   144→\n   145→**Configuration**:\n   146→```yaml\n   147→smoothing:\n   148→  enabled: true\n   149→  window_size: 5\n   150→  method: \"moving_average\"\n   151→```\n   152→\n   153→### Stage 6: Normalization\n   154→\n   155→**Input**: Smoothed columns\n   156→**Output**: Normalized columns in [-1, 1]\n   157→\n   158→```python\n   159→from sentimentarcs.core.normalizer import normalize_series\n   160→\n   161→normalized = normalize_series(\n   162→    smoothed_series,\n   163→    target_min=-1.0,\n   164→    target_max=1.0\n   165→)\n   166→df[f\"{model}_sentiment_smoothed_norm\"] = normalized\n   167→```\n   168→\n   169→### Stage 6.5: Ensemble Plot\n   170→\n   171→**Input**: All normalized model columns\n   172→**Output**: Multi-model overlay plot PNG\n   173→\n   174→```python\n   175→from sentimentarcs.plotting.ensemble_plot import plot_ensemble_models\n   176→\n   177→plot_ensemble_models(\n   178→    df=df,\n   179→    model_columns=[f\"{m}_sentiment_smoothed_norm\" for m in models],\n   180→    output_path=\"plots/ensemble.png\",\n   181→    title=\"Ensemble Sentiment Arcs\"\n   182→)\n   183→```\n   184→\n   185→### Stage 6.75: Incoherence Analysis (NEW)\n   186→\n   187→**Input**: Raw sentiment columns\n   188→**Output**: Incoherence metric columns + separate outputs\n   189→\n   190→```python\n   191→from sentimentarcs.analysis.incoherence_detector import compute_incoherence\n   192→\n   193→incoherence_series, column_name = compute_incoherence(\n   194→    sentiment_table=df,\n   195→    model_columns=[f\"{m}_sentiment\" for m in models],\n   196→    algorithm=\"sd\",  # Options: sd, var, mad\n   197→    min_models=2\n   198→)\n   199→\n   200→# Add to DataFrame right after raw sentiment columns\n   201→df.insert(position, column_name, incoherence_series)\n   202→\n   203→# Generate separate outputs\n   204→save_incoherence_csv(df, incoherence_dir)\n   205→generate_incoherence_report(df, incoherence_dir)\n   206→```\n   207→\n   208→**Algorithms**:\n   209→- `sd`: Standard deviation across models\n   210→- `var`: Variance across models\n   211→- `mad`: Mean absolute deviation from mean\n   212→\n   213→**Configuration**:\n   214→```yaml\n   215→incoherence:\n   216→  enabled: true\n   217→  algorithm: \"sd\"\n   218→  min_models: 2\n   219→```\n   220→\n   221→**Output Files**:\n   222→- `incoherence/{project}_incoherence.csv`: Focused CSV with segment info + incoherence\n   223→- `incoherence/{project}_incoherence_report.txt`: Statistics and top disagreement segments\n   224→\n   225→### Stage 7: Crux Detection\n   226→\n   227→**Input**: Normalized sentiment column\n   228→**Output**: CruxDetectionResult with peaks/valleys\n   229→\n   230→```python\n   231→from sentimentarcs.analysis.crux_detector import detect_crux_points\n   232→\n   233→crux_result = detect_crux_points(\n   234→    sentiment_series=df[norm_col],\n   235→    method=\"derivative_extrema\",\n   236→    min_prominence=0.1,\n   237→    context_window=10\n   238→)\n   239→```\n   240→\n   241→**Configuration**:\n   242→```yaml\n   243→crux_detection:\n   244→  base_model_choice: [\"vader\", \"textblob\"]  # Can be single or list\n   245→  avg_method: \"mean\"  # Options: mean, median, mode\n   246→  method: \"derivative_extrema\"\n   247→  min_prominence: 0.1\n   248→  context_window_segments: 10\n   249→```\n   250→\n   251→### Stage 8: Report Generation\n   252→\n   253→**Input**: Complete DataFrame + crux results\n   254→**Output**: Markdown report + sentiment arc plot\n   255→\n   256→```python\n   257→generate_report(\n   258→    sentiment_table=df,\n   259→    crux_result=crux_result,\n   260→    plot_path=plot_path,\n   261→    output_path=report_path\n   262→)\n   263→```\n   264→\n   265→---\n   266→\n   267→## Models Architecture\n   268→\n   269→### Base Model Interface\n   270→\n   271→All models implement `BaseSentimentModel`:\n   272→\n   273→```python\n   274→@dataclass\n   275→class BaseSentimentModel:\n   276→    @property\n   277→    def model_name(self) -> str:\n   278→        \"\"\"Unique model identifier.\"\"\"\n   279→        raise NotImplementedError\n   280→\n   281→    def load(self) -> None:\n   282→        \"\"\"Load model into memory.\"\"\"\n   283→        raise NotImplementedError\n   284→\n   285→    def unload(self) -> None:\n   286→        \"\"\"Release model from memory.\"\"\"\n   287→        pass\n   288→\n   289→    def predict(self, texts: List[str]) -> np.ndarray:\n   290→        \"\"\"\n   291→        Compute sentiment scores for texts.\n   292→\n   293→        Returns\n   294→        -------\n   295→        np.ndarray\n   296→            Sentiment scores in [-1, 1] range.\n   297→        \"\"\"\n   298→        raise NotImplementedError\n   299→```\n   300→\n   301→### Local Models\n   302→\n   303→#### VADER (Lexical)\n   304→- **Library**: `vaderSentiment`\n   305→- **Speed**: Very fast (~0.001s per segment)\n   306→- **Load Time**: Instant\n   307→- **Memory**: < 10 MB\n   308→\n   309→#### TextBlob (Lexical)\n   310→- **Library**: `textblob`\n   311→- **Speed**: Fast (~0.002s per segment)\n   312→- **Load Time**: Instant\n   313→- **Memory**: < 20 MB\n   314→\n   315→#### DistilBERT (Transformer)\n   316→- **Library**: HuggingFace `transformers`\n   317→- **Model**: `distilbert-base-uncased-finetuned-sst-2-english`\n   318→- **Speed**: Moderate (~0.1s per segment on CPU, ~0.01s on GPU)\n   319→- **Load Time**: 2-5 seconds\n   320→- **Memory**: ~250 MB\n   321→- **Batch Size**: 32 (configurable)\n   322→\n   323→#### NLPTown (Transformer)\n   324→- **Library**: HuggingFace `transformers`\n   325→- **Model**: `nlptown/bert-base-multilingual-uncased-sentiment`\n   326→- **Speed**: Moderate (~0.15s per segment on CPU)\n   327→- **Load Time**: 3-7 seconds\n   328→- **Memory**: ~450 MB\n   329→- **Output**: 5-class (1-5 stars) → normalized to [-1, 1]\n   330→\n   331→### API Models\n   332→\n   333→#### Common Features\n   334→\n   335→All API models support:\n   336→- **Batch Processing**: Process multiple segments per API call\n   337→- **Exponential Backoff**: Automatic retry with configurable parameters\n   338→- **Pydantic Validation**: Type-safe response validation\n   339→- **Progress Tracking**: Time estimates and percentage complete\n   340→- **Rate Limiting**: Configurable retry delays\n   341→\n   342→**Configuration Parameters**:\n   343→```yaml\n   344→api_models:\n   345→  {provider}:\n   346→    enabled: true/false\n   347→    provider: \"openai|anthropic|google|ollama|lmstudio\"\n   348→    model_name: \"{model_id}\"\n   349→    base_url: \"{api_endpoint}\"\n   350→    api_key_env: \"{ENV_VAR_NAME}\"\n   351→    max_output_tokens: 64\n   352→    temperature: 1.0\n   353→    batch_size: 20\n   354→    max_retries: 3\n   355→    max_wait_initial_sec: 0.5\n   356→    max_wait_multiplier: 2\n   357→```\n   358→\n   359→#### OpenAI API Model\n   360→\n   361→**Supported Models**:\n   362→- `gpt-5-mini` (Reasoning model, uses `responses.create` API)\n   363→- `gpt-4o` (Uses `max_completion_tokens`)\n   364→- `gpt-4-turbo`\n   365→- `gpt-3.5-turbo` (Uses `max_tokens`)\n   366→\n   367→**API Differences**:\n   368→```python\n   369→# GPT-5 (Reasoning models)\n   370→response = client.responses.create(\n   371→    model=\"gpt-5-mini\",\n   372→    input=full_prompt,  # Combined system + user\n   373→    text={\"verbosity\": \"low\"}  # No temperature parameter\n   374→)\n   375→content = response.output_text\n   376→\n   377→# GPT-4o / GPT-4 / GPT-3.5\n   378→response = client.chat.completions.create(\n   379→    model=\"gpt-4o\",\n   380→    messages=[\n   381→        {\"role\": \"system\", \"content\": system_prompt},\n   382→        {\"role\": \"user\", \"content\": user_message}\n   383→    ],\n   384→    max_completion_tokens=64,  # GPT-4o\n   385→    # max_tokens=64,  # GPT-3.5/4\n   386→    temperature=1.0\n   387→)\n   388→content = response.choices[0].message.content\n   389→```\n   390→\n   391→**Prompt Template**: `sentimentarcs/models/openai_api_model_prompt.txt`\n   392→\n   393→#### Ollama API Model\n   394→\n   395→**Features**:\n   396→- **Local Inference**: Runs on local Ollama server (default: http://localhost:11434)\n   397→- **Model Warmup**: 120-second timeout to load model into memory\n   398→- **Model Switching**: 3-second delay between model switches\n   399→- **Multi-Model Support**: Can run multiple Ollama models in ensemble\n   400→\n   401→**Native API Endpoint**:\n   402→```python\n   403→# Uses /api/generate (not OpenAI-compatible /v1)\n   404→api_url = f\"{base_url}/api/generate\"\n   405→\n   406→payload = {\n   407→    \"model\": cfg.model_name,\n   408→    \"prompt\": full_prompt,\n   409→    \"stream\": False,\n   410→    \"options\": {\n   411→        \"temperature\": cfg.temperature,\n   412→        \"num_predict\": cfg.max_output_tokens\n   413→    }\n   414→}\n   415→\n   416→response = requests.post(api_url, json=payload, timeout=120)\n   417→result = response.json()\n   418→content = result.get(\"response\", \"\") or result.get(\"thinking\", \"\")\n   419→```\n   420→\n   421→**Multi-Model Configuration**:\n   422→```yaml\n   423→models:\n   424→  enabled_models:\n   425→    - \"api_ollama_gemma3\"     # Uses gemma3:4b\n   426→    - \"api_ollama_llama3.2\"   # Uses llama3.2:3b\n   427→    - \"api_ollama_granite\"    # Uses granite3.1-moe:3b\n   428→    - \"api_ollama_phi4\"       # Uses phi4-mini:3.8b\n   429→\n   430→api_models:\n   431→  ollama:\n   432→    enabled: true\n   433→    provider: \"ollama\"\n   434→    model_name: \"llama3.2:3b\"  # Default\n   435→    base_url: \"http://localhost:11434\"\n   436→    model_switch_delay_sec: 3\n   437→    ollama_models:\n   438→      gemma3: \"gemma3:4b\"\n   439→      llama3.2: \"llama3.2:3b\"\n   440→      granite: \"granite3.1-moe:3b\"\n   441→      phi4: \"phi4-mini:3.8b\"\n   442→```\n   443→\n   444→**JSON Response Parsing**:\n   445→- Strips markdown code blocks (```json ... ```)\n   446→- Extracts JSON using regex if wrapped in explanatory text\n   447→- Validates with Pydantic\n   448→\n   449→#### Anthropic, Google, LM Studio\n   450→\n   451→Similar architecture to OpenAI, with provider-specific API adapters.\n   452→\n   453→### Model Factory\n   454→\n   455→Central model creation in `sentimentarcs/models/__init__.py`:\n   456→\n   457→```python\n   458→def create_model(name: str, **kwargs) -> BaseSentimentModel:\n   459→    \"\"\"\n   460→    Factory function to create model instances.\n   461→\n   462→    Parameters\n   463→    ----------\n   464→    name : str\n   465→        Model identifier. Can be:\n   466→        - Local: \"vader\", \"textblob\", \"distilbert\", \"nlptown\"\n   467→        - API single: \"api_openai\", \"api_anthropic\", etc.\n   468→        - API multi: \"api_ollama_gemma3\", \"api_ollama_llama3.2\"\n   469→    \"\"\"\n   470→    # Parse multi-model naming: api_ollama_<identifier>\n   471→    if name.startswith(\"api_ollama_\"):\n   472→        identifier = name.removeprefix(\"api_ollama_\")\n   473→        cfg = get_ollama_config_for(identifier)\n   474→        return OllamaAPIModel(cfg=cfg, model_identifier=identifier)\n   475→\n   476→    # Single API model\n   477→    if name.startswith(\"api_\"):\n   478→        provider = name.removeprefix(\"api_\")\n   479→        cfg = get_provider_config(provider)\n   480→        return {\n   481→            \"openai\": OpenAIAPIModel,\n   482→            \"anthropic\": AnthropicAPIModel,\n   483→            \"google\": GoogleAPIModel,\n   484→            \"ollama\": OllamaAPIModel,\n   485→            \"lmstudio\": LMStudioAPIModel,\n   486→        }[provider](cfg=cfg)\n   487→\n   488→    # Local model\n   489→    return {\n   490→        \"vader\": VADERModel,\n   491→        \"textblob\": TextBlobModel,\n   492→        \"distilbert\": DistilBERTModel,\n   493→        \"nlptown\": NLPTownModel,\n   494→    }[name]()\n   495→```\n   496→\n   497→---\n   498→\n   499→## Configuration System\n   500→\n   501→### Dataclass Hierarchy\n   502→\n   503→```python\n   504→@dataclass\n   505→class ArcConfig:\n   506→    project: ProjectConfig\n   507→    paths: PathsConfig\n   508→    text: TextConfig\n   509→    segmentation: SegmentationConfig\n   510→    models: ModelsConfig\n   511→    api_models: ApiModelsConfig\n   512→    normalization: NormalizationConfig\n   513→    smoothing: SmoothingConfig\n   514→    crux_detection: CruxDetectionConfig\n   515→    incoherence: IncoherenceConfig  # NEW\n   516→    logging: LoggingConfig\n   517→    reproducibility: ReproducibilityConfig\n   518→\n   519→    @classmethod\n   520→    def from_yaml(cls, path: str | Path) -> \"ArcConfig\":\n   521→        \"\"\"Load config from YAML file.\"\"\"\n   522→        raw = yaml.safe_load(Path(path).read_text())\n   523→        return cls(**parse_config(raw))\n   524→```\n   525→\n   526→### Validation\n   527→\n   528→Configuration validation occurs at dataclass `__post_init__`:\n   529→\n   530→```python\n   531→@dataclass\n   532→class IncoherenceConfig:\n   533→    enabled: bool = True\n   534→    algorithm: str = \"sd\"\n   535→    min_models: int = 2\n   536→\n   537→    def __post_init__(self) -> None:\n   538→        allowed_algorithms = {\"sd\", \"var\", \"mad\"}\n   539→        if self.algorithm not in allowed_algorithms:\n   540→            raise ValueError(\n   541→                f\"Invalid algorithm '{self.algorithm}'. \"\n   542→                f\"Must be one of: {allowed_algorithms}\"\n   543→            )\n   544→        if self.min_models < 2:\n   545→            raise ValueError(\"min_models must be at least 2\")\n   546→```\n   547→\n   548→---\n   549→\n   550→## Data Flow\n   551→\n   552→### DataFrame Schema Evolution\n   553→\n   554→```\n   555→Stage 1-3: Segmentation\n   556→├─ segment_no: int\n   557→└─ segment_text: str\n   558→\n   559→Stage 4: Sentiment Analysis\n   560→├─ segment_no: int\n   561→├─ segment_text: str\n   562→├─ vader_sentiment: float\n   563→├─ textblob_sentiment: float\n   564→├─ distilbert_sentiment: float\n   565→└─ api_openai_sentiment: float\n   566→\n   567→Stage 5: Smoothing\n   568→├─ ... (previous columns)\n   569→├─ vader_sentiment_smoothed: float\n   570→├─ textblob_sentiment_smoothed: float\n   571→└─ ...\n   572→\n   573→Stage 6: Normalization\n   574→├─ ... (previous columns)\n   575→├─ vader_sentiment_smoothed_norm: float\n   576→└─ ...\n   577→\n   578→Stage 6.75: Incoherence (NEW)\n   579→├─ segment_no: int\n   580→├─ segment_text: str\n   581→├─ vader_sentiment: float (raw)\n   582→├─ textblob_sentiment: float (raw)\n   583→├─ incoherence_sd: float  ← Inserted here\n   584→├─ vader_sentiment_smoothed: float\n   585→└─ ... (rest of columns)\n   586→\n   587→Stage 6: Ensemble Average (if multiple models in base_model_choice)\n   588→├─ ... (previous columns)\n   589→└─ {model1}-{model2}_sentiment: float\n   590→\n   591→Stage 7: Crux Detection\n   592→└─ (No new columns, produces CruxDetectionResult object)\n   593→```\n   594→\n   595→### Column Ordering Strategy\n   596→\n   597→**Main Sentiment CSV** ordering:\n   598→1. `segment_no`\n   599→2. `segment_text`\n   600→3. `{model}_sentiment` (all raw sentiment columns)\n   601→4. `incoherence_{algorithm}` ← **Inserted here in Stage 6.75**\n   602→5. `{ensemble}_sentiment` (if applicable)\n   603→6. `{model}_sentiment_smoothed` (all smoothed columns)\n   604→7. `{model}_sentiment_smoothed_norm` (all normalized columns)\n   605→8. `{ensemble}_sentiment_smoothed` (if applicable)\n   606→9. `{ensemble}_sentiment_smoothed_norm` (if applicable)\n   607→\n   608→---\n   609→\n   610→## Extension Points\n   611→\n   612→### Adding a New Model\n   613→\n   614→1. **Create Model Class**:\n   615→\n   616→```python\n   617→# sentimentarcs/models/my_model.py\n   618→from .base import BaseSentimentModel\n   619→\n   620→@dataclass\n   621→class MyModel(BaseSentimentModel):\n   622→    @property\n   623→    def model_name(self) -> str:\n   624→        return \"my_model\"\n   625→\n   626→    def load(self) -> None:\n   627→        # Load model resources\n   628→        pass\n   629→\n   630→    def unload(self) -> None:\n   631→        # Clean up resources\n   632→        pass\n   633→\n   634→    def predict(self, texts: List[str]) -> np.ndarray:\n   635→        # Return scores in [-1, 1]\n   636→        scores = [...]\n   637→        return np.array(scores, dtype=float)\n   638→```\n   639→\n   640→2. **Register in Factory**:\n   641→\n   642→```python\n   643→# sentimentarcs/models/__init__.py\n   644→def create_model(name: str, **kwargs) -> BaseSentimentModel:\n   645→    models = {\n   646→        # ... existing models ...\n   647→        \"my_model\": MyModel,\n   648→    }\n   649→    return models[name](**kwargs)\n   650→```\n   651→\n   652→3. **Add to Configuration**:\n   653→\n   654→```yaml\n   655→models:\n   656→  enabled_models:\n   657→    - \"my_model\"\n   658→```\n   659→\n   660→### Adding a New Incoherence Algorithm\n   661→\n   662→1. **Implement Algorithm**:\n   663→\n   664→```python\n   665→# sentimentarcs/analysis/incoherence_detector.py\n   666→def compute_incoherence(\n   667→    sentiment_table: pd.DataFrame,\n   668→    model_columns: List[str],\n   669→    algorithm: str = \"sd\",\n   670→    min_models: int = 2,\n   671→) -> Tuple[pd.Series, str]:\n   672→    sentiment_matrix = sentiment_table[model_columns].values\n   673→\n   674→    if algorithm == \"my_metric\":\n   675→        # Implement custom disagreement metric\n   676→        incoherence = custom_calculation(sentiment_matrix)\n   677→        column_name = \"incoherence_my_metric\"\n   678→    # ... existing algorithms ...\n   679→\n   680→    return pd.Series(incoherence, index=sentiment_table.index), column_name\n   681→```\n   682→\n   683→2. **Update Configuration Validation**:\n   684→\n   685→```python\n   686→@dataclass\n   687→class IncoherenceConfig:\n   688→    # ...\n   689→    def __post_init__(self) -> None:\n   690→        allowed_algorithms = {\"sd\", \"var\", \"mad\", \"my_metric\"}\n   691→        # ...\n   692→```\n   693→\n   694→### Adding a New Pipeline Stage\n   695→\n   696→1. **Implement Stage Method** in `SentimentAnalyzer`:\n   697→\n   698→```python\n   699→def _stage_X_my_analysis(self, df: pd.DataFrame) -> pd.DataFrame:\n   700→    \"\"\"\n   701→    Stage X: My custom analysis.\n   702→    \"\"\"\n   703→    # Process df\n   704→    df[\"my_metric\"] = calculate_my_metric(df)\n   705→    return df\n   706→```\n   707→\n   708→2. **Insert into Pipeline** in `run()`:\n   709→\n   710→```python\n   711→def run(self, input_path: str | Path) -> SentimentAnalyzerResult:\n   712→    # ... existing stages ...\n   713→\n   714→    # Stage X: My analysis\n   715→    sentiment_table = self._stage_X_my_analysis(sentiment_table)\n   716→\n   717→    # ... continue pipeline ...\n   718→```\n   719→\n   720→---\n   721→\n   722→## API Reference\n   723→\n   724→### Core Classes\n   725→\n   726→#### SentimentAnalyzer\n   727→\n   728→```python\n   729→class SentimentAnalyzer:\n   730→    \"\"\"\n   731→    Main pipeline orchestrator.\n   732→\n   733→    Parameters\n   734→    ----------\n   735→    cfg : ArcConfig\n   736→        Configuration object loaded from YAML.\n   737→\n   738→    Methods\n   739→    -------\n   740→    run(input_path: str | Path) -> SentimentAnalyzerResult\n   741→        Execute full pipeline on input text file.\n   742→    \"\"\"\n   743→```\n   744→\n   745→#### SentimentAnalyzerResult\n   746→\n   747→```python\n   748→@dataclass\n   749→class SentimentAnalyzerResult:\n   750→    segments: SegmentationResult\n   751→    sentiment_table: pd.DataFrame\n   752→    crux: Optional[CruxDetectionResult]\n   753→    ensemble_plot_path: Optional[Path]\n   754→    plot_path: Optional[Path]\n   755→    report_path: Optional[Path]\n   756→```\n   757→\n   758→### Key Functions\n   759→\n   760→#### Incoherence Analysis\n   761→\n   762→```python\n   763→def compute_incoherence(\n   764→    sentiment_table: pd.DataFrame,\n   765→    model_columns: List[str],\n   766→    algorithm: str = \"sd\",\n   767→    min_models: int = 2,\n   768→) -> Tuple[pd.Series, str]:\n   769→    \"\"\"\n   770→    Compute disagreement metrics across ensemble models.\n   771→\n   772→    Returns\n   773→    -------\n   774→    incoherence_series : pd.Series\n   775→        Incoherence values for each segment.\n   776→    column_name : str\n   777→        Name of incoherence column (e.g., 'incoherence_sd').\n   778→    \"\"\"\n   779→\n   780→def identify_high_disagreement_segments(\n   781→    sentiment_table: pd.DataFrame,\n   782→    incoherence_column: str,\n   783→    threshold_percentile: float = 90.0,\n   784→) -> pd.DataFrame:\n   785→    \"\"\"\n   786→    Identify segments with high model disagreement.\n   787→\n   788→    Returns top segments sorted by incoherence descending.\n   789→    \"\"\"\n   790→\n   791→def generate_incoherence_report(\n   792→    sentiment_table: pd.DataFrame,\n   793→    incoherence_column: str,\n   794→    model_columns: List[str],\n   795→    output_path: str,\n   796→) -> None:\n   797→    \"\"\"\n   798→    Generate markdown report with statistics and top disagreements.\n   799→    \"\"\"\n   800→```\n   801→\n   802→---\n   803→\n   804→## Testing Strategy\n   805→\n   806→See [TESTING.md](TESTING.md) for comprehensive testing documentation.\n   807→\n   808→### Test Structure\n   809→\n   810→```\n   811→tests/\n   812→├── unit/                      # Module-level tests\n   813→│   ├── test_incoherence_detector.py (11 tests)\n   814→│   ├── test_models_local.py\n   815→│   ├── test_models_api.py\n   816→│   └── ...\n   817→├── integration/               # Pipeline-level tests\n   818→│   ├── test_incoherence_analysis.py (8 tests)\n   819→│   ├── test_sentiment_analyzer.py\n   820→│   └── ...\n   821→└── conftest.py               # Shared fixtures\n   822→```\n   823→\n   824→### Running Tests\n   825→\n   826→```bash\n   827→# All tests\n   828→pytest tests/\n   829→\n   830→# Unit tests only\n   831→pytest tests/unit/\n   832→\n   833→# Integration tests only\n   834→pytest tests/integration/\n   835→\n   836→# Exclude API tests (require credentials)\n   837→pytest tests/ -k \"not api\"\n   838→\n   839→# With coverage\n   840→pytest --cov=sentimentarcs --cov-report=html tests/\n   841→```\n   842→\n   843→---\n   844→\n   845→## Performance Considerations\n   846→\n   847→### Model Load Times\n   848→\n   849→| Model | Load Time | Memory | Speed (CPU) |\n   850→|-------|-----------|---------|-------------|\n   851→| VADER | < 0.1s | < 10 MB | ~1000 seg/s |\n   852→| TextBlob | < 0.1s | < 20 MB | ~500 seg/s |\n   853→| DistilBERT | 2-5s | ~250 MB | ~10 seg/s |\n   854→| NLPTown | 3-7s | ~450 MB | ~7 seg/s |\n   855→| OpenAI API | N/A | N/A | ~1 seg/s (batch 20) |\n   856→| Ollama Local | 5-120s | Varies | ~0.5 seg/s (batch 20) |\n   857→\n   858→### Batch Processing\n   859→\n   860→API models use batch processing to reduce API calls:\n   861→\n   862→```python\n   863→# Instead of 100 API calls\n   864→for text in texts:\n   865→    score = api_call(text)  # 100 calls\n   866→\n   867→# Batch into 5 API calls\n   868→for batch in batches(texts, size=20):\n   869→    scores = api_call(batch)  # 5 calls\n   870→```\n   871→\n   872→**Configuration**:\n   873→```yaml\n   874→api_models:\n   875→  openai:\n   876→    batch_size: 20  # Process 20 segments per API call\n   877→```\n   878→\n   879→### Memory Management\n   880→\n   881→**Transformer Models**:\n   882→- Explicitly call `model.unload()` after use\n   883→- Use GPU if available: `models.use_gpu_if_available: true`\n   884→- Reduce batch size if OOM: `transformer_batch_size: 16`\n   885→\n   886→**Ollama Models**:\n   887→- Wait for model to unload: `model_switch_delay_sec: 3`\n   888→- Single model in memory at a time\n   889→\n   890→### Output File Sizes\n   891→\n   892→Typical output sizes for 1000-segment novel:\n   893→\n   894→- Segments CSV: ~500 KB\n   895→- Sentiment CSV: ~1 MB (4 models) → ~2 MB (with incoherence)\n   896→- Incoherence CSV: ~200 KB\n   897→- Plots: ~50-100 KB each\n   898→- Reports: ~10-20 KB\n   899→- Logs: ~100-500 KB\n   900→\n   901→---\n   902→\n   903→## Environment Variables\n   904→\n   905→### Required for API Models\n   906→\n   907→```bash\n   908→# OpenAI\n   909→export OPENAI_API_KEY=\"sk-proj-...\"\n   910→\n   911→# Anthropic\n   912→export ANTHROPIC_API_KEY=\"sk-ant-...\"\n   913→\n   914→# Google\n   915→export GEMINI_API_KEY=\"...\"\n   916→```\n   917→\n   918→### Configuration via .env\n   919→\n   920→Create `.env` file in project root:\n   921→\n   922→```bash\n   923→OPENAI_API_KEY=\"sk-proj-...\"\n   924→ANTHROPIC_API_KEY=\"sk-ant-...\"\n   925→GEMINI_API_KEY=\"...\"\n   926→```\n   927→\n   928→Loaded automatically via `python-dotenv`:\n   929→\n   930→```python\n   931→from dotenv import load_dotenv\n   932→load_dotenv()  # Loads .env file\n   933→\n   934→api_key = os.getenv(\"OPENAI_API_KEY\")\n   935→```\n   936→\n   937→---\n   938→\n   939→## Dependencies\n   940→\n   941→### Core Dependencies\n   942→\n   943→```toml\n   944→[project]\n   945→dependencies = [\n   946→  \"pandas>=1.5,<2.3\",\n   947→  \"numpy>=1.24,<2.0\",\n   948→  \"matplotlib>=3.7,<4.0\",\n   949→  \"scipy>=1.10,<2.0\",\n   950→  \"pyyaml>=6.0,<7.0\",\n   951→  \"pydantic>=2.0,<3.0\",\n   952→  \"python-dotenv>=1.0.0,<2.0\",\n   953→]\n   954→```\n   955→\n   956→### Model-Specific Dependencies\n   957→\n   958→```toml\n   959→# Local sentiment models\n   960→\"textblob>=0.18,<0.19\"\n   961→\"vaderSentiment>=3.3.2,<4.0\"\n   962→\n   963→# Transformers\n   964→\"transformers>=4.0,<5.0\"\n   965→\"torch>=2.0,<3.0\"\n   966→\n   967→# API clients\n   968→\"openai>=1.0.0,<2.0\"\n   969→\"anthropic>=0.20.0,<1.0\"\n   970→\"requests>=2.31,<3.0\"\n   971→```\n   972→\n   973→---\n   974→\n   975→## Logging\n   976→\n   977→### Configuration\n   978→\n   979→```yaml\n   980→logging:\n   981→  level: \"INFO\"  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n   982→  log_to_stdout: true\n   983→  log_to_file: true\n   984→```\n   985→\n   986→### Log File Structure\n   987→\n   988→```\n   989→outputs/{run_name}/logs/\n   990→└── sentimentarcs_{model_label}_{timestamp}.log\n   991→```\n   992→\n   993→### Log Format\n   994→\n   995→```\n   996→2025-11-11 02:40:00,556 [INFO] sentimentarcs.core.sentiment_analyzer: Stage 6.75: Computing incoherence metrics across 2 models\n   997→```\n   998→\n   999→---\n  1000→\n  1001→## Reproducibility\n  1002→\n  1003→### Random Seed\n  1004→\n  1005→```yaml\n  1006→reproducibility:\n  1007→  random_seed: 42\n  1008→  deterministic: true\n  1009→```\n  1010→\n  1011→Applied to:\n  1012→- NumPy random operations\n  1013→- PyTorch operations (if using GPU)\n  1014→- Model initialization\n  1015→\n  1016→### Version Pinning\n  1017→\n  1018→All dependencies use version ranges to ensure reproducibility while allowing security updates:\n  1019→\n  1020→```toml\n  1021→\"pandas>=1.5,<2.3\"  # Major version locked, minor updates allowed\n  1022→```\n  1023→\n  1024→---\n  1025→\n  1026→## Future Roadmap\n  1027→\n  1028→1. **Parallel Processing**: Multi-threaded model execution\n  1029→2. **Streaming API**: Process large texts without loading entire file\n  1030→3. **Custom Aggregation**: User-defined ensemble functions\n  1031→4. **Interactive Dashboard**: Web UI for exploration\n  1032→5. **Model Caching**: Cache API responses to reduce costs\n  1033→6. **Distributed Processing**: Ray/Dask for large-scale analysis\n  1034→\n  1035→---\n  1036→\n  1037→## References\n  1038→\n  1039→- **OpenAI API Docs**: https://platform.openai.com/docs/api-reference\n  1040→- **Ollama API Docs**: https://github.com/ollama/ollama/blob/main/docs/api.md\n  1041→- **HuggingFace Transformers**: https://huggingface.co/docs/transformers\n  1042→- **Pydantic V2**: https://docs.pydantic.dev/latest/\n  1043→- **Pytest**: https://docs.pytest.org/\n  1044→\n  1045→---\n  1046→\n  1047→**Document Version**: 1.0\n  1048→**Last Updated**: November 2025\n  1049→**Maintainer**: Jon Chun (jon.chun@example.com)\n  1050→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9fd2955a-c86a-434a-8674-257ced56f020","timestamp":"2025-11-11T15:13:05.356Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/docs/doc_tech-spec.md","content":"# SentimentArcs Technical Specification\n\n**Version:** 0.1.0\n**Last Updated:** November 2025\n**Author:** Jon Chun\n\nThis document provides a comprehensive technical specification for experienced engineers to quickly understand the SentimentArcs architecture, implementation, and extension points.\n\n---\n\n## Table of Contents\n\n1. [Architecture Overview](#architecture-overview)\n2. [Pipeline Stages](#pipeline-stages)\n3. [Models Architecture](#models-architecture)\n4. [Configuration System](#configuration-system)\n5. [Data Flow](#data-flow)\n6. [Extension Points](#extension-points)\n7. [API Reference](#api-reference)\n8. [Testing Strategy](#testing-strategy)\n9. [Performance Considerations](#performance-considerations)\n\n---\n\n## Architecture Overview\n\n### Design Philosophy\n\nSentimentArcs follows a **stage-based pipeline architecture** with clear separation of concerns:\n\n- **Immutable Data Flow**: Each stage reads from and writes to DataFrames\n- **Configuration-Driven**: YAML configuration controls all pipeline behavior\n- **Model Abstraction**: Unified interface for local and API-based models\n- **Output Isolation**: Each run creates isolated output directory tree\n\n### Core Components\n\n```\nsentimentarcs/\n├── core/\n│   ├── sentiment_analyzer.py    # Main pipeline orchestrator\n│   ├── text_processor.py        # Segmentation and cleaning\n│   └── normalizer.py            # Data normalization\n├── models/\n│   ├── base.py                  # BaseSentimentModel interface\n│   ├── vader_model.py           # Local: VADER\n│   ├── textblob_model.py        # Local: TextBlob\n│   ├── distilbert_model.py      # Local: DistilBERT (HuggingFace)\n│   ├── nlptown_model.py         # Local: NLPTown (HuggingFace)\n│   ├── openai_api_model.py      # API: OpenAI (GPT-5-mini, GPT-4o)\n│   ├── anthropic_api_model.py   # API: Anthropic (Claude)\n│   ├── google_api_model.py      # API: Google (Gemini)\n│   ├── ollama_api_model.py      # API: Local Ollama server\n│   ├── lmstudio_api_model.py    # API: Local LM Studio server\n│   ├── api_validation.py        # Pydantic response validation\n│   └── __init__.py              # Model factory\n├── analysis/\n│   ├── aggregator.py            # Ensemble aggregation (mean/median/mode)\n│   ├── smoothing.py             # Moving average smoothing\n│   ├── crux_detector.py         # Peak/valley detection\n│   └── incoherence_detector.py  # Stage 6.75: Model disagreement metrics\n├── plotting/\n│   ├── arc_plot.py              # Single-model sentiment arcs\n│   └── ensemble_plot.py         # Multi-model overlays\n├── config.py                     # Configuration dataclasses\n├── cli.py                        # Command-line interface\n└── utils/\n    ├── file_io.py               # CSV/text file operations\n    ├── logging_config.py        # Structured logging\n    └── reproducibility.py       # Random seed management\n```\n\n---\n\n## Pipeline Stages\n\n### Stage 1-3: Text Processing\n\n**Input**: Raw text file\n**Output**: Segmented and validated DataFrame\n\n```python\n# Stage 1: Load and clean text\nraw_text = load_text(input_path, encoding=\"utf-8\")\ncleaned_text = preprocess_text(raw_text)\n\n# Stage 2: Segment into sentences/paragraphs\nsegments = segment_text(cleaned_text, max_chars=2000)\n\n# Stage 3: Validate segments\nvalid_segments = validate_segments(segments, min_chars=5)\n```\n\n**Output Columns**: `segment_no`, `segment_text`\n\n**Configuration**:\n```yaml\ntext:\n  encoding: \"utf-8\"\n  language: \"en\"\n\nsegmentation:\n  max_segment_chars: 2000\n  min_segment_chars: 5\n  allow_empty_segments: false\n```\n\n### Stage 4: Sentiment Analysis\n\n**Input**: Segmented DataFrame\n**Output**: DataFrame with raw sentiment columns\n\n```python\nfor model_name in enabled_models:\n    model = create_model(model_name, **config)\n    model.load()\n    scores = model.predict(texts)\n    df[f\"{model_name}_sentiment\"] = scores\n    model.unload()\n```\n\n**Output Columns**: `{model}_sentiment` for each enabled model\n\n**Model Loading Strategy**:\n- **Sequential**: Load → Predict → Unload → Next model\n- **Memory Management**: Explicit unload() for transformers\n- **Model Switching Delay**: 3-second delay for Ollama model switches\n\n### Stage 5: Smoothing\n\n**Input**: Raw sentiment columns\n**Output**: Smoothed sentiment columns\n\n```python\nfrom sentimentarcs.analysis.smoothing import smooth_series\n\nsmoothed = smooth_series(\n    raw_series,\n    window_size=5,\n    method=\"moving_average\"\n)\ndf[f\"{model}_sentiment_smoothed\"] = smoothed\n```\n\n**Configuration**:\n```yaml\nsmoothing:\n  enabled: true\n  window_size: 5\n  method: \"moving_average\"\n```\n\n### Stage 6: Normalization\n\n**Input**: Smoothed columns\n**Output**: Normalized columns in [-1, 1]\n\n```python\nfrom sentimentarcs.core.normalizer import normalize_series\n\nnormalized = normalize_series(\n    smoothed_series,\n    target_min=-1.0,\n    target_max=1.0\n)\ndf[f\"{model}_sentiment_smoothed_norm\"] = normalized\n```\n\n### Stage 6.5: Ensemble Plot\n\n**Input**: All normalized model columns\n**Output**: Multi-model overlay plot PNG\n\n```python\nfrom sentimentarcs.plotting.ensemble_plot import plot_ensemble_models\n\nplot_ensemble_models(\n    df=df,\n    model_columns=[f\"{m}_sentiment_smoothed_norm\" for m in models],\n    output_path=\"plots/ensemble.png\",\n    title=\"Ensemble Sentiment Arcs\"\n)\n```\n\n### Stage 6.75: Incoherence Analysis (NEW)\n\n**Input**: Raw sentiment columns\n**Output**: Incoherence metric columns + separate outputs\n\n```python\nfrom sentimentarcs.analysis.incoherence_detector import compute_incoherence\n\nincoherence_series, column_name = compute_incoherence(\n    sentiment_table=df,\n    model_columns=[f\"{m}_sentiment\" for m in models],\n    algorithm=\"sd\",  # Options: sd, var, mad\n    min_models=2\n)\n\n# Add to DataFrame right after raw sentiment columns\ndf.insert(position, column_name, incoherence_series)\n\n# Generate separate outputs\nsave_incoherence_csv(df, incoherence_dir)\ngenerate_incoherence_report(df, incoherence_dir)\n```\n\n**Algorithms**:\n- `sd`: Standard deviation across models\n- `var`: Variance across models\n- `mad`: Mean absolute deviation from mean\n\n**Configuration**:\n```yaml\nincoherence:\n  enabled: true\n  algorithm: \"sd\"\n  min_models: 2\n```\n\n**Output Files**:\n- `incoherence/{project}_incoherence.csv`: Focused CSV with segment info + incoherence\n- `incoherence/{project}_incoherence_report.txt`: Statistics and top disagreement segments\n\n### Stage 7: Crux Detection\n\n**Input**: Normalized sentiment column\n**Output**: CruxDetectionResult with peaks/valleys\n\n```python\nfrom sentimentarcs.analysis.crux_detector import detect_crux_points\n\ncrux_result = detect_crux_points(\n    sentiment_series=df[norm_col],\n    method=\"derivative_extrema\",\n    min_prominence=0.1,\n    context_window=10\n)\n```\n\n**Configuration**:\n```yaml\ncrux_detection:\n  base_model_choice: [\"vader\", \"textblob\"]  # Can be single or list\n  avg_method: \"mean\"  # Options: mean, median, mode\n  method: \"derivative_extrema\"\n  min_prominence: 0.1\n  context_window_segments: 10\n```\n\n### Stage 8: Report Generation\n\n**Input**: Complete DataFrame + crux results\n**Output**: Markdown report + sentiment arc plot\n\n```python\ngenerate_report(\n    sentiment_table=df,\n    crux_result=crux_result,\n    plot_path=plot_path,\n    output_path=report_path\n)\n```\n\n---\n\n## Models Architecture\n\n### Base Model Interface\n\nAll models implement `BaseSentimentModel`:\n\n```python\n@dataclass\nclass BaseSentimentModel:\n    @property\n    def model_name(self) -> str:\n        \"\"\"Unique model identifier.\"\"\"\n        raise NotImplementedError\n\n    def load(self) -> None:\n        \"\"\"Load model into memory.\"\"\"\n        raise NotImplementedError\n\n    def unload(self) -> None:\n        \"\"\"Release model from memory.\"\"\"\n        pass\n\n    def predict(self, texts: List[str]) -> np.ndarray:\n        \"\"\"\n        Compute sentiment scores for texts.\n\n        Returns\n        -------\n        np.ndarray\n            Sentiment scores in [-1, 1] range.\n        \"\"\"\n        raise NotImplementedError\n```\n\n### Local Models\n\n#### VADER (Lexical)\n- **Library**: `vaderSentiment`\n- **Speed**: Very fast (~0.001s per segment)\n- **Load Time**: Instant\n- **Memory**: < 10 MB\n\n#### TextBlob (Lexical)\n- **Library**: `textblob`\n- **Speed**: Fast (~0.002s per segment)\n- **Load Time**: Instant\n- **Memory**: < 20 MB\n\n#### DistilBERT (Transformer)\n- **Library**: HuggingFace `transformers`\n- **Model**: `distilbert-base-uncased-finetuned-sst-2-english`\n- **Speed**: Moderate (~0.1s per segment on CPU, ~0.01s on GPU)\n- **Load Time**: 2-5 seconds\n- **Memory**: ~250 MB\n- **Batch Size**: 32 (configurable)\n\n#### NLPTown (Transformer)\n- **Library**: HuggingFace `transformers`\n- **Model**: `nlptown/bert-base-multilingual-uncased-sentiment`\n- **Speed**: Moderate (~0.15s per segment on CPU)\n- **Load Time**: 3-7 seconds\n- **Memory**: ~450 MB\n- **Output**: 5-class (1-5 stars) → normalized to [-1, 1]\n\n### API Models\n\n#### Common Features\n\nAll API models support:\n- **Batch Processing**: Process multiple segments per API call\n- **Exponential Backoff**: Automatic retry with configurable parameters\n- **Pydantic Validation**: Type-safe response validation\n- **Progress Tracking**: Time estimates and percentage complete\n- **Rate Limiting**: Configurable retry delays\n\n**Configuration Parameters**:\n```yaml\napi_models:\n  {provider}:\n    enabled: true/false\n    provider: \"openai|anthropic|google|ollama|lmstudio\"\n    model_name: \"{model_id}\"\n    base_url: \"{api_endpoint}\"\n    api_key_env: \"{ENV_VAR_NAME}\"\n    max_output_tokens: 64\n    temperature: 1.0\n    batch_size: 20\n    max_retries: 3\n    max_wait_initial_sec: 0.5\n    max_wait_multiplier: 2\n```\n\n#### OpenAI API Model\n\n**Supported Models**:\n- `gpt-5-mini` (Reasoning model, uses `responses.create` API)\n- `gpt-4o` (Uses `max_completion_tokens`)\n- `gpt-4-turbo`\n- `gpt-3.5-turbo` (Uses `max_tokens`)\n\n**API Differences**:\n```python\n# GPT-5 (Reasoning models)\nresponse = client.responses.create(\n    model=\"gpt-5-mini\",\n    input=full_prompt,  # Combined system + user\n    text={\"verbosity\": \"low\"}  # No temperature parameter\n)\ncontent = response.output_text\n\n# GPT-4o / GPT-4 / GPT-3.5\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_message}\n    ],\n    max_completion_tokens=64,  # GPT-4o\n    # max_tokens=64,  # GPT-3.5/4\n    temperature=1.0\n)\ncontent = response.choices[0].message.content\n```\n\n**Prompt Template**: `sentimentarcs/models/openai_api_model_prompt.txt`\n\n#### Ollama API Model\n\n**Features**:\n- **Local Inference**: Runs on local Ollama server (default: http://localhost:11434)\n- **Model Warmup**: 120-second timeout to load model into memory\n- **Model Switching**: 3-second delay between model switches\n- **Multi-Model Support**: Can run multiple Ollama models in ensemble\n\n**Native API Endpoint**:\n```python\n# Uses /api/generate (not OpenAI-compatible /v1)\napi_url = f\"{base_url}/api/generate\"\n\npayload = {\n    \"model\": cfg.model_name,\n    \"prompt\": full_prompt,\n    \"stream\": False,\n    \"options\": {\n        \"temperature\": cfg.temperature,\n        \"num_predict\": cfg.max_output_tokens\n    }\n}\n\nresponse = requests.post(api_url, json=payload, timeout=120)\nresult = response.json()\ncontent = result.get(\"response\", \"\") or result.get(\"thinking\", \"\")\n```\n\n**Multi-Model Configuration**:\n```yaml\nmodels:\n  enabled_models:\n    - \"api_ollama_gemma3\"     # Uses gemma3:4b\n    - \"api_ollama_llama3.2\"   # Uses llama3.2:3b\n    - \"api_ollama_granite\"    # Uses granite3.1-moe:3b\n    - \"api_ollama_phi4\"       # Uses phi4-mini:3.8b\n\napi_models:\n  ollama:\n    enabled: true\n    provider: \"ollama\"\n    model_name: \"llama3.2:3b\"  # Default\n    base_url: \"http://localhost:11434\"\n    model_switch_delay_sec: 3\n    ollama_models:\n      gemma3: \"gemma3:4b\"\n      llama3.2: \"llama3.2:3b\"\n      granite: \"granite3.1-moe:3b\"\n      phi4: \"phi4-mini:3.8b\"\n```\n\n**JSON Response Parsing**:\n- Strips markdown code blocks (```json ... ```)\n- Extracts JSON using regex if wrapped in explanatory text\n- Validates with Pydantic\n\n#### Anthropic, Google, LM Studio\n\nSimilar architecture to OpenAI, with provider-specific API adapters.\n\n### Model Factory\n\nCentral model creation in `sentimentarcs/models/__init__.py`:\n\n```python\ndef create_model(name: str, **kwargs) -> BaseSentimentModel:\n    \"\"\"\n    Factory function to create model instances.\n\n    Parameters\n    ----------\n    name : str\n        Model identifier. Can be:\n        - Local: \"vader\", \"textblob\", \"distilbert\", \"nlptown\"\n        - API single: \"api_openai\", \"api_anthropic\", etc.\n        - API multi: \"api_ollama_gemma3\", \"api_ollama_llama3.2\"\n    \"\"\"\n    # Parse multi-model naming: api_ollama_<identifier>\n    if name.startswith(\"api_ollama_\"):\n        identifier = name.removeprefix(\"api_ollama_\")\n        cfg = get_ollama_config_for(identifier)\n        return OllamaAPIModel(cfg=cfg, model_identifier=identifier)\n\n    # Single API model\n    if name.startswith(\"api_\"):\n        provider = name.removeprefix(\"api_\")\n        cfg = get_provider_config(provider)\n        return {\n            \"openai\": OpenAIAPIModel,\n            \"anthropic\": AnthropicAPIModel,\n            \"google\": GoogleAPIModel,\n            \"ollama\": OllamaAPIModel,\n            \"lmstudio\": LMStudioAPIModel,\n        }[provider](cfg=cfg)\n\n    # Local model\n    return {\n        \"vader\": VADERModel,\n        \"textblob\": TextBlobModel,\n        \"distilbert\": DistilBERTModel,\n        \"nlptown\": NLPTownModel,\n    }[name]()\n```\n\n---\n\n## Configuration System\n\n### Dataclass Hierarchy\n\n```python\n@dataclass\nclass ArcConfig:\n    project: ProjectConfig\n    paths: PathsConfig\n    text: TextConfig\n    segmentation: SegmentationConfig\n    models: ModelsConfig\n    api_models: ApiModelsConfig\n    normalization: NormalizationConfig\n    smoothing: SmoothingConfig\n    crux_detection: CruxDetectionConfig\n    incoherence: IncoherenceConfig  # NEW\n    logging: LoggingConfig\n    reproducibility: ReproducibilityConfig\n\n    @classmethod\n    def from_yaml(cls, path: str | Path) -> \"ArcConfig\":\n        \"\"\"Load config from YAML file.\"\"\"\n        raw = yaml.safe_load(Path(path).read_text())\n        return cls(**parse_config(raw))\n```\n\n### Validation\n\nConfiguration validation occurs at dataclass `__post_init__`:\n\n```python\n@dataclass\nclass IncoherenceConfig:\n    enabled: bool = True\n    algorithm: str = \"sd\"\n    min_models: int = 2\n\n    def __post_init__(self) -> None:\n        allowed_algorithms = {\"sd\", \"var\", \"mad\"}\n        if self.algorithm not in allowed_algorithms:\n            raise ValueError(\n                f\"Invalid algorithm '{self.algorithm}'. \"\n                f\"Must be one of: {allowed_algorithms}\"\n            )\n        if self.min_models < 2:\n            raise ValueError(\"min_models must be at least 2\")\n```\n\n---\n\n## Data Flow\n\n### DataFrame Schema Evolution\n\n```\nStage 1-3: Segmentation\n├─ segment_no: int\n└─ segment_text: str\n\nStage 4: Sentiment Analysis\n├─ segment_no: int\n├─ segment_text: str\n├─ vader_sentiment: float\n├─ textblob_sentiment: float\n├─ distilbert_sentiment: float\n└─ api_openai_sentiment: float\n\nStage 5: Smoothing\n├─ ... (previous columns)\n├─ vader_sentiment_smoothed: float\n├─ textblob_sentiment_smoothed: float\n└─ ...\n\nStage 6: Normalization\n├─ ... (previous columns)\n├─ vader_sentiment_smoothed_norm: float\n└─ ...\n\nStage 6.75: Incoherence (NEW)\n├─ segment_no: int\n├─ segment_text: str\n├─ vader_sentiment: float (raw)\n├─ textblob_sentiment: float (raw)\n├─ incoherence_sd: float  ← Inserted here\n├─ vader_sentiment_smoothed: float\n└─ ... (rest of columns)\n\nStage 6: Ensemble Average (if multiple models in base_model_choice)\n├─ ... (previous columns)\n└─ {model1}-{model2}_sentiment: float\n\nStage 7: Crux Detection\n└─ (No new columns, produces CruxDetectionResult object)\n```\n\n### Column Ordering Strategy\n\n**Main Sentiment CSV** ordering:\n1. `segment_no`\n2. `segment_text`\n3. `{model}_sentiment` (all raw sentiment columns)\n4. `incoherence_{algorithm}` ← **Inserted here in Stage 6.75**\n5. `{ensemble}_sentiment` (if applicable)\n6. `{model}_sentiment_smoothed` (all smoothed columns)\n7. `{model}_sentiment_smoothed_norm` (all normalized columns)\n8. `{ensemble}_sentiment_smoothed` (if applicable)\n9. `{ensemble}_sentiment_smoothed_norm` (if applicable)\n\n---\n\n## Extension Points\n\n### Adding a New Model\n\n1. **Create Model Class**:\n\n```python\n# sentimentarcs/models/my_model.py\nfrom .base import BaseSentimentModel\n\n@dataclass\nclass MyModel(BaseSentimentModel):\n    @property\n    def model_name(self) -> str:\n        return \"my_model\"\n\n    def load(self) -> None:\n        # Load model resources\n        pass\n\n    def unload(self) -> None:\n        # Clean up resources\n        pass\n\n    def predict(self, texts: List[str]) -> np.ndarray:\n        # Return scores in [-1, 1]\n        scores = [...]\n        return np.array(scores, dtype=float)\n```\n\n2. **Register in Factory**:\n\n```python\n# sentimentarcs/models/__init__.py\ndef create_model(name: str, **kwargs) -> BaseSentimentModel:\n    models = {\n        # ... existing models ...\n        \"my_model\": MyModel,\n    }\n    return models[name](**kwargs)\n```\n\n3. **Add to Configuration**:\n\n```yaml\nmodels:\n  enabled_models:\n    - \"my_model\"\n```\n\n### Adding a New Incoherence Algorithm\n\n1. **Implement Algorithm**:\n\n```python\n# sentimentarcs/analysis/incoherence_detector.py\ndef compute_incoherence(\n    sentiment_table: pd.DataFrame,\n    model_columns: List[str],\n    algorithm: str = \"sd\",\n    min_models: int = 2,\n) -> Tuple[pd.Series, str]:\n    sentiment_matrix = sentiment_table[model_columns].values\n\n    if algorithm == \"my_metric\":\n        # Implement custom disagreement metric\n        incoherence = custom_calculation(sentiment_matrix)\n        column_name = \"incoherence_my_metric\"\n    # ... existing algorithms ...\n\n    return pd.Series(incoherence, index=sentiment_table.index), column_name\n```\n\n2. **Update Configuration Validation**:\n\n```python\n@dataclass\nclass IncoherenceConfig:\n    # ...\n    def __post_init__(self) -> None:\n        allowed_algorithms = {\"sd\", \"var\", \"mad\", \"my_metric\"}\n        # ...\n```\n\n### Adding a New Pipeline Stage\n\n1. **Implement Stage Method** in `SentimentAnalyzer`:\n\n```python\ndef _stage_X_my_analysis(self, df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Stage X: My custom analysis.\n    \"\"\"\n    # Process df\n    df[\"my_metric\"] = calculate_my_metric(df)\n    return df\n```\n\n2. **Insert into Pipeline** in `run()`:\n\n```python\ndef run(self, input_path: str | Path) -> SentimentAnalyzerResult:\n    # ... existing stages ...\n\n    # Stage X: My analysis\n    sentiment_table = self._stage_X_my_analysis(sentiment_table)\n\n    # ... continue pipeline ...\n```\n\n---\n\n## API Reference\n\n### Core Classes\n\n#### SentimentAnalyzer\n\n```python\nclass SentimentAnalyzer:\n    \"\"\"\n    Main pipeline orchestrator.\n\n    Parameters\n    ----------\n    cfg : ArcConfig\n        Configuration object loaded from YAML.\n\n    Methods\n    -------\n    run(input_path: str | Path) -> SentimentAnalyzerResult\n        Execute full pipeline on input text file.\n    \"\"\"\n```\n\n#### SentimentAnalyzerResult\n\n```python\n@dataclass\nclass SentimentAnalyzerResult:\n    segments: SegmentationResult\n    sentiment_table: pd.DataFrame\n    crux: Optional[CruxDetectionResult]\n    ensemble_plot_path: Optional[Path]\n    plot_path: Optional[Path]\n    report_path: Optional[Path]\n```\n\n### Key Functions\n\n#### Incoherence Analysis\n\n```python\ndef compute_incoherence(\n    sentiment_table: pd.DataFrame,\n    model_columns: List[str],\n    algorithm: str = \"sd\",\n    min_models: int = 2,\n) -> Tuple[pd.Series, str]:\n    \"\"\"\n    Compute disagreement metrics across ensemble models.\n\n    Returns\n    -------\n    incoherence_series : pd.Series\n        Incoherence values for each segment.\n    column_name : str\n        Name of incoherence column (e.g., 'incoherence_sd').\n    \"\"\"\n\ndef identify_high_disagreement_segments(\n    sentiment_table: pd.DataFrame,\n    incoherence_column: str,\n    threshold_percentile: float = 90.0,\n) -> pd.DataFrame:\n    \"\"\"\n    Identify segments with high model disagreement.\n\n    Returns top segments sorted by incoherence descending.\n    \"\"\"\n\ndef generate_incoherence_report(\n    sentiment_table: pd.DataFrame,\n    incoherence_column: str,\n    model_columns: List[str],\n    output_path: str,\n) -> None:\n    \"\"\"\n    Generate markdown report with statistics and top disagreements.\n    \"\"\"\n```\n\n---\n\n## Testing Strategy\n\nSee [TESTING.md](TESTING.md) for comprehensive testing documentation.\n\n### Test Structure\n\n```\ntests/\n├── unit/                      # Module-level tests\n│   ├── test_incoherence_detector.py (11 tests)\n│   ├── test_models_local.py\n│   ├── test_models_api.py\n│   └── ...\n├── integration/               # Pipeline-level tests\n│   ├── test_incoherence_analysis.py (8 tests)\n│   ├── test_sentiment_analyzer.py\n│   └── ...\n└── conftest.py               # Shared fixtures\n```\n\n### Running Tests\n\n```bash\n# All tests\npytest tests/\n\n# Unit tests only\npytest tests/unit/\n\n# Integration tests only\npytest tests/integration/\n\n# Exclude API tests (require credentials)\npytest tests/ -k \"not api\"\n\n# With coverage\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\n---\n\n## Performance Considerations\n\n### Model Load Times\n\n| Model | Load Time | Memory | Speed (CPU) |\n|-------|-----------|---------|-------------|\n| VADER | < 0.1s | < 10 MB | ~1000 seg/s |\n| TextBlob | < 0.1s | < 20 MB | ~500 seg/s |\n| DistilBERT | 2-5s | ~250 MB | ~10 seg/s |\n| NLPTown | 3-7s | ~450 MB | ~7 seg/s |\n| OpenAI API | N/A | N/A | ~1 seg/s (batch 20) |\n| Ollama Local | 5-120s | Varies | ~0.5 seg/s (batch 20) |\n\n### Batch Processing\n\nAPI models use batch processing to reduce API calls:\n\n```python\n# Instead of 100 API calls\nfor text in texts:\n    score = api_call(text)  # 100 calls\n\n# Batch into 5 API calls\nfor batch in batches(texts, size=20):\n    scores = api_call(batch)  # 5 calls\n```\n\n**Configuration**:\n```yaml\napi_models:\n  openai:\n    batch_size: 20  # Process 20 segments per API call\n```\n\n### Memory Management\n\n**Transformer Models**:\n- Explicitly call `model.unload()` after use\n- Use GPU if available: `models.use_gpu_if_available: true`\n- Reduce batch size if OOM: `transformer_batch_size: 16`\n\n**Ollama Models**:\n- Wait for model to unload: `model_switch_delay_sec: 3`\n- Single model in memory at a time\n\n### Output File Sizes\n\nTypical output sizes for 1000-segment novel:\n\n- Segments CSV: ~500 KB\n- Sentiment CSV: ~1 MB (4 models) → ~2 MB (with incoherence)\n- Incoherence CSV: ~200 KB\n- Plots: ~50-100 KB each\n- Reports: ~10-20 KB\n- Logs: ~100-500 KB\n\n---\n\n## Environment Variables\n\n### Required for API Models\n\n```bash\n# OpenAI\nexport OPENAI_API_KEY=\"sk-proj-...\"\n\n# Anthropic\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n\n# Google\nexport GEMINI_API_KEY=\"...\"\n```\n\n### Configuration via .env\n\nCreate `.env` file in project root:\n\n```bash\nOPENAI_API_KEY=\"sk-proj-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGEMINI_API_KEY=\"...\"\n```\n\nLoaded automatically via `python-dotenv`:\n\n```python\nfrom dotenv import load_dotenv\nload_dotenv()  # Loads .env file\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\n```\n\n---\n\n## Dependencies\n\n### Core Dependencies\n\n```toml\n[project]\ndependencies = [\n  \"pandas>=1.5,<2.3\",\n  \"numpy>=1.24,<2.0\",\n  \"matplotlib>=3.7,<4.0\",\n  \"scipy>=1.10,<2.0\",\n  \"pyyaml>=6.0,<7.0\",\n  \"pydantic>=2.0,<3.0\",\n  \"python-dotenv>=1.0.0,<2.0\",\n]\n```\n\n### Model-Specific Dependencies\n\n```toml\n# Local sentiment models\n\"textblob>=0.18,<0.19\"\n\"vaderSentiment>=3.3.2,<4.0\"\n\n# Transformers\n\"transformers>=4.0,<5.0\"\n\"torch>=2.0,<3.0\"\n\n# API clients\n\"openai>=1.0.0,<2.0\"\n\"anthropic>=0.20.0,<1.0\"\n\"requests>=2.31,<3.0\"\n```\n\n---\n\n## Logging\n\n### Configuration\n\n```yaml\nlogging:\n  level: \"INFO\"  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n  log_to_stdout: true\n  log_to_file: true\n```\n\n### Log File Structure\n\n```\noutputs/{run_name}/logs/\n└── sentimentarcs_{model_label}_{timestamp}.log\n```\n\n### Log Format\n\n```\n2025-11-11 02:40:00,556 [INFO] sentimentarcs.core.sentiment_analyzer: Stage 6.75: Computing incoherence metrics across 2 models\n```\n\n---\n\n## Reproducibility\n\n### Random Seed\n\n```yaml\nreproducibility:\n  random_seed: 42\n  deterministic: true\n```\n\nApplied to:\n- NumPy random operations\n- PyTorch operations (if using GPU)\n- Model initialization\n\n### Version Pinning\n\nAll dependencies use version ranges to ensure reproducibility while allowing security updates:\n\n```toml\n\"pandas>=1.5,<2.3\"  # Major version locked, minor updates allowed\n```\n\n---\n\n## Future Roadmap\n\n1. **Parallel Processing**: Multi-threaded model execution\n2. **Streaming API**: Process large texts without loading entire file\n3. **Custom Aggregation**: User-defined ensemble functions\n4. **Interactive Dashboard**: Web UI for exploration\n5. **Model Caching**: Cache API responses to reduce costs\n6. **Distributed Processing**: Ray/Dask for large-scale analysis\n\n---\n\n## References\n\n- **OpenAI API Docs**: https://platform.openai.com/docs/api-reference\n- **Ollama API Docs**: https://github.com/ollama/ollama/blob/main/docs/api.md\n- **HuggingFace Transformers**: https://huggingface.co/docs/transformers\n- **Pydantic V2**: https://docs.pydantic.dev/latest/\n- **Pytest**: https://docs.pytest.org/\n\n---\n\n**Document Version**: 1.0\n**Last Updated**: November 2025\n**Maintainer**: Jon Chun (jon.chun@example.com)\n","numLines":1050,"startLine":1,"totalLines":1050}}}
{"parentUuid":"9fd2955a-c86a-434a-8674-257ced56f020","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_0139BQVsfd9NNgSWFACjfGdD","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me check the config structure and testing to better understand the current capabilities:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2487,"cache_creation_input_tokens":20706,"cache_read_input_tokens":17710,"cache_creation":{"ephemeral_5m_input_tokens":20706,"ephemeral_1h_input_tokens":0},"output_tokens":263,"service_tier":"standard"}},"requestId":"req_011CV2KRvX5wMb2AqRoSPEtH","type":"assistant","uuid":"9e42eccf-86e2-45bd-964c-61385ef9a98d","timestamp":"2025-11-11T15:13:09.434Z"}
{"parentUuid":"9e42eccf-86e2-45bd-964c-61385ef9a98d","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_0139BQVsfd9NNgSWFACjfGdD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016nsThyLzL7gnywQQQoo4m6","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/sentimentarcs/config.py","limit":150}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2487,"cache_creation_input_tokens":20706,"cache_read_input_tokens":17710,"cache_creation":{"ephemeral_5m_input_tokens":20706,"ephemeral_1h_input_tokens":0},"output_tokens":263,"service_tier":"standard"}},"requestId":"req_011CV2KRvX5wMb2AqRoSPEtH","type":"assistant","uuid":"ac58e11a-3280-47c5-aa87-d557f6fe4199","timestamp":"2025-11-11T15:13:10.174Z"}
{"parentUuid":"ac58e11a-3280-47c5-aa87-d557f6fe4199","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_0139BQVsfd9NNgSWFACjfGdD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012MSs7mFn9jSScUXB5NdLhq","name":"Bash","input":{"command":"find tests/ -name \"*.py\" -type f | wc -l","description":"Count test files"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2487,"cache_creation_input_tokens":20706,"cache_read_input_tokens":17710,"cache_creation":{"ephemeral_5m_input_tokens":20706,"ephemeral_1h_input_tokens":0},"output_tokens":263,"service_tier":"standard"}},"requestId":"req_011CV2KRvX5wMb2AqRoSPEtH","type":"assistant","uuid":"3895e049-acdb-43db-ba87-ccc365e1a513","timestamp":"2025-11-11T15:13:11.126Z"}
{"parentUuid":"3895e049-acdb-43db-ba87-ccc365e1a513","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_0139BQVsfd9NNgSWFACjfGdD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019e46Tx2gCwNMJfa1o73YLX","name":"Read","input":{"file_path":"/Users/jonc/code/sentimentarcs/docs/doc_testing.md","limit":100}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2487,"cache_creation_input_tokens":20706,"cache_read_input_tokens":17710,"cache_creation":{"ephemeral_5m_input_tokens":20706,"ephemeral_1h_input_tokens":0},"output_tokens":263,"service_tier":"standard"}},"requestId":"req_011CV2KRvX5wMb2AqRoSPEtH","type":"assistant","uuid":"8fc151dc-baa2-4563-8905-277c32d40870","timestamp":"2025-11-11T15:13:11.710Z"}
{"parentUuid":"8fc151dc-baa2-4563-8905-277c32d40870","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016nsThyLzL7gnywQQQoo4m6","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→from dataclasses import dataclass, field\n     4→from pathlib import Path\n     5→from typing import Any, Dict, List, Optional, Union\n     6→import yaml\n     7→@dataclass\n     8→class ProjectConfig:\n     9→    name: str = \"sentimentarcs_project\"\n    10→\n    11→\n    12→@dataclass\n    13→class PathsConfig:\n    14→    output_root: Path = Path(\"outputs\")\n    15→    logs_subdir: str = \"logs\"\n    16→    segments_subdir: str = \"segments\"\n    17→    sentiment_subdir: str = \"sentiment\"\n    18→    plots_subdir: str = \"plots\"\n    19→    reports_subdir: str = \"reports\"\n    20→\n    21→\n    22→@dataclass\n    23→class TextConfig:\n    24→    encoding: str = \"utf-8\"\n    25→    language: str = \"en\"\n    26→\n    27→\n    28→@dataclass\n    29→class SegmentationConfig:\n    30→    max_segment_chars: int = 2000\n    31→    min_segment_chars: int = 5\n    32→    allow_empty_segments: bool = False\n    33→    preview_segments: int = 3\n    34→\n    35→\n    36→@dataclass\n    37→class ModelsConfig:\n    38→    enabled_models: list[str] = field(\n    39→        default_factory=lambda: [\"vader\", \"textblob\", \"distilbert\", \"nlptown\"]\n    40→    )\n    41→    distilbert_model_name: str = \"distilbert-base-uncased-finetuned-sst-2-english\"\n    42→    nlptown_model_name: str = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n    43→    transformer_batch_size: int = 32\n    44→    use_gpu_if_available: bool = True\n    45→\n    46→\n    47→@dataclass\n    48→class NormalizationConfig:\n    49→    strategy: str = \"minmax_per_text\"\n    50→    sentiment_column_suffix: str = \"_sentiment\"\n    51→\n    52→\n    53→@dataclass\n    54→class SmoothingConfig:\n    55→    method: str = \"sma\"\n    56→    sma_window_percent: float = 3.0\n    57→    es_span: int = 20\n    58→    sg_window_percent: float = 3.0\n    59→    sg_polyorder: int = 3\n    60→\n    61→\n    62→@dataclass\n    63→class IncoherenceConfig:\n    64→    \"\"\"\n    65→    Configuration options for ensemble model disagreement/incoherence analysis.\n    66→\n    67→    Attributes\n    68→    ----------\n    69→    enabled : bool\n    70→        Whether to compute incoherence metrics (default: True).\n    71→    algorithm : str\n    72→        Algorithm to use for computing incoherence. Options:\n    73→        - 'sd': Standard deviation across models\n    74→        - 'var': Variance across models\n    75→        - 'mad': Mean absolute deviation from the mean\n    76→    min_models : int\n    77→        Minimum number of models required to compute incoherence (default: 2).\n    78→    \"\"\"\n    79→    enabled: bool = True\n    80→    algorithm: str = \"sd\"\n    81→    min_models: int = 2\n    82→\n    83→    def __post_init__(self) -> None:\n    84→        allowed_algorithms = {\"sd\", \"var\", \"mad\"}\n    85→        if self.algorithm not in allowed_algorithms:\n    86→            raise ValueError(\n    87→                f\"incoherence.algorithm must be one of {sorted(allowed_algorithms)}, \"\n    88→                f\"got {self.algorithm!r}\"\n    89→            )\n    90→        if self.min_models < 2:\n    91→            raise ValueError(\n    92→                f\"incoherence.min_models must be >= 2, got {self.min_models}\"\n    93→            )\n    94→\n    95→\n    96→@dataclass\n    97→class CruxDetectionConfig:\n    98→    \"\"\"\n    99→    Configuration options for crux (peak/valley) detection on the\n   100→    sentiment arc.\n   101→\n   102→    Attributes\n   103→    ----------\n   104→    base_model_choice :\n   105→        Either a single model name (e.g. \"distilbert\") or a list of\n   106→        model names (e.g. [\"vader\", \"textblob\", \"distilbert\"]).\n   107→\n   108→        These names must match the prefixes of sentiment columns in\n   109→        the sentiment table (before the sentiment suffix), e.g.\n   110→        \"distilbert\" → \"distilbert_sentiment\".\n   111→\n   112→    avg_method :\n   113→        Aggregation method to use when more than one base model is\n   114→        specified. Supported values are:\n   115→\n   116→        - \"mean\"   : arithmetic mean across models\n   117→        - \"median\" : median across models\n   118→        - \"mode\"   : per-position mode (with mean fallback if needed).\n   119→\n   120→    window_size :\n   121→        Half-window size (in segments) used when extracting crux\n   122→        text windows around detected peaks/valleys.\n   123→\n   124→    context_window_segments :\n   125→        Legacy synonym for window_size used in the original config\n   126→        and tests. If provided, it overrides window_size so old\n   127→        configs keep working.\n   128→\n   129→    min_distance :\n   130→        Absolute minimum distance (in segments) between adjacent peaks/\n   131→        valleys passed to the underlying peak-finding routine. If this\n   132→        is None, `min_distance_percent` will be used instead.\n   133→\n   134→    min_distance_percent :\n   135→        Optional minimum distance as a fraction of the total number of\n   136→        segments (e.g. 0.01 → 1% of segments). Used only if\n   137→        `min_distance` is None. This field exists for backwards\n   138→        compatibility with older configs and tests.\n   139→\n   140→    prominence_threshold :\n   141→        Minimum prominence for a peak/valley to be considered a crux\n   142→        point. Higher values keep only more salient extremes.\n   143→\n   144→    min_height :\n   145→        Optional absolute height cutoff for peaks/valleys. If None,\n   146→        height is not constrained beyond the prominence threshold.\n   147→\n   148→    max_crux_points :\n   149→        Optional cap on the number of crux points returned. If set,\n   150→        only the top-k points (by absolute sentiment) will be kept.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"553b3210-7c9c-4131-94f0-52003959f069","timestamp":"2025-11-11T15:13:11.736Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/sentimentarcs/config.py","content":"from __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\nimport yaml\n@dataclass\nclass ProjectConfig:\n    name: str = \"sentimentarcs_project\"\n\n\n@dataclass\nclass PathsConfig:\n    output_root: Path = Path(\"outputs\")\n    logs_subdir: str = \"logs\"\n    segments_subdir: str = \"segments\"\n    sentiment_subdir: str = \"sentiment\"\n    plots_subdir: str = \"plots\"\n    reports_subdir: str = \"reports\"\n\n\n@dataclass\nclass TextConfig:\n    encoding: str = \"utf-8\"\n    language: str = \"en\"\n\n\n@dataclass\nclass SegmentationConfig:\n    max_segment_chars: int = 2000\n    min_segment_chars: int = 5\n    allow_empty_segments: bool = False\n    preview_segments: int = 3\n\n\n@dataclass\nclass ModelsConfig:\n    enabled_models: list[str] = field(\n        default_factory=lambda: [\"vader\", \"textblob\", \"distilbert\", \"nlptown\"]\n    )\n    distilbert_model_name: str = \"distilbert-base-uncased-finetuned-sst-2-english\"\n    nlptown_model_name: str = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n    transformer_batch_size: int = 32\n    use_gpu_if_available: bool = True\n\n\n@dataclass\nclass NormalizationConfig:\n    strategy: str = \"minmax_per_text\"\n    sentiment_column_suffix: str = \"_sentiment\"\n\n\n@dataclass\nclass SmoothingConfig:\n    method: str = \"sma\"\n    sma_window_percent: float = 3.0\n    es_span: int = 20\n    sg_window_percent: float = 3.0\n    sg_polyorder: int = 3\n\n\n@dataclass\nclass IncoherenceConfig:\n    \"\"\"\n    Configuration options for ensemble model disagreement/incoherence analysis.\n\n    Attributes\n    ----------\n    enabled : bool\n        Whether to compute incoherence metrics (default: True).\n    algorithm : str\n        Algorithm to use for computing incoherence. Options:\n        - 'sd': Standard deviation across models\n        - 'var': Variance across models\n        - 'mad': Mean absolute deviation from the mean\n    min_models : int\n        Minimum number of models required to compute incoherence (default: 2).\n    \"\"\"\n    enabled: bool = True\n    algorithm: str = \"sd\"\n    min_models: int = 2\n\n    def __post_init__(self) -> None:\n        allowed_algorithms = {\"sd\", \"var\", \"mad\"}\n        if self.algorithm not in allowed_algorithms:\n            raise ValueError(\n                f\"incoherence.algorithm must be one of {sorted(allowed_algorithms)}, \"\n                f\"got {self.algorithm!r}\"\n            )\n        if self.min_models < 2:\n            raise ValueError(\n                f\"incoherence.min_models must be >= 2, got {self.min_models}\"\n            )\n\n\n@dataclass\nclass CruxDetectionConfig:\n    \"\"\"\n    Configuration options for crux (peak/valley) detection on the\n    sentiment arc.\n\n    Attributes\n    ----------\n    base_model_choice :\n        Either a single model name (e.g. \"distilbert\") or a list of\n        model names (e.g. [\"vader\", \"textblob\", \"distilbert\"]).\n\n        These names must match the prefixes of sentiment columns in\n        the sentiment table (before the sentiment suffix), e.g.\n        \"distilbert\" → \"distilbert_sentiment\".\n\n    avg_method :\n        Aggregation method to use when more than one base model is\n        specified. Supported values are:\n\n        - \"mean\"   : arithmetic mean across models\n        - \"median\" : median across models\n        - \"mode\"   : per-position mode (with mean fallback if needed).\n\n    window_size :\n        Half-window size (in segments) used when extracting crux\n        text windows around detected peaks/valleys.\n\n    context_window_segments :\n        Legacy synonym for window_size used in the original config\n        and tests. If provided, it overrides window_size so old\n        configs keep working.\n\n    min_distance :\n        Absolute minimum distance (in segments) between adjacent peaks/\n        valleys passed to the underlying peak-finding routine. If this\n        is None, `min_distance_percent` will be used instead.\n\n    min_distance_percent :\n        Optional minimum distance as a fraction of the total number of\n        segments (e.g. 0.01 → 1% of segments). Used only if\n        `min_distance` is None. This field exists for backwards\n        compatibility with older configs and tests.\n\n    prominence_threshold :\n        Minimum prominence for a peak/valley to be considered a crux\n        point. Higher values keep only more salient extremes.\n\n    min_height :\n        Optional absolute height cutoff for peaks/valleys. If None,\n        height is not constrained beyond the prominence threshold.\n\n    max_crux_points :\n        Optional cap on the number of crux points returned. If set,\n        only the top-k points (by absolute sentiment) will be kept.","numLines":150,"startLine":1,"totalLines":311}}}
{"parentUuid":"553b3210-7c9c-4131-94f0-52003959f069","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019e46Tx2gCwNMJfa1o73YLX","type":"tool_result","content":"     1→# SentimentArcs Testing Guide\n     2→\n     3→## Table of Contents\n     4→\n     5→1. [Overview](#overview)\n     6→2. [Test Organization](#test-organization)\n     7→3. [CLI Tests](#cli-tests)\n     8→4. [API Tests](#api-tests)\n     9→5. [Running Tests](#running-tests)\n    10→6. [Master Regression Harness](#master-regression-harness)\n    11→7. [Writing New Tests](#writing-new-tests)\n    12→8. [Test Data](#test-data)\n    13→9. [Continuous Integration](#continuous-integration)\n    14→10. [Troubleshooting](#troubleshooting)\n    15→11. [Test Coverage Metrics](#test-coverage-metrics)\n    16→\n    17→---\n    18→\n    19→## Overview\n    20→\n    21→The SentimentArcs library provides two complete interfaces for sentiment analysis:\n    22→\n    23→- **CLI Interface** (`SentimentAnalyzer`) - Original command-line interface for batch processing\n    24→- **API Interface** (`SentimentPipeline`) - NEW programmatic fluent interface for script integration\n    25→\n    26→Both interfaces have comprehensive test suites ensuring reliability, correctness, and backward compatibility.\n    27→\n    28→### Testing Philosophy\n    29→\n    30→Our testing strategy follows a pyramid approach:\n    31→\n    32→1. **Unit Tests** - Test individual functions and methods in isolation using mocks\n    33→2. **Integration Tests** - Test complete workflows with real data processing\n    34→3. **Regression Tests** - Ensure changes don't break existing functionality\n    35→\n    36→### Test Summary\n    37→\n    38→| Category | Unit Tests | Integration Tests | Total |\n    39→|----------|------------|-------------------|-------|\n    40→| **CLI Tests** | 16 tests | 9 tests | **25 tests** |\n    41→| **API Tests** | 31 tests | 35 tests | **66 tests** |\n    42→| **TOTAL** | **47 tests** | **44 tests** | **91 tests** |\n    43→\n    44→### Quick Start Commands\n    45→\n    46→```bash\n    47→# Run all tests (recommended)\n    48→python tests/test_regression_harness.py\n    49→\n    50→# Run with verbose output\n    51→python tests/test_regression_harness.py --verbose\n    52→\n    53→# Run only CLI tests\n    54→python tests/test_regression_harness.py --cli-only\n    55→\n    56→# Run only API tests\n    57→python tests/test_regression_harness.py --api-only\n    58→\n    59→# Run only unit tests\n    60→python tests/test_regression_harness.py --unit-only\n    61→\n    62→# Run only integration tests\n    63→python tests/test_regression_harness.py --integration-only\n    64→\n    65→# Direct pytest (all tests)\n    66→pytest tests/\n    67→\n    68→# Direct pytest (with coverage)\n    69→pytest --cov=sentimentarcs --cov-report=html tests/\n    70→```\n    71→\n    72→**Expected Execution Time:** ~35 seconds for full test suite\n    73→\n    74→---\n    75→\n    76→## Test Organization\n    77→\n    78→### Directory Structure\n    79→\n    80→```\n    81→tests/\n    82→├── conftest.py                              # Shared pytest fixtures\n    83→│\n    84→├── unit/                                     # Unit tests (47 total)\n    85→│   ├── test_incoherence_detector.py        # CLI - 11 tests\n    86→│   ├── test_text_processor.py              # CLI - 1 test\n    87→│   ├── test_normalizer.py                  # CLI - 2 tests\n    88→│   ├── test_crux_detector.py               # CLI - 1 test\n    89→│   ├── test_smoothing.py                   # CLI - 1 test\n    90→│   ├── test_models_local.py                # CLI - (skipped in CI)\n    91→│   ├── test_models_api.py                  # CLI - (skipped in CI)\n    92→│   └── test_api_pipeline_unit.py           # API - 31 tests\n    93→│\n    94→├── integration/                              # Integration tests (44 total)\n    95→│   ├── test_sentiment_analyzer.py          # CLI - 1 test (end-to-end)\n    96→│   ├── test_incoherence_analysis.py        # CLI - 8 tests\n    97→│   ├── test_cli.py                         # CLI - (optional)\n    98→│   └── test_api_pipeline_integration.py    # API - 35 tests\n    99→│\n   100→└── test_regression_harness.py               # Master test runner\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"2bd61952-d040-4dd1-8d77-4b82b55508a1","timestamp":"2025-11-11T15:13:11.737Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/jonc/code/sentimentarcs/docs/doc_testing.md","content":"# SentimentArcs Testing Guide\n\n## Table of Contents\n\n1. [Overview](#overview)\n2. [Test Organization](#test-organization)\n3. [CLI Tests](#cli-tests)\n4. [API Tests](#api-tests)\n5. [Running Tests](#running-tests)\n6. [Master Regression Harness](#master-regression-harness)\n7. [Writing New Tests](#writing-new-tests)\n8. [Test Data](#test-data)\n9. [Continuous Integration](#continuous-integration)\n10. [Troubleshooting](#troubleshooting)\n11. [Test Coverage Metrics](#test-coverage-metrics)\n\n---\n\n## Overview\n\nThe SentimentArcs library provides two complete interfaces for sentiment analysis:\n\n- **CLI Interface** (`SentimentAnalyzer`) - Original command-line interface for batch processing\n- **API Interface** (`SentimentPipeline`) - NEW programmatic fluent interface for script integration\n\nBoth interfaces have comprehensive test suites ensuring reliability, correctness, and backward compatibility.\n\n### Testing Philosophy\n\nOur testing strategy follows a pyramid approach:\n\n1. **Unit Tests** - Test individual functions and methods in isolation using mocks\n2. **Integration Tests** - Test complete workflows with real data processing\n3. **Regression Tests** - Ensure changes don't break existing functionality\n\n### Test Summary\n\n| Category | Unit Tests | Integration Tests | Total |\n|----------|------------|-------------------|-------|\n| **CLI Tests** | 16 tests | 9 tests | **25 tests** |\n| **API Tests** | 31 tests | 35 tests | **66 tests** |\n| **TOTAL** | **47 tests** | **44 tests** | **91 tests** |\n\n### Quick Start Commands\n\n```bash\n# Run all tests (recommended)\npython tests/test_regression_harness.py\n\n# Run with verbose output\npython tests/test_regression_harness.py --verbose\n\n# Run only CLI tests\npython tests/test_regression_harness.py --cli-only\n\n# Run only API tests\npython tests/test_regression_harness.py --api-only\n\n# Run only unit tests\npython tests/test_regression_harness.py --unit-only\n\n# Run only integration tests\npython tests/test_regression_harness.py --integration-only\n\n# Direct pytest (all tests)\npytest tests/\n\n# Direct pytest (with coverage)\npytest --cov=sentimentarcs --cov-report=html tests/\n```\n\n**Expected Execution Time:** ~35 seconds for full test suite\n\n---\n\n## Test Organization\n\n### Directory Structure\n\n```\ntests/\n├── conftest.py                              # Shared pytest fixtures\n│\n├── unit/                                     # Unit tests (47 total)\n│   ├── test_incoherence_detector.py        # CLI - 11 tests\n│   ├── test_text_processor.py              # CLI - 1 test\n│   ├── test_normalizer.py                  # CLI - 2 tests\n│   ├── test_crux_detector.py               # CLI - 1 test\n│   ├── test_smoothing.py                   # CLI - 1 test\n│   ├── test_models_local.py                # CLI - (skipped in CI)\n│   ├── test_models_api.py                  # CLI - (skipped in CI)\n│   └── test_api_pipeline_unit.py           # API - 31 tests\n│\n├── integration/                              # Integration tests (44 total)\n│   ├── test_sentiment_analyzer.py          # CLI - 1 test (end-to-end)\n│   ├── test_incoherence_analysis.py        # CLI - 8 tests\n│   ├── test_cli.py                         # CLI - (optional)\n│   └── test_api_pipeline_integration.py    # API - 35 tests\n│\n└── test_regression_harness.py               # Master test runner","numLines":100,"startLine":1,"totalLines":1709}}}
{"parentUuid":"2bd61952-d040-4dd1-8d77-4b82b55508a1","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012MSs7mFn9jSScUXB5NdLhq","type":"tool_result","content":"      14","is_error":false}]},"uuid":"cd58b45d-63a3-4778-b580-9861180edd78","timestamp":"2025-11-11T15:13:11.775Z","toolUseResult":{"stdout":"      14","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"cd58b45d-63a3-4778-b580-9861180edd78","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","message":{"model":"claude-sonnet-4-5-20250929","id":"msg_018FEoC2ZLpsN8fVYA33Fw12","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a comprehensive understanding of the SentimentArcs project. Let me create the detailed roadmap document:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1377,"cache_creation_input_tokens":4746,"cache_read_input_tokens":38416,"cache_creation":{"ephemeral_5m_input_tokens":4746,"ephemeral_1h_input_tokens":0},"output_tokens":32000,"service_tier":"standard"}},"requestId":"req_011CV2KSPkwAX9wMxpG98u6D","type":"assistant","uuid":"12a0c055-1ec6-4764-9116-7a518e437f48","timestamp":"2025-11-11T15:13:14.986Z"}
{"parentUuid":"12a0c055-1ec6-4764-9116-7a518e437f48","isSidechain":true,"userType":"external","cwd":"/Users/jonc/code/sentimentarcs","sessionId":"41e37eb3-40a8-48af-b471-c5d7aadc1a1d","version":"2.0.35","gitBranch":"main","agentId":"0c231c7b","type":"assistant","uuid":"ae7bc911-0655-4b1d-b834-77ab9a569e68","timestamp":"2025-11-11T15:22:30.228Z","message":{"id":"0d814c2f-c257-45f1-9370-6fe92abfe2dc","container":null,"model":"<synthetic>","role":"assistant","stop_reason":"stop_sequence","stop_sequence":"","type":"message","usage":{"input_tokens":0,"output_tokens":0,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":null,"cache_creation":{"ephemeral_1h_input_tokens":0,"ephemeral_5m_input_tokens":0}},"content":[{"type":"text","text":"API Error: Claude's response exceeded the 32000 output token maximum. To configure this behavior, set the CLAUDE_CODE_MAX_OUTPUT_TOKENS environment variable."}],"context_management":null},"isApiErrorMessage":true}
